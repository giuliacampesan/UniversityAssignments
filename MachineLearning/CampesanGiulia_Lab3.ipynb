{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clothes Classification with Neural Networks\n",
    "\n",
    "In this notebook we are going to use the Neural Networks for image classification. We are going to use the same dataset of Lab 2 on SVM: Fashion MNIST (https://pravarmahajan.github.io/fashion/), a dataset of small images of clothes and accessories.\n",
    "\n",
    "The dataset labels are the following:\n",
    "\n",
    "| Label | Description |\n",
    "| --- | --- |\n",
    "| 0 | T-shirt/top |\n",
    "| 1 | Trouser |\n",
    "| 2 | Pullover |\n",
    "| 3 | Dress |\n",
    "| 4 | Coat |\n",
    "| 5 | Sandal |\n",
    "| 6 | Shirt |\n",
    "| 7 | Sneaker |\n",
    "| 8 | Bag |\n",
    "| 9 | Ankle boot |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scikit-learn version:  0.23.2\n"
     ]
    }
   ],
   "source": [
    "#load the required packages and check Scikit-learn version\n",
    "\n",
    "%matplotlib inline  \n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "print ('scikit-learn version: ', sklearn.__version__)\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to load Fashion MNIST dataset from disk\n",
    "def load_mnist(path, kind='train'):\n",
    "    import os\n",
    "    import gzip\n",
    "    import numpy as np\n",
    "    labels_path = os.path.join(path, '%s-labels-idx1-ubyte.gz' % kind)\n",
    "    images_path = os.path.join(path, '%s-images-idx3-ubyte.gz' % kind)\n",
    "    with gzip.open(labels_path, 'rb') as lbpath:\n",
    "        labels = np.frombuffer(lbpath.read(), dtype=np.uint8,offset=8)\n",
    "    with gzip.open(images_path, 'rb') as imgpath:\n",
    "        images = np.frombuffer(imgpath.read(), dtype=np.uint8,offset=16).reshape(len(labels), 784)\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO \n",
    "Place a seed for the random generatoryour (you can use your \"numero di matricola\"). Try to change the seed to see the impact of the randomization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID = 987654321\n",
    "np.random.seed(ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in the MNIST dataset: 60000\n"
     ]
    }
   ],
   "source": [
    "#load the MNIST dataset and let's normalize the features so that each value is in [0,1]\n",
    "X, y = load_mnist(\"data\")\n",
    "print(\"Number of samples in the MNIST dataset:\", X.shape[0])\n",
    "# rescale the data\n",
    "X = X / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now split into training and test. We start with a small training set of 600 samples to reduce computation time while 4000 samples will be used for testing. Make sure that each label is present at least 10 times in train and test set frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels in training dataset:  [0 1 2 3 4 5 6 7 8 9]\n",
      "Frequencies in training dataset:  [55 56 62 61 51 57 68 67 65 58]\n",
      "Labels in test set:  [0 1 2 3 4 5 6 7 8 9]\n",
      "Frequencies in test set:  [55 56 62 61 51 57 68 67 65 58]\n"
     ]
    }
   ],
   "source": [
    "#random permute the data and split into training and test taking the first 600\n",
    "#data samples as training and 4000 as test set\n",
    "permutation = np.random.permutation(X.shape[0])\n",
    "\n",
    "X = X[permutation]\n",
    "y = y[permutation]\n",
    "\n",
    "m_training = 600\n",
    "m_test = 4000\n",
    "\n",
    "X_train, X_test = X[:m_training], X[m_training:m_training+m_test]\n",
    "y_train, y_test = y[:m_training], y[m_training:m_training+m_test]\n",
    "\n",
    "labels, freqs = np.unique(y_train, return_counts=True)\n",
    "print(\"Labels in training dataset: \", labels)\n",
    "print(\"Frequencies in training dataset: \", freqs)\n",
    "\n",
    "labelsT, freqsT = np.unique(y_test, return_counts=True)\n",
    "print(\"Labels in test set: \", labels)\n",
    "print(\"Frequencies in test set: \", freqs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for plotting a image and printing the corresponding label\n",
    "def plot_input(X_matrix, labels, index):\n",
    "    print(\"INPUT:\")\n",
    "    plt.imshow(\n",
    "        X_matrix[index].reshape(28,28),\n",
    "        cmap          = plt.cm.gray_r,\n",
    "        interpolation = \"nearest\"\n",
    "    )\n",
    "    #print(X_matrix[index].reshape(28,28))\n",
    "    plt.show()\n",
    "    print(\"LABEL: %i\"%labels[index])\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL: 8\n",
      "INPUT:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL: 4\n",
      "INPUT:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL: 7\n"
     ]
    }
   ],
   "source": [
    "#let's try the plotting function\n",
    "plot_input(X_train,y_train,10)\n",
    "plot_input(X_test,y_test,100)\n",
    "plot_input(X_test,y_test,1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO DO 1\n",
    "\n",
    "Now use a feed-forward Neural Network for prediction. Use the multi-layer perceptron classifier, with the following parameters: max_iter=250, alpha=1e-4, solver='sgd', tol=1e-4, learning_rate_init=.1, random_state=ID (this last parameter ensures the run is the same even if you run it more than once). The alpha parameter is the regularization term.\n",
    "\n",
    "Then, using the default activation function, pick four or five architectures to consider, with different numbers of hidden layers and different sizes. It is not necessary to create huge neural networks, you can limit to 3 layers and, for each layer, its maximum size can be of 50. Evaluate the architectures you chose using GridSearchCV with cv=5.\n",
    "\n",
    "You can reduce the number of iterations if the running time is too long on your computer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.37373501\n",
      "Iteration 2, loss = 2.27005446\n",
      "Iteration 3, loss = 2.12606962\n",
      "Iteration 4, loss = 1.90690169\n",
      "Iteration 5, loss = 1.43848640\n",
      "Iteration 6, loss = 1.15085205\n",
      "Iteration 7, loss = 1.03204410\n",
      "Iteration 8, loss = 1.00472584\n",
      "Iteration 9, loss = 0.94966255\n",
      "Iteration 10, loss = 0.88171628\n",
      "Iteration 11, loss = 0.81965556\n",
      "Iteration 12, loss = 0.79259301\n",
      "Iteration 13, loss = 0.76721352\n",
      "Iteration 14, loss = 0.74539978\n",
      "Iteration 15, loss = 0.70442624\n",
      "Iteration 16, loss = 0.68731406\n",
      "Iteration 17, loss = 0.72477136\n",
      "Iteration 18, loss = 0.69884110\n",
      "Iteration 19, loss = 0.63559108\n",
      "Iteration 20, loss = 0.62523541\n",
      "Iteration 21, loss = 0.64186460\n",
      "Iteration 22, loss = 0.62121970\n",
      "Iteration 23, loss = 0.57387075\n",
      "Iteration 24, loss = 0.55003913\n",
      "Iteration 25, loss = 0.56327142\n",
      "Iteration 26, loss = 0.53837167\n",
      "Iteration 27, loss = 0.52254733\n",
      "Iteration 28, loss = 0.51943062\n",
      "Iteration 29, loss = 0.50234694\n",
      "Iteration 30, loss = 0.48374772\n",
      "Iteration 31, loss = 0.46108576\n",
      "Iteration 32, loss = 0.45853034\n",
      "Iteration 33, loss = 0.47391612\n",
      "Iteration 34, loss = 0.42495486\n",
      "Iteration 35, loss = 0.40567315\n",
      "Iteration 36, loss = 0.38575818\n",
      "Iteration 37, loss = 0.38185153\n",
      "Iteration 38, loss = 0.37688195\n",
      "Iteration 39, loss = 0.36854188\n",
      "Iteration 40, loss = 0.35838005\n",
      "Iteration 41, loss = 0.45066629\n",
      "Iteration 42, loss = 0.34439982\n",
      "Iteration 43, loss = 0.33349738\n",
      "Iteration 44, loss = 0.40393583\n",
      "Iteration 45, loss = 0.47226413\n",
      "Iteration 46, loss = 0.40933847\n",
      "Iteration 47, loss = 0.53082298\n",
      "Iteration 48, loss = 0.32048022\n",
      "Iteration 49, loss = 0.31586914\n",
      "Iteration 50, loss = 0.34380720\n",
      "Iteration 51, loss = 0.26631119\n",
      "Iteration 52, loss = 0.26777969\n",
      "Iteration 53, loss = 0.33291967\n",
      "Iteration 54, loss = 0.26225965\n",
      "Iteration 55, loss = 0.24957858\n",
      "Iteration 56, loss = 0.29843355\n",
      "Iteration 57, loss = 0.33791826\n",
      "Iteration 58, loss = 0.22172824\n",
      "Iteration 59, loss = 0.22052586\n",
      "Iteration 60, loss = 0.21450060\n",
      "Iteration 61, loss = 0.20237336\n",
      "Iteration 62, loss = 0.21183688\n",
      "Iteration 63, loss = 0.18941781\n",
      "Iteration 64, loss = 0.21497543\n",
      "Iteration 65, loss = 0.20067733\n",
      "Iteration 66, loss = 0.18187857\n",
      "Iteration 67, loss = 0.16802174\n",
      "Iteration 68, loss = 0.19576649\n",
      "Iteration 69, loss = 0.24167498\n",
      "Iteration 70, loss = 0.19245072\n",
      "Iteration 71, loss = 0.16297013\n",
      "Iteration 72, loss = 0.15572421\n",
      "Iteration 73, loss = 0.15137602\n",
      "Iteration 74, loss = 0.14860273\n",
      "Iteration 75, loss = 0.14589347\n",
      "Iteration 76, loss = 0.16024552\n",
      "Iteration 77, loss = 1.11058745\n",
      "Iteration 78, loss = 4.04254376\n",
      "Iteration 79, loss = 2.20284130\n",
      "Iteration 80, loss = 2.07477884\n",
      "Iteration 81, loss = 1.95589680\n",
      "Iteration 82, loss = 1.78214240\n",
      "Iteration 83, loss = 1.62286384\n",
      "Iteration 84, loss = 1.50078452\n",
      "Iteration 85, loss = 1.47799635\n",
      "Iteration 86, loss = 1.46638262\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 2.36651282\n",
      "Iteration 2, loss = 2.26433973\n",
      "Iteration 3, loss = 2.13681498\n",
      "Iteration 4, loss = 1.91416809\n",
      "Iteration 5, loss = 1.61435507\n",
      "Iteration 6, loss = 1.27948918\n",
      "Iteration 7, loss = 1.11707770\n",
      "Iteration 8, loss = 1.00981301\n",
      "Iteration 9, loss = 1.02579651\n",
      "Iteration 10, loss = 1.04274576\n",
      "Iteration 11, loss = 0.87130723\n",
      "Iteration 12, loss = 0.83697649\n",
      "Iteration 13, loss = 0.79199308\n",
      "Iteration 14, loss = 0.76870832\n",
      "Iteration 15, loss = 0.75969027\n",
      "Iteration 16, loss = 0.71365070\n",
      "Iteration 17, loss = 0.67744583\n",
      "Iteration 18, loss = 0.66798511\n",
      "Iteration 19, loss = 0.62045736\n",
      "Iteration 20, loss = 0.62249688\n",
      "Iteration 21, loss = 0.59930234\n",
      "Iteration 22, loss = 0.58745582\n",
      "Iteration 23, loss = 0.55389134\n",
      "Iteration 24, loss = 0.53716438\n",
      "Iteration 25, loss = 0.52512575\n",
      "Iteration 26, loss = 0.52245719\n",
      "Iteration 27, loss = 0.48460561\n",
      "Iteration 28, loss = 0.48024861\n",
      "Iteration 29, loss = 0.48892832\n",
      "Iteration 30, loss = 0.46251028\n",
      "Iteration 31, loss = 0.42969125\n",
      "Iteration 32, loss = 0.43009529\n",
      "Iteration 33, loss = 0.41698600\n",
      "Iteration 34, loss = 0.44922277\n",
      "Iteration 35, loss = 0.40928984\n",
      "Iteration 36, loss = 0.38381618\n",
      "Iteration 37, loss = 0.38715740\n",
      "Iteration 38, loss = 0.37137056\n",
      "Iteration 39, loss = 0.37721362\n",
      "Iteration 40, loss = 0.36156236\n",
      "Iteration 41, loss = 0.33760919\n",
      "Iteration 42, loss = 0.36611907\n",
      "Iteration 43, loss = 0.33099513\n",
      "Iteration 44, loss = 0.32244709\n",
      "Iteration 45, loss = 0.33076064\n",
      "Iteration 46, loss = 0.41601553\n",
      "Iteration 47, loss = 0.32329754\n",
      "Iteration 48, loss = 0.37819246\n",
      "Iteration 49, loss = 0.37276402\n",
      "Iteration 50, loss = 0.50174091\n",
      "Iteration 51, loss = 0.33687140\n",
      "Iteration 52, loss = 0.29682059\n",
      "Iteration 53, loss = 0.30758501\n",
      "Iteration 54, loss = 0.28323615\n",
      "Iteration 55, loss = 0.25279713\n",
      "Iteration 56, loss = 0.25688070\n",
      "Iteration 57, loss = 0.24198415\n",
      "Iteration 58, loss = 0.23761349\n",
      "Iteration 59, loss = 0.25827090\n",
      "Iteration 60, loss = 0.24402131\n",
      "Iteration 61, loss = 0.22662548\n",
      "Iteration 62, loss = 0.26243488\n",
      "Iteration 63, loss = 0.22096518\n",
      "Iteration 64, loss = 0.26600437\n",
      "Iteration 65, loss = 0.42318756\n",
      "Iteration 66, loss = 0.45603430\n",
      "Iteration 67, loss = 0.22925745\n",
      "Iteration 68, loss = 0.21125181\n",
      "Iteration 69, loss = 0.20657962\n",
      "Iteration 70, loss = 0.21318823\n",
      "Iteration 71, loss = 0.23338227\n",
      "Iteration 72, loss = 0.20864211\n",
      "Iteration 73, loss = 0.18122399\n",
      "Iteration 74, loss = 0.17647694\n",
      "Iteration 75, loss = 0.16895261\n",
      "Iteration 76, loss = 0.17480765\n",
      "Iteration 77, loss = 0.17935974\n",
      "Iteration 78, loss = 0.16036600\n",
      "Iteration 79, loss = 0.16095936\n",
      "Iteration 80, loss = 0.16427244\n",
      "Iteration 81, loss = 0.15944575\n",
      "Iteration 82, loss = 0.17982715\n",
      "Iteration 83, loss = 0.22405319\n",
      "Iteration 84, loss = 0.18758512\n",
      "Iteration 85, loss = 0.14732437\n",
      "Iteration 86, loss = 0.21464250\n",
      "Iteration 87, loss = 0.16341746\n",
      "Iteration 88, loss = 0.19515356\n",
      "Iteration 89, loss = 0.15440631\n",
      "Iteration 90, loss = 0.13707131\n",
      "Iteration 91, loss = 0.14783136\n",
      "Iteration 92, loss = 1.52319247\n",
      "Iteration 93, loss = 5.51541082\n",
      "Iteration 94, loss = 2.43009734\n",
      "Iteration 95, loss = 2.35931416\n",
      "Iteration 96, loss = 2.24394087\n",
      "Iteration 97, loss = 2.11841349\n",
      "Iteration 98, loss = 1.96702404\n",
      "Iteration 99, loss = 1.88126709\n",
      "Iteration 100, loss = 1.79190983\n",
      "Iteration 101, loss = 1.71188900\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 2.38293205\n",
      "Iteration 2, loss = 2.27494819\n",
      "Iteration 3, loss = 2.16022958\n",
      "Iteration 4, loss = 1.89052375\n",
      "Iteration 5, loss = 1.58586740\n",
      "Iteration 6, loss = 1.41464448\n",
      "Iteration 7, loss = 1.16241665\n",
      "Iteration 8, loss = 1.06414660\n",
      "Iteration 9, loss = 1.03945365\n",
      "Iteration 10, loss = 1.00927660\n",
      "Iteration 11, loss = 0.87972127\n",
      "Iteration 12, loss = 0.83507037\n",
      "Iteration 13, loss = 0.79576678\n",
      "Iteration 14, loss = 0.76738657\n",
      "Iteration 15, loss = 0.77269844\n",
      "Iteration 16, loss = 0.75071808\n",
      "Iteration 17, loss = 0.68773314\n",
      "Iteration 18, loss = 0.67529733\n",
      "Iteration 19, loss = 0.66749735\n",
      "Iteration 20, loss = 0.65702037\n",
      "Iteration 21, loss = 0.63911784\n",
      "Iteration 22, loss = 0.59449586\n",
      "Iteration 23, loss = 0.56835964\n",
      "Iteration 24, loss = 0.56171220\n",
      "Iteration 25, loss = 0.53857792\n",
      "Iteration 26, loss = 0.53314545\n",
      "Iteration 27, loss = 0.53094393\n",
      "Iteration 28, loss = 0.64404593\n",
      "Iteration 29, loss = 0.52256861\n",
      "Iteration 30, loss = 0.48925892\n",
      "Iteration 31, loss = 0.45747589\n",
      "Iteration 32, loss = 0.45247733\n",
      "Iteration 33, loss = 0.45738241\n",
      "Iteration 34, loss = 0.46354831\n",
      "Iteration 35, loss = 0.47656716\n",
      "Iteration 36, loss = 0.42838643\n",
      "Iteration 37, loss = 0.39986797\n",
      "Iteration 38, loss = 0.40491282\n",
      "Iteration 39, loss = 0.39025328\n",
      "Iteration 40, loss = 0.36390294\n",
      "Iteration 41, loss = 0.36529759\n",
      "Iteration 42, loss = 0.35468899\n",
      "Iteration 43, loss = 0.38257824\n",
      "Iteration 44, loss = 0.35706615\n",
      "Iteration 45, loss = 0.34315167\n",
      "Iteration 46, loss = 0.35759633\n",
      "Iteration 47, loss = 0.35170241\n",
      "Iteration 48, loss = 0.32683867\n",
      "Iteration 49, loss = 0.33853820\n",
      "Iteration 50, loss = 0.36547666\n",
      "Iteration 51, loss = 0.37663837\n",
      "Iteration 52, loss = 0.37951291\n",
      "Iteration 53, loss = 0.36129186\n",
      "Iteration 54, loss = 0.30518751\n",
      "Iteration 55, loss = 0.28512760\n",
      "Iteration 56, loss = 0.41455411\n",
      "Iteration 57, loss = 0.30413363\n",
      "Iteration 58, loss = 0.31422880\n",
      "Iteration 59, loss = 0.27840261\n",
      "Iteration 60, loss = 0.26549472\n",
      "Iteration 61, loss = 0.35292362\n",
      "Iteration 62, loss = 0.57123621\n",
      "Iteration 63, loss = 0.98878426\n",
      "Iteration 64, loss = 0.37764941\n",
      "Iteration 65, loss = 0.38758193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 66, loss = 0.29701535\n",
      "Iteration 67, loss = 0.28141757\n",
      "Iteration 68, loss = 0.27179634\n",
      "Iteration 69, loss = 0.25083216\n",
      "Iteration 70, loss = 0.26697008\n",
      "Iteration 71, loss = 0.27084920\n",
      "Iteration 72, loss = 0.23338260\n",
      "Iteration 73, loss = 0.24377207\n",
      "Iteration 74, loss = 0.23256384\n",
      "Iteration 75, loss = 0.23322004\n",
      "Iteration 76, loss = 0.22618786\n",
      "Iteration 77, loss = 0.23591137\n",
      "Iteration 78, loss = 0.21681478\n",
      "Iteration 79, loss = 0.22171348\n",
      "Iteration 80, loss = 0.21146329\n",
      "Iteration 81, loss = 0.25635220\n",
      "Iteration 82, loss = 0.20399633\n",
      "Iteration 83, loss = 0.20389775\n",
      "Iteration 84, loss = 0.22659327\n",
      "Iteration 85, loss = 0.20120551\n",
      "Iteration 86, loss = 0.22923580\n",
      "Iteration 87, loss = 0.22343075\n",
      "Iteration 88, loss = 0.19800179\n",
      "Iteration 89, loss = 0.17940040\n",
      "Iteration 90, loss = 0.22327774\n",
      "Iteration 91, loss = 0.18418272\n",
      "Iteration 92, loss = 0.17451525\n",
      "Iteration 93, loss = 0.16907080\n",
      "Iteration 94, loss = 0.18492090\n",
      "Iteration 95, loss = 0.16921114\n",
      "Iteration 96, loss = 0.17247311\n",
      "Iteration 97, loss = 0.17539289\n",
      "Iteration 98, loss = 0.15500476\n",
      "Iteration 99, loss = 0.15509773\n",
      "Iteration 100, loss = 0.15197477\n",
      "Iteration 101, loss = 0.15370515\n",
      "Iteration 102, loss = 0.16868402\n",
      "Iteration 103, loss = 0.15609451\n",
      "Iteration 104, loss = 0.14915003\n",
      "Iteration 105, loss = 0.16091196\n",
      "Iteration 106, loss = 0.14303819\n",
      "Iteration 107, loss = 0.14607375\n",
      "Iteration 108, loss = 0.14447242\n",
      "Iteration 109, loss = 0.14469511\n",
      "Iteration 110, loss = 0.13989184\n",
      "Iteration 111, loss = 0.13457546\n",
      "Iteration 112, loss = 0.19352910\n",
      "Iteration 113, loss = 0.13015508\n",
      "Iteration 114, loss = 0.13403595\n",
      "Iteration 115, loss = 0.12908011\n",
      "Iteration 116, loss = 0.13838638\n",
      "Iteration 117, loss = 0.15699317\n",
      "Iteration 118, loss = 0.13231787\n",
      "Iteration 119, loss = 0.16361709\n",
      "Iteration 120, loss = 1.21930435\n",
      "Iteration 121, loss = 1.58746375\n",
      "Iteration 122, loss = 0.78062494\n",
      "Iteration 123, loss = 0.77427036\n",
      "Iteration 124, loss = 0.78160040\n",
      "Iteration 125, loss = 0.91875735\n",
      "Iteration 126, loss = 0.57156563\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 2.36923263\n",
      "Iteration 2, loss = 2.26304469\n",
      "Iteration 3, loss = 2.15955463\n",
      "Iteration 4, loss = 1.91093040\n",
      "Iteration 5, loss = 1.55934757\n",
      "Iteration 6, loss = 1.23840997\n",
      "Iteration 7, loss = 1.06988010\n",
      "Iteration 8, loss = 0.95564634\n",
      "Iteration 9, loss = 0.97433293\n",
      "Iteration 10, loss = 0.95068871\n",
      "Iteration 11, loss = 0.77548770\n",
      "Iteration 12, loss = 0.77642151\n",
      "Iteration 13, loss = 0.75028467\n",
      "Iteration 14, loss = 0.64991502\n",
      "Iteration 15, loss = 0.62232252\n",
      "Iteration 16, loss = 0.58188441\n",
      "Iteration 17, loss = 0.52095497\n",
      "Iteration 18, loss = 0.48938894\n",
      "Iteration 19, loss = 0.52413833\n",
      "Iteration 20, loss = 0.43450010\n",
      "Iteration 21, loss = 0.39332812\n",
      "Iteration 22, loss = 0.50164186\n",
      "Iteration 23, loss = 0.40300736\n",
      "Iteration 24, loss = 0.56552587\n",
      "Iteration 25, loss = 0.37556964\n",
      "Iteration 26, loss = 0.32189681\n",
      "Iteration 27, loss = 0.31562341\n",
      "Iteration 28, loss = 0.31532908\n",
      "Iteration 29, loss = 0.23480127\n",
      "Iteration 30, loss = 0.24835452\n",
      "Iteration 31, loss = 0.24977234\n",
      "Iteration 32, loss = 0.29315262\n",
      "Iteration 33, loss = 0.26921602\n",
      "Iteration 34, loss = 0.21268546\n",
      "Iteration 35, loss = 0.20824452\n",
      "Iteration 36, loss = 0.18438731\n",
      "Iteration 37, loss = 0.16064311\n",
      "Iteration 38, loss = 0.18667431\n",
      "Iteration 39, loss = 0.16933158\n",
      "Iteration 40, loss = 0.12806568\n",
      "Iteration 41, loss = 0.12413012\n",
      "Iteration 42, loss = 0.18100607\n",
      "Iteration 43, loss = 0.14086655\n",
      "Iteration 44, loss = 0.27893044\n",
      "Iteration 45, loss = 0.14540996\n",
      "Iteration 46, loss = 0.11533287\n",
      "Iteration 47, loss = 0.09201425\n",
      "Iteration 48, loss = 0.09659718\n",
      "Iteration 49, loss = 0.11529847\n",
      "Iteration 50, loss = 0.08297693\n",
      "Iteration 51, loss = 0.07168361\n",
      "Iteration 52, loss = 0.07687545\n",
      "Iteration 53, loss = 0.09827778\n",
      "Iteration 54, loss = 0.06125479\n",
      "Iteration 55, loss = 0.06992901\n",
      "Iteration 56, loss = 0.06506363\n",
      "Iteration 57, loss = 0.05351558\n",
      "Iteration 58, loss = 0.04979142\n",
      "Iteration 59, loss = 0.05242293\n",
      "Iteration 60, loss = 0.04424726\n",
      "Iteration 61, loss = 0.04380737\n",
      "Iteration 62, loss = 0.04515066\n",
      "Iteration 63, loss = 0.09553769\n",
      "Iteration 64, loss = 0.06368351\n",
      "Iteration 65, loss = 0.04555620\n",
      "Iteration 66, loss = 0.04404327\n",
      "Iteration 67, loss = 0.08241646\n",
      "Iteration 68, loss = 0.03309176\n",
      "Iteration 69, loss = 0.03157007\n",
      "Iteration 70, loss = 0.03064250\n",
      "Iteration 71, loss = 0.02836937\n",
      "Iteration 72, loss = 0.02987146\n",
      "Iteration 73, loss = 0.02694529\n",
      "Iteration 74, loss = 0.02498028\n",
      "Iteration 75, loss = 0.02446376\n",
      "Iteration 76, loss = 0.02389211\n",
      "Iteration 77, loss = 0.02295492\n",
      "Iteration 78, loss = 0.02235744\n",
      "Iteration 79, loss = 0.02306246\n",
      "Iteration 80, loss = 0.02128903\n",
      "Iteration 81, loss = 0.02077753\n",
      "Iteration 82, loss = 0.02093266\n",
      "Iteration 83, loss = 0.02196372\n",
      "Iteration 84, loss = 0.01985117\n",
      "Iteration 85, loss = 0.01893298\n",
      "Iteration 86, loss = 0.01810640\n",
      "Iteration 87, loss = 0.01813750\n",
      "Iteration 88, loss = 0.01836417\n",
      "Iteration 89, loss = 0.01716305\n",
      "Iteration 90, loss = 0.01716724\n",
      "Iteration 91, loss = 0.01852152\n",
      "Iteration 92, loss = 0.01630892\n",
      "Iteration 93, loss = 0.01612521\n",
      "Iteration 94, loss = 0.01568293\n",
      "Iteration 95, loss = 0.01525088\n",
      "Iteration 96, loss = 0.01508114\n",
      "Iteration 97, loss = 0.01516405\n",
      "Iteration 98, loss = 0.01474870\n",
      "Iteration 99, loss = 0.01435476\n",
      "Iteration 100, loss = 0.01428490\n",
      "Iteration 101, loss = 0.01569743\n",
      "Iteration 102, loss = 0.01385114\n",
      "Iteration 103, loss = 0.01406339\n",
      "Iteration 104, loss = 0.01356708\n",
      "Iteration 105, loss = 0.01315104\n",
      "Iteration 106, loss = 0.01306588\n",
      "Iteration 107, loss = 0.01329917\n",
      "Iteration 108, loss = 0.01247356\n",
      "Iteration 109, loss = 0.01243953\n",
      "Iteration 110, loss = 0.01268274\n",
      "Iteration 111, loss = 0.01252530\n",
      "Iteration 112, loss = 0.01186167\n",
      "Iteration 113, loss = 0.01180203\n",
      "Iteration 114, loss = 0.01156881\n",
      "Iteration 115, loss = 0.01136971\n",
      "Iteration 116, loss = 0.01141117\n",
      "Iteration 117, loss = 0.01160377\n",
      "Iteration 118, loss = 0.01103096\n",
      "Iteration 119, loss = 0.01084053\n",
      "Iteration 120, loss = 0.01077911\n",
      "Iteration 121, loss = 0.01061151\n",
      "Iteration 122, loss = 0.01054576\n",
      "Iteration 123, loss = 0.01047284\n",
      "Iteration 124, loss = 0.01036646\n",
      "Iteration 125, loss = 0.01019974\n",
      "Iteration 126, loss = 0.01015796\n",
      "Iteration 127, loss = 0.01006221\n",
      "Iteration 128, loss = 0.00993291\n",
      "Iteration 129, loss = 0.00983327\n",
      "Iteration 130, loss = 0.00969080\n",
      "Iteration 131, loss = 0.00964691\n",
      "Iteration 132, loss = 0.00958013\n",
      "Iteration 133, loss = 0.00941851\n",
      "Iteration 134, loss = 0.00938185\n",
      "Iteration 135, loss = 0.00931585\n",
      "Iteration 136, loss = 0.00949183\n",
      "Iteration 137, loss = 0.00930012\n",
      "Iteration 138, loss = 0.00904012\n",
      "Iteration 139, loss = 0.00894920\n",
      "Iteration 140, loss = 0.00884729\n",
      "Iteration 141, loss = 0.00877317\n",
      "Iteration 142, loss = 0.00866390\n",
      "Iteration 143, loss = 0.00857870\n",
      "Iteration 144, loss = 0.00850774\n",
      "Iteration 145, loss = 0.00845462\n",
      "Iteration 146, loss = 0.00845607\n",
      "Iteration 147, loss = 0.00839091\n",
      "Iteration 148, loss = 0.00829753\n",
      "Iteration 149, loss = 0.00822031\n",
      "Iteration 150, loss = 0.00810185\n",
      "Iteration 151, loss = 0.00805066\n",
      "Iteration 152, loss = 0.00799027\n",
      "Iteration 153, loss = 0.00797513\n",
      "Iteration 154, loss = 0.00787928\n",
      "Iteration 155, loss = 0.00785999\n",
      "Iteration 156, loss = 0.00775500\n",
      "Iteration 157, loss = 0.00769920\n",
      "Iteration 158, loss = 0.00763002\n",
      "Iteration 159, loss = 0.00758069\n",
      "Iteration 160, loss = 0.00748919\n",
      "Iteration 161, loss = 0.00744781\n",
      "Iteration 162, loss = 0.00740665\n",
      "Iteration 163, loss = 0.00737829\n",
      "Iteration 164, loss = 0.00732712\n",
      "Iteration 165, loss = 0.00728080\n",
      "Iteration 166, loss = 0.00720555\n",
      "Iteration 167, loss = 0.00713991\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 2.36036436\n",
      "Iteration 2, loss = 2.26304017\n",
      "Iteration 3, loss = 2.14119518\n",
      "Iteration 4, loss = 1.94761744\n",
      "Iteration 5, loss = 1.54878560\n",
      "Iteration 6, loss = 1.20786289\n",
      "Iteration 7, loss = 1.06171098\n",
      "Iteration 8, loss = 1.00902245\n",
      "Iteration 9, loss = 0.94383599\n",
      "Iteration 10, loss = 0.87150579\n",
      "Iteration 11, loss = 0.86611721\n",
      "Iteration 12, loss = 0.82449670\n",
      "Iteration 13, loss = 0.77448744\n",
      "Iteration 14, loss = 0.76040857\n",
      "Iteration 15, loss = 0.70697432\n",
      "Iteration 16, loss = 0.69891901\n",
      "Iteration 17, loss = 0.67114233\n",
      "Iteration 18, loss = 0.64365702\n",
      "Iteration 19, loss = 0.64383497\n",
      "Iteration 20, loss = 0.59989049\n",
      "Iteration 21, loss = 0.59294236\n",
      "Iteration 22, loss = 0.57385654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 23, loss = 0.56395070\n",
      "Iteration 24, loss = 0.56110262\n",
      "Iteration 25, loss = 0.51771178\n",
      "Iteration 26, loss = 0.50521061\n",
      "Iteration 27, loss = 0.55078584\n",
      "Iteration 28, loss = 0.54097161\n",
      "Iteration 29, loss = 0.46276658\n",
      "Iteration 30, loss = 0.50114068\n",
      "Iteration 31, loss = 0.44299635\n",
      "Iteration 32, loss = 0.43028733\n",
      "Iteration 33, loss = 0.42609010\n",
      "Iteration 34, loss = 0.41145286\n",
      "Iteration 35, loss = 0.41454105\n",
      "Iteration 36, loss = 0.38999480\n",
      "Iteration 37, loss = 0.37736586\n",
      "Iteration 38, loss = 0.37070580\n",
      "Iteration 39, loss = 0.36707294\n",
      "Iteration 40, loss = 0.36395652\n",
      "Iteration 41, loss = 0.35293732\n",
      "Iteration 42, loss = 0.35278013\n",
      "Iteration 43, loss = 0.35682875\n",
      "Iteration 44, loss = 0.32660088\n",
      "Iteration 45, loss = 0.31267225\n",
      "Iteration 46, loss = 0.31188681\n",
      "Iteration 47, loss = 0.29986265\n",
      "Iteration 48, loss = 0.29300541\n",
      "Iteration 49, loss = 0.29575641\n",
      "Iteration 50, loss = 0.28321070\n",
      "Iteration 51, loss = 0.27883265\n",
      "Iteration 52, loss = 0.27114636\n",
      "Iteration 53, loss = 0.27127013\n",
      "Iteration 54, loss = 0.26535615\n",
      "Iteration 55, loss = 0.26581901\n",
      "Iteration 56, loss = 0.25047468\n",
      "Iteration 57, loss = 0.26070921\n",
      "Iteration 58, loss = 0.29773446\n",
      "Iteration 59, loss = 0.25888547\n",
      "Iteration 60, loss = 0.24331736\n",
      "Iteration 61, loss = 0.22839679\n",
      "Iteration 62, loss = 0.23215456\n",
      "Iteration 63, loss = 0.23153779\n",
      "Iteration 64, loss = 0.21521501\n",
      "Iteration 65, loss = 0.21587384\n",
      "Iteration 66, loss = 0.22674114\n",
      "Iteration 67, loss = 0.20605726\n",
      "Iteration 68, loss = 0.20561363\n",
      "Iteration 69, loss = 0.20027581\n",
      "Iteration 70, loss = 0.19279040\n",
      "Iteration 71, loss = 0.18526074\n",
      "Iteration 72, loss = 0.18112622\n",
      "Iteration 73, loss = 0.17988553\n",
      "Iteration 74, loss = 0.17801897\n",
      "Iteration 75, loss = 0.16978896\n",
      "Iteration 76, loss = 0.16584274\n",
      "Iteration 77, loss = 0.19217857\n",
      "Iteration 78, loss = 0.16259663\n",
      "Iteration 79, loss = 0.16265965\n",
      "Iteration 80, loss = 0.16381556\n",
      "Iteration 81, loss = 0.16092221\n",
      "Iteration 82, loss = 0.15772603\n",
      "Iteration 83, loss = 0.15081417\n",
      "Iteration 84, loss = 0.17356102\n",
      "Iteration 85, loss = 0.15712784\n",
      "Iteration 86, loss = 0.13927351\n",
      "Iteration 87, loss = 0.14047905\n",
      "Iteration 88, loss = 0.16735357\n",
      "Iteration 89, loss = 0.18721652\n",
      "Iteration 90, loss = 0.20015379\n",
      "Iteration 91, loss = 0.13138752\n",
      "Iteration 92, loss = 0.13384541\n",
      "Iteration 93, loss = 0.13371143\n",
      "Iteration 94, loss = 0.12145521\n",
      "Iteration 95, loss = 0.13493274\n",
      "Iteration 96, loss = 0.12921492\n",
      "Iteration 97, loss = 0.11946208\n",
      "Iteration 98, loss = 0.11537489\n",
      "Iteration 99, loss = 0.11248862\n",
      "Iteration 100, loss = 0.11566801\n",
      "Iteration 101, loss = 0.10923338\n",
      "Iteration 102, loss = 0.11100986\n",
      "Iteration 103, loss = 0.10283629\n",
      "Iteration 104, loss = 0.13354756\n",
      "Iteration 105, loss = 0.10670689\n",
      "Iteration 106, loss = 0.10341046\n",
      "Iteration 107, loss = 0.09795954\n",
      "Iteration 108, loss = 0.09949317\n",
      "Iteration 109, loss = 0.09252368\n",
      "Iteration 110, loss = 0.09813976\n",
      "Iteration 111, loss = 0.09397045\n",
      "Iteration 112, loss = 0.09136672\n",
      "Iteration 113, loss = 0.08743758\n",
      "Iteration 114, loss = 0.08803959\n",
      "Iteration 115, loss = 0.08514497\n",
      "Iteration 116, loss = 0.08010397\n",
      "Iteration 117, loss = 0.08696050\n",
      "Iteration 118, loss = 0.07874772\n",
      "Iteration 119, loss = 0.08328598\n",
      "Iteration 120, loss = 0.08296532\n",
      "Iteration 121, loss = 0.07627719\n",
      "Iteration 122, loss = 0.07767964\n",
      "Iteration 123, loss = 0.08397674\n",
      "Iteration 124, loss = 0.07362758\n",
      "Iteration 125, loss = 0.07133009\n",
      "Iteration 126, loss = 0.07163436\n",
      "Iteration 127, loss = 0.06989712\n",
      "Iteration 128, loss = 0.06867834\n",
      "Iteration 129, loss = 0.06825400\n",
      "Iteration 130, loss = 0.06765371\n",
      "Iteration 131, loss = 0.06979714\n",
      "Iteration 132, loss = 0.07037042\n",
      "Iteration 133, loss = 0.06728919\n",
      "Iteration 134, loss = 0.06525536\n",
      "Iteration 135, loss = 0.06566343\n",
      "Iteration 136, loss = 0.06839153\n",
      "Iteration 137, loss = 0.06909766\n",
      "Iteration 138, loss = 0.06472651\n",
      "Iteration 139, loss = 0.06490897\n",
      "Iteration 140, loss = 0.06272440\n",
      "Iteration 141, loss = 0.07024512\n",
      "Iteration 142, loss = 0.06166204\n",
      "Iteration 143, loss = 0.06054461\n",
      "Iteration 144, loss = 0.05963421\n",
      "Iteration 145, loss = 0.06156252\n",
      "Iteration 146, loss = 0.05808282\n",
      "Iteration 147, loss = 0.05977893\n",
      "Iteration 148, loss = 0.05755938\n",
      "Iteration 149, loss = 0.05717985\n",
      "Iteration 150, loss = 0.05579066\n",
      "Iteration 151, loss = 0.05669049\n",
      "Iteration 152, loss = 0.05650677\n",
      "Iteration 153, loss = 0.05578030\n",
      "Iteration 154, loss = 0.05621108\n",
      "Iteration 155, loss = 0.05402908\n",
      "Iteration 156, loss = 0.05406747\n",
      "Iteration 157, loss = 0.05719091\n",
      "Iteration 158, loss = 0.05514137\n",
      "Iteration 159, loss = 0.05278030\n",
      "Iteration 160, loss = 0.05325837\n",
      "Iteration 161, loss = 0.05171118\n",
      "Iteration 162, loss = 0.05113989\n",
      "Iteration 163, loss = 0.05079262\n",
      "Iteration 164, loss = 0.05193729\n",
      "Iteration 165, loss = 0.05189170\n",
      "Iteration 166, loss = 0.04987032\n",
      "Iteration 167, loss = 0.05003972\n",
      "Iteration 168, loss = 0.05058923\n",
      "Iteration 169, loss = 0.04866639\n",
      "Iteration 170, loss = 0.05039365\n",
      "Iteration 171, loss = 0.04883799\n",
      "Iteration 172, loss = 0.05051025\n",
      "Iteration 173, loss = 0.05097867\n",
      "Iteration 174, loss = 0.04757447\n",
      "Iteration 175, loss = 0.04686382\n",
      "Iteration 176, loss = 0.04646635\n",
      "Iteration 177, loss = 0.04678829\n",
      "Iteration 178, loss = 0.04587448\n",
      "Iteration 179, loss = 0.04527326\n",
      "Iteration 180, loss = 0.04572950\n",
      "Iteration 181, loss = 0.04473335\n",
      "Iteration 182, loss = 0.04509721\n",
      "Iteration 183, loss = 0.04468029\n",
      "Iteration 184, loss = 0.04422335\n",
      "Iteration 185, loss = 0.04327096\n",
      "Iteration 186, loss = 0.04306168\n",
      "Iteration 187, loss = 0.04302637\n",
      "Iteration 188, loss = 0.04583133\n",
      "Iteration 189, loss = 0.04289519\n",
      "Iteration 190, loss = 0.04514125\n",
      "Iteration 191, loss = 0.04186800\n",
      "Iteration 192, loss = 0.04128424\n",
      "Iteration 193, loss = 0.04214062\n",
      "Iteration 194, loss = 0.04364199\n",
      "Iteration 195, loss = 0.04149128\n",
      "Iteration 196, loss = 0.04220834\n",
      "Iteration 197, loss = 0.04126868\n",
      "Iteration 198, loss = 0.04018637\n",
      "Iteration 199, loss = 0.03991211\n",
      "Iteration 200, loss = 0.03972656\n",
      "Iteration 201, loss = 0.04010478\n",
      "Iteration 202, loss = 0.03877092\n",
      "Iteration 203, loss = 0.04006816\n",
      "Iteration 204, loss = 0.03906660\n",
      "Iteration 205, loss = 0.03951748\n",
      "Iteration 206, loss = 0.04311618\n",
      "Iteration 207, loss = 0.03784107\n",
      "Iteration 208, loss = 0.03748282\n",
      "Iteration 209, loss = 0.03809389\n",
      "Iteration 210, loss = 0.03718744\n",
      "Iteration 211, loss = 0.03769546\n",
      "Iteration 212, loss = 0.03792375\n",
      "Iteration 213, loss = 0.03690494\n",
      "Iteration 214, loss = 0.03639516\n",
      "Iteration 215, loss = 0.03675356\n",
      "Iteration 216, loss = 0.03566107\n",
      "Iteration 217, loss = 0.03553892\n",
      "Iteration 218, loss = 0.03492958\n",
      "Iteration 219, loss = 0.03494291\n",
      "Iteration 220, loss = 0.03492271\n",
      "Iteration 221, loss = 0.03474147\n",
      "Iteration 222, loss = 0.03458026\n",
      "Iteration 223, loss = 0.03380629\n",
      "Iteration 224, loss = 0.03386547\n",
      "Iteration 225, loss = 0.03369320\n",
      "Iteration 226, loss = 0.03370575\n",
      "Iteration 227, loss = 0.03352875\n",
      "Iteration 228, loss = 0.03471296\n",
      "Iteration 229, loss = 0.04057421\n",
      "Iteration 230, loss = 0.03327969\n",
      "Iteration 231, loss = 0.03270448\n",
      "Iteration 232, loss = 0.03338348\n",
      "Iteration 233, loss = 0.03261095\n",
      "Iteration 234, loss = 0.03168736\n",
      "Iteration 235, loss = 0.03166236\n",
      "Iteration 236, loss = 0.03158026\n",
      "Iteration 237, loss = 0.03159992\n",
      "Iteration 238, loss = 0.03060048\n",
      "Iteration 239, loss = 0.03047920\n",
      "Iteration 240, loss = 0.03080722\n",
      "Iteration 241, loss = 0.03116917\n",
      "Iteration 242, loss = 0.03021313\n",
      "Iteration 243, loss = 0.03006454\n",
      "Iteration 244, loss = 0.03497495\n",
      "Iteration 245, loss = 0.03066927\n",
      "Iteration 246, loss = 0.03025790\n",
      "Iteration 247, loss = 0.02959987\n",
      "Iteration 248, loss = 0.02906497\n",
      "Iteration 249, loss = 0.02846978\n",
      "Iteration 250, loss = 0.02892032\n",
      "Iteration 1, loss = 2.38969684\n",
      "Iteration 2, loss = 2.06299902\n",
      "Iteration 3, loss = 1.87699590\n",
      "Iteration 4, loss = 1.58627004\n",
      "Iteration 5, loss = 1.18339514\n",
      "Iteration 6, loss = 1.02390757\n",
      "Iteration 7, loss = 0.90192693\n",
      "Iteration 8, loss = 0.76708838\n",
      "Iteration 9, loss = 0.69932879\n",
      "Iteration 10, loss = 0.69704869\n",
      "Iteration 11, loss = 0.65453032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/giulia/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (250) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 12, loss = 0.56939478\n",
      "Iteration 13, loss = 0.56707561\n",
      "Iteration 14, loss = 0.50768655\n",
      "Iteration 15, loss = 0.56818070\n",
      "Iteration 16, loss = 0.47001224\n",
      "Iteration 17, loss = 0.41470299\n",
      "Iteration 18, loss = 0.36982375\n",
      "Iteration 19, loss = 0.36364420\n",
      "Iteration 20, loss = 0.37355661\n",
      "Iteration 21, loss = 0.31232728\n",
      "Iteration 22, loss = 0.30384215\n",
      "Iteration 23, loss = 0.30460874\n",
      "Iteration 24, loss = 0.27929509\n",
      "Iteration 25, loss = 0.29073750\n",
      "Iteration 26, loss = 0.43877987\n",
      "Iteration 27, loss = 0.25692843\n",
      "Iteration 28, loss = 0.21911601\n",
      "Iteration 29, loss = 0.22232179\n",
      "Iteration 30, loss = 0.20280811\n",
      "Iteration 31, loss = 0.19585110\n",
      "Iteration 32, loss = 0.30462750\n",
      "Iteration 33, loss = 0.21642017\n",
      "Iteration 34, loss = 0.16793187\n",
      "Iteration 35, loss = 0.14440923\n",
      "Iteration 36, loss = 0.22301622\n",
      "Iteration 37, loss = 0.14383901\n",
      "Iteration 38, loss = 0.15610318\n",
      "Iteration 39, loss = 0.25073911\n",
      "Iteration 40, loss = 0.12615164\n",
      "Iteration 41, loss = 0.18173857\n",
      "Iteration 42, loss = 0.12984941\n",
      "Iteration 43, loss = 0.09260218\n",
      "Iteration 44, loss = 0.09446088\n",
      "Iteration 45, loss = 0.08998724\n",
      "Iteration 46, loss = 0.08421735\n",
      "Iteration 47, loss = 0.09429581\n",
      "Iteration 48, loss = 0.07558892\n",
      "Iteration 49, loss = 0.07186732\n",
      "Iteration 50, loss = 0.05422758\n",
      "Iteration 51, loss = 0.04885774\n",
      "Iteration 52, loss = 0.04682621\n",
      "Iteration 53, loss = 0.04478192\n",
      "Iteration 54, loss = 0.04539066\n",
      "Iteration 55, loss = 0.04995565\n",
      "Iteration 56, loss = 0.04863537\n",
      "Iteration 57, loss = 0.04021195\n",
      "Iteration 58, loss = 0.03908852\n",
      "Iteration 59, loss = 0.03602201\n",
      "Iteration 60, loss = 0.03261280\n",
      "Iteration 61, loss = 0.02910092\n",
      "Iteration 62, loss = 0.02768274\n",
      "Iteration 63, loss = 0.02649504\n",
      "Iteration 64, loss = 0.02388125\n",
      "Iteration 65, loss = 0.02549836\n",
      "Iteration 66, loss = 0.02183243\n",
      "Iteration 67, loss = 0.02104723\n",
      "Iteration 68, loss = 0.02180368\n",
      "Iteration 69, loss = 0.01986156\n",
      "Iteration 70, loss = 0.01977245\n",
      "Iteration 71, loss = 0.01916768\n",
      "Iteration 72, loss = 0.01780699\n",
      "Iteration 73, loss = 0.01707178\n",
      "Iteration 74, loss = 0.01658511\n",
      "Iteration 75, loss = 0.01630094\n",
      "Iteration 76, loss = 0.01552208\n",
      "Iteration 77, loss = 0.01491164\n",
      "Iteration 78, loss = 0.01460300\n",
      "Iteration 79, loss = 0.01392327\n",
      "Iteration 80, loss = 0.01414975\n",
      "Iteration 81, loss = 0.01363565\n",
      "Iteration 82, loss = 0.01350206\n",
      "Iteration 83, loss = 0.01288344\n",
      "Iteration 84, loss = 0.01261049\n",
      "Iteration 85, loss = 0.01222848\n",
      "Iteration 86, loss = 0.01172143\n",
      "Iteration 87, loss = 0.01158798\n",
      "Iteration 88, loss = 0.01143037\n",
      "Iteration 89, loss = 0.01100383\n",
      "Iteration 90, loss = 0.01091015\n",
      "Iteration 91, loss = 0.01051009\n",
      "Iteration 92, loss = 0.01049478\n",
      "Iteration 93, loss = 0.01033021\n",
      "Iteration 94, loss = 0.00988898\n",
      "Iteration 95, loss = 0.00967590\n",
      "Iteration 96, loss = 0.00946075\n",
      "Iteration 97, loss = 0.00956128\n",
      "Iteration 98, loss = 0.00919972\n",
      "Iteration 99, loss = 0.00920475\n",
      "Iteration 100, loss = 0.00883772\n",
      "Iteration 101, loss = 0.00866655\n",
      "Iteration 102, loss = 0.00852185\n",
      "Iteration 103, loss = 0.00825618\n",
      "Iteration 104, loss = 0.00817827\n",
      "Iteration 105, loss = 0.00796142\n",
      "Iteration 106, loss = 0.00795186\n",
      "Iteration 107, loss = 0.00783475\n",
      "Iteration 108, loss = 0.00773380\n",
      "Iteration 109, loss = 0.00796914\n",
      "Iteration 110, loss = 0.00739053\n",
      "Iteration 111, loss = 0.00723117\n",
      "Iteration 112, loss = 0.00706164\n",
      "Iteration 113, loss = 0.00697602\n",
      "Iteration 114, loss = 0.00685318\n",
      "Iteration 115, loss = 0.00687017\n",
      "Iteration 116, loss = 0.00668378\n",
      "Iteration 117, loss = 0.00657953\n",
      "Iteration 118, loss = 0.00648809\n",
      "Iteration 119, loss = 0.00636896\n",
      "Iteration 120, loss = 0.00627950\n",
      "Iteration 121, loss = 0.00622035\n",
      "Iteration 122, loss = 0.00616637\n",
      "Iteration 123, loss = 0.00604607\n",
      "Iteration 124, loss = 0.00597915\n",
      "Iteration 125, loss = 0.00583740\n",
      "Iteration 126, loss = 0.00582909\n",
      "Iteration 127, loss = 0.00575666\n",
      "Iteration 128, loss = 0.00563551\n",
      "Iteration 129, loss = 0.00561006\n",
      "Iteration 130, loss = 0.00556814\n",
      "Iteration 131, loss = 0.00539751\n",
      "Iteration 132, loss = 0.00538780\n",
      "Iteration 133, loss = 0.00533392\n",
      "Iteration 134, loss = 0.00525345\n",
      "Iteration 135, loss = 0.00514965\n",
      "Iteration 136, loss = 0.00513415\n",
      "Iteration 137, loss = 0.00503722\n",
      "Iteration 138, loss = 0.00501221\n",
      "Iteration 139, loss = 0.00492100\n",
      "Iteration 140, loss = 0.00487584\n",
      "Iteration 141, loss = 0.00485742\n",
      "Iteration 142, loss = 0.00475425\n",
      "Iteration 143, loss = 0.00472349\n",
      "Iteration 144, loss = 0.00467189\n",
      "Iteration 145, loss = 0.00462359\n",
      "Iteration 146, loss = 0.00456889\n",
      "Iteration 147, loss = 0.00454349\n",
      "Iteration 148, loss = 0.00446742\n",
      "Iteration 149, loss = 0.00441438\n",
      "Iteration 150, loss = 0.00435727\n",
      "Iteration 151, loss = 0.00430995\n",
      "Iteration 152, loss = 0.00426721\n",
      "Iteration 153, loss = 0.00426879\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 2.38822468\n",
      "Iteration 2, loss = 2.06759432\n",
      "Iteration 3, loss = 1.77512427\n",
      "Iteration 4, loss = 1.45604560\n",
      "Iteration 5, loss = 1.15033952\n",
      "Iteration 6, loss = 0.95712653\n",
      "Iteration 7, loss = 1.45933803\n",
      "Iteration 8, loss = 0.91778277\n",
      "Iteration 9, loss = 0.80007746\n",
      "Iteration 10, loss = 0.73813810\n",
      "Iteration 11, loss = 0.66040930\n",
      "Iteration 12, loss = 0.60843965\n",
      "Iteration 13, loss = 0.62776945\n",
      "Iteration 14, loss = 0.54706408\n",
      "Iteration 15, loss = 0.67550703\n",
      "Iteration 16, loss = 0.53620351\n",
      "Iteration 17, loss = 0.48912452\n",
      "Iteration 18, loss = 0.47120403\n",
      "Iteration 19, loss = 0.43612737\n",
      "Iteration 20, loss = 0.46097164\n",
      "Iteration 21, loss = 0.40012475\n",
      "Iteration 22, loss = 0.36356569\n",
      "Iteration 23, loss = 0.35412719\n",
      "Iteration 24, loss = 0.39393243\n",
      "Iteration 25, loss = 0.34158926\n",
      "Iteration 26, loss = 0.30773383\n",
      "Iteration 27, loss = 0.29085423\n",
      "Iteration 28, loss = 0.27005600\n",
      "Iteration 29, loss = 0.28254062\n",
      "Iteration 30, loss = 0.47331742\n",
      "Iteration 31, loss = 0.32233120\n",
      "Iteration 32, loss = 0.28692724\n",
      "Iteration 33, loss = 0.34065197\n",
      "Iteration 34, loss = 0.23861365\n",
      "Iteration 35, loss = 0.21866653\n",
      "Iteration 36, loss = 0.19418583\n",
      "Iteration 37, loss = 0.24635859\n",
      "Iteration 38, loss = 0.18068261\n",
      "Iteration 39, loss = 0.17964232\n",
      "Iteration 40, loss = 0.40285518\n",
      "Iteration 41, loss = 0.19478295\n",
      "Iteration 42, loss = 0.16204124\n",
      "Iteration 43, loss = 0.13841250\n",
      "Iteration 44, loss = 0.14042702\n",
      "Iteration 45, loss = 0.17645948\n",
      "Iteration 46, loss = 0.14111941\n",
      "Iteration 47, loss = 0.12073824\n",
      "Iteration 48, loss = 0.11216398\n",
      "Iteration 49, loss = 0.11017119\n",
      "Iteration 50, loss = 0.09099176\n",
      "Iteration 51, loss = 0.08261780\n",
      "Iteration 52, loss = 0.08926623\n",
      "Iteration 53, loss = 0.12924419\n",
      "Iteration 54, loss = 0.10522041\n",
      "Iteration 55, loss = 0.07992003\n",
      "Iteration 56, loss = 0.09095768\n",
      "Iteration 57, loss = 0.06324653\n",
      "Iteration 58, loss = 0.06286454\n",
      "Iteration 59, loss = 0.05740286\n",
      "Iteration 60, loss = 0.05606234\n",
      "Iteration 61, loss = 0.05130548\n",
      "Iteration 62, loss = 0.04852878\n",
      "Iteration 63, loss = 0.04633537\n",
      "Iteration 64, loss = 0.04202444\n",
      "Iteration 65, loss = 0.04191401\n",
      "Iteration 66, loss = 0.03675876\n",
      "Iteration 67, loss = 0.03740187\n",
      "Iteration 68, loss = 0.04353764\n",
      "Iteration 69, loss = 0.04423278\n",
      "Iteration 70, loss = 0.04313634\n",
      "Iteration 71, loss = 0.03094280\n",
      "Iteration 72, loss = 0.03216882\n",
      "Iteration 73, loss = 0.02969986\n",
      "Iteration 74, loss = 0.02600281\n",
      "Iteration 75, loss = 0.02530016\n",
      "Iteration 76, loss = 0.02335732\n",
      "Iteration 77, loss = 0.02349521\n",
      "Iteration 78, loss = 0.02249880\n",
      "Iteration 79, loss = 0.02187283\n",
      "Iteration 80, loss = 0.02149498\n",
      "Iteration 81, loss = 0.02011576\n",
      "Iteration 82, loss = 0.01969172\n",
      "Iteration 83, loss = 0.01859589\n",
      "Iteration 84, loss = 0.01794868\n",
      "Iteration 85, loss = 0.01864225\n",
      "Iteration 86, loss = 0.01755267\n",
      "Iteration 87, loss = 0.01640907\n",
      "Iteration 88, loss = 0.01611610\n",
      "Iteration 89, loss = 0.01645609\n",
      "Iteration 90, loss = 0.01546309\n",
      "Iteration 91, loss = 0.01493258\n",
      "Iteration 92, loss = 0.01448213\n",
      "Iteration 93, loss = 0.01399453\n",
      "Iteration 94, loss = 0.01383139\n",
      "Iteration 95, loss = 0.01326587\n",
      "Iteration 96, loss = 0.01310930\n",
      "Iteration 97, loss = 0.01296940\n",
      "Iteration 98, loss = 0.01241194\n",
      "Iteration 99, loss = 0.01200750\n",
      "Iteration 100, loss = 0.01180606\n",
      "Iteration 101, loss = 0.01151164\n",
      "Iteration 102, loss = 0.01127400\n",
      "Iteration 103, loss = 0.01111267\n",
      "Iteration 104, loss = 0.01067201\n",
      "Iteration 105, loss = 0.01060869\n",
      "Iteration 106, loss = 0.01033656\n",
      "Iteration 107, loss = 0.01008851\n",
      "Iteration 108, loss = 0.00996881\n",
      "Iteration 109, loss = 0.01006566\n",
      "Iteration 110, loss = 0.01007110\n",
      "Iteration 111, loss = 0.00978894\n",
      "Iteration 112, loss = 0.00917922\n",
      "Iteration 113, loss = 0.00914542\n",
      "Iteration 114, loss = 0.00869225\n",
      "Iteration 115, loss = 0.00858060\n",
      "Iteration 116, loss = 0.00852996\n",
      "Iteration 117, loss = 0.00851954\n",
      "Iteration 118, loss = 0.00810161\n",
      "Iteration 119, loss = 0.00806817\n",
      "Iteration 120, loss = 0.00790765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 121, loss = 0.00779510\n",
      "Iteration 122, loss = 0.00758270\n",
      "Iteration 123, loss = 0.00741446\n",
      "Iteration 124, loss = 0.00729630\n",
      "Iteration 125, loss = 0.00724013\n",
      "Iteration 126, loss = 0.00708977\n",
      "Iteration 127, loss = 0.00696009\n",
      "Iteration 128, loss = 0.00688055\n",
      "Iteration 129, loss = 0.00679582\n",
      "Iteration 130, loss = 0.00669981\n",
      "Iteration 131, loss = 0.00660534\n",
      "Iteration 132, loss = 0.00651249\n",
      "Iteration 133, loss = 0.00642489\n",
      "Iteration 134, loss = 0.00626617\n",
      "Iteration 135, loss = 0.00614912\n",
      "Iteration 136, loss = 0.00610972\n",
      "Iteration 137, loss = 0.00606346\n",
      "Iteration 138, loss = 0.00595369\n",
      "Iteration 139, loss = 0.00585179\n",
      "Iteration 140, loss = 0.00576008\n",
      "Iteration 141, loss = 0.00575876\n",
      "Iteration 142, loss = 0.00571438\n",
      "Iteration 143, loss = 0.00554341\n",
      "Iteration 144, loss = 0.00549098\n",
      "Iteration 145, loss = 0.00538984\n",
      "Iteration 146, loss = 0.00531904\n",
      "Iteration 147, loss = 0.00531532\n",
      "Iteration 148, loss = 0.00521927\n",
      "Iteration 149, loss = 0.00522365\n",
      "Iteration 150, loss = 0.00509106\n",
      "Iteration 151, loss = 0.00501599\n",
      "Iteration 152, loss = 0.00496419\n",
      "Iteration 153, loss = 0.00495540\n",
      "Iteration 154, loss = 0.00489442\n",
      "Iteration 155, loss = 0.00483269\n",
      "Iteration 156, loss = 0.00471373\n",
      "Iteration 157, loss = 0.00473900\n",
      "Iteration 158, loss = 0.00466886\n",
      "Iteration 159, loss = 0.00459909\n",
      "Iteration 160, loss = 0.00462302\n",
      "Iteration 161, loss = 0.00451915\n",
      "Iteration 162, loss = 0.00445547\n",
      "Iteration 163, loss = 0.00438365\n",
      "Iteration 164, loss = 0.00437596\n",
      "Iteration 165, loss = 0.00430223\n",
      "Iteration 166, loss = 0.00438701\n",
      "Iteration 167, loss = 0.00421870\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 2.37720767\n",
      "Iteration 2, loss = 2.06878829\n",
      "Iteration 3, loss = 1.88884657\n",
      "Iteration 4, loss = 1.59125899\n",
      "Iteration 5, loss = 1.31271513\n",
      "Iteration 6, loss = 1.05580761\n",
      "Iteration 7, loss = 0.90394036\n",
      "Iteration 8, loss = 0.83084198\n",
      "Iteration 9, loss = 0.78509945\n",
      "Iteration 10, loss = 1.02199743\n",
      "Iteration 11, loss = 0.65473596\n",
      "Iteration 12, loss = 0.62551865\n",
      "Iteration 13, loss = 0.58012437\n",
      "Iteration 14, loss = 0.53539609\n",
      "Iteration 15, loss = 0.49865763\n",
      "Iteration 16, loss = 0.50292075\n",
      "Iteration 17, loss = 0.54055651\n",
      "Iteration 18, loss = 0.42186764\n",
      "Iteration 19, loss = 0.38013447\n",
      "Iteration 20, loss = 0.39644029\n",
      "Iteration 21, loss = 0.32849872\n",
      "Iteration 22, loss = 0.32675633\n",
      "Iteration 23, loss = 0.33988986\n",
      "Iteration 24, loss = 0.29461938\n",
      "Iteration 25, loss = 0.30474025\n",
      "Iteration 26, loss = 0.36170101\n",
      "Iteration 27, loss = 0.23830845\n",
      "Iteration 28, loss = 0.24242977\n",
      "Iteration 29, loss = 0.23807004\n",
      "Iteration 30, loss = 0.21363266\n",
      "Iteration 31, loss = 0.19384890\n",
      "Iteration 32, loss = 0.19828573\n",
      "Iteration 33, loss = 0.16694928\n",
      "Iteration 34, loss = 0.15125428\n",
      "Iteration 35, loss = 0.15846860\n",
      "Iteration 36, loss = 0.17652988\n",
      "Iteration 37, loss = 0.20024494\n",
      "Iteration 38, loss = 0.13338227\n",
      "Iteration 39, loss = 0.15543185\n",
      "Iteration 40, loss = 0.12261616\n",
      "Iteration 41, loss = 0.11241503\n",
      "Iteration 42, loss = 0.10300978\n",
      "Iteration 43, loss = 0.09525512\n",
      "Iteration 44, loss = 0.08438393\n",
      "Iteration 45, loss = 0.08162545\n",
      "Iteration 46, loss = 0.07192045\n",
      "Iteration 47, loss = 0.08977542\n",
      "Iteration 48, loss = 0.60838178\n",
      "Iteration 49, loss = 0.18255251\n",
      "Iteration 50, loss = 0.12920546\n",
      "Iteration 51, loss = 0.08919876\n",
      "Iteration 52, loss = 0.07315029\n",
      "Iteration 53, loss = 0.07139625\n",
      "Iteration 54, loss = 0.07074540\n",
      "Iteration 55, loss = 0.08351512\n",
      "Iteration 56, loss = 0.05663899\n",
      "Iteration 57, loss = 0.07844173\n",
      "Iteration 58, loss = 0.04368256\n",
      "Iteration 59, loss = 0.03903589\n",
      "Iteration 60, loss = 0.03651715\n",
      "Iteration 61, loss = 0.03391477\n",
      "Iteration 62, loss = 0.03241950\n",
      "Iteration 63, loss = 0.03183948\n",
      "Iteration 64, loss = 0.03132029\n",
      "Iteration 65, loss = 0.03151607\n",
      "Iteration 66, loss = 0.02690146\n",
      "Iteration 67, loss = 0.02590725\n",
      "Iteration 68, loss = 0.02493398\n",
      "Iteration 69, loss = 0.02297890\n",
      "Iteration 70, loss = 0.02231143\n",
      "Iteration 71, loss = 0.02239258\n",
      "Iteration 72, loss = 0.02140422\n",
      "Iteration 73, loss = 0.02069188\n",
      "Iteration 74, loss = 0.01964136\n",
      "Iteration 75, loss = 0.01897941\n",
      "Iteration 76, loss = 0.01826920\n",
      "Iteration 77, loss = 0.01789521\n",
      "Iteration 78, loss = 0.01779158\n",
      "Iteration 79, loss = 0.01694069\n",
      "Iteration 80, loss = 0.01636366\n",
      "Iteration 81, loss = 0.01595041\n",
      "Iteration 82, loss = 0.01569778\n",
      "Iteration 83, loss = 0.01499067\n",
      "Iteration 84, loss = 0.01468329\n",
      "Iteration 85, loss = 0.01490912\n",
      "Iteration 86, loss = 0.01414490\n",
      "Iteration 87, loss = 0.01348150\n",
      "Iteration 88, loss = 0.01323451\n",
      "Iteration 89, loss = 0.01314499\n",
      "Iteration 90, loss = 0.01255564\n",
      "Iteration 91, loss = 0.01246700\n",
      "Iteration 92, loss = 0.01218101\n",
      "Iteration 93, loss = 0.01201695\n",
      "Iteration 94, loss = 0.01182462\n",
      "Iteration 95, loss = 0.01139777\n",
      "Iteration 96, loss = 0.01123401\n",
      "Iteration 97, loss = 0.01087083\n",
      "Iteration 98, loss = 0.01056903\n",
      "Iteration 99, loss = 0.01044203\n",
      "Iteration 100, loss = 0.01049126\n",
      "Iteration 101, loss = 0.01005262\n",
      "Iteration 102, loss = 0.01003019\n",
      "Iteration 103, loss = 0.00962830\n",
      "Iteration 104, loss = 0.00943467\n",
      "Iteration 105, loss = 0.00929173\n",
      "Iteration 106, loss = 0.00920794\n",
      "Iteration 107, loss = 0.00906852\n",
      "Iteration 108, loss = 0.00884349\n",
      "Iteration 109, loss = 0.00872962\n",
      "Iteration 110, loss = 0.00854322\n",
      "Iteration 111, loss = 0.00851545\n",
      "Iteration 112, loss = 0.00823333\n",
      "Iteration 113, loss = 0.00817793\n",
      "Iteration 114, loss = 0.00794935\n",
      "Iteration 115, loss = 0.00782924\n",
      "Iteration 116, loss = 0.00773156\n",
      "Iteration 117, loss = 0.00764919\n",
      "Iteration 118, loss = 0.00754408\n",
      "Iteration 119, loss = 0.00744161\n",
      "Iteration 120, loss = 0.00734143\n",
      "Iteration 121, loss = 0.00718141\n",
      "Iteration 122, loss = 0.00704543\n",
      "Iteration 123, loss = 0.00697823\n",
      "Iteration 124, loss = 0.00689065\n",
      "Iteration 125, loss = 0.00684858\n",
      "Iteration 126, loss = 0.00667265\n",
      "Iteration 127, loss = 0.00663068\n",
      "Iteration 128, loss = 0.00649608\n",
      "Iteration 129, loss = 0.00644367\n",
      "Iteration 130, loss = 0.00637045\n",
      "Iteration 131, loss = 0.00627563\n",
      "Iteration 132, loss = 0.00621238\n",
      "Iteration 133, loss = 0.00609697\n",
      "Iteration 134, loss = 0.00604741\n",
      "Iteration 135, loss = 0.00595080\n",
      "Iteration 136, loss = 0.00590238\n",
      "Iteration 137, loss = 0.00585591\n",
      "Iteration 138, loss = 0.00577331\n",
      "Iteration 139, loss = 0.00566648\n",
      "Iteration 140, loss = 0.00562899\n",
      "Iteration 141, loss = 0.00556749\n",
      "Iteration 142, loss = 0.00552007\n",
      "Iteration 143, loss = 0.00541448\n",
      "Iteration 144, loss = 0.00534055\n",
      "Iteration 145, loss = 0.00530043\n",
      "Iteration 146, loss = 0.00521807\n",
      "Iteration 147, loss = 0.00520059\n",
      "Iteration 148, loss = 0.00510640\n",
      "Iteration 149, loss = 0.00508828\n",
      "Iteration 150, loss = 0.00502841\n",
      "Iteration 151, loss = 0.00496206\n",
      "Iteration 152, loss = 0.00490826\n",
      "Iteration 153, loss = 0.00484410\n",
      "Iteration 154, loss = 0.00482395\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 2.39008048\n",
      "Iteration 2, loss = 2.03059457\n",
      "Iteration 3, loss = 1.78649923\n",
      "Iteration 4, loss = 1.61912300\n",
      "Iteration 5, loss = 1.13566725\n",
      "Iteration 6, loss = 0.92443578\n",
      "Iteration 7, loss = 0.82470303\n",
      "Iteration 8, loss = 0.80816283\n",
      "Iteration 9, loss = 0.81964891\n",
      "Iteration 10, loss = 0.92122564\n",
      "Iteration 11, loss = 0.64283186\n",
      "Iteration 12, loss = 0.62497693\n",
      "Iteration 13, loss = 0.58956641\n",
      "Iteration 14, loss = 0.51227977\n",
      "Iteration 15, loss = 0.47450584\n",
      "Iteration 16, loss = 0.57933154\n",
      "Iteration 17, loss = 0.53976871\n",
      "Iteration 18, loss = 0.44523476\n",
      "Iteration 19, loss = 0.41899963\n",
      "Iteration 20, loss = 0.39895089\n",
      "Iteration 21, loss = 0.37426804\n",
      "Iteration 22, loss = 0.36360997\n",
      "Iteration 23, loss = 0.33363409\n",
      "Iteration 24, loss = 0.30587161\n",
      "Iteration 25, loss = 0.29526370\n",
      "Iteration 26, loss = 0.36409278\n",
      "Iteration 27, loss = 0.29389061\n",
      "Iteration 28, loss = 0.22563107\n",
      "Iteration 29, loss = 0.31146982\n",
      "Iteration 30, loss = 0.26070691\n",
      "Iteration 31, loss = 0.19629876\n",
      "Iteration 32, loss = 0.18872901\n",
      "Iteration 33, loss = 0.18062074\n",
      "Iteration 34, loss = 0.35613915\n",
      "Iteration 35, loss = 0.17401939\n",
      "Iteration 36, loss = 0.13990678\n",
      "Iteration 37, loss = 0.13386953\n",
      "Iteration 38, loss = 0.12357989\n",
      "Iteration 39, loss = 0.13061187\n",
      "Iteration 40, loss = 0.56957515\n",
      "Iteration 41, loss = 0.17278454\n",
      "Iteration 42, loss = 0.15140995\n",
      "Iteration 43, loss = 0.19294609\n",
      "Iteration 44, loss = 0.11935709\n",
      "Iteration 45, loss = 0.11432481\n",
      "Iteration 46, loss = 0.18832150\n",
      "Iteration 47, loss = 0.12108340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 48, loss = 0.14866095\n",
      "Iteration 49, loss = 0.09733716\n",
      "Iteration 50, loss = 0.07308870\n",
      "Iteration 51, loss = 0.06367296\n",
      "Iteration 52, loss = 0.06110236\n",
      "Iteration 53, loss = 0.26857033\n",
      "Iteration 54, loss = 0.07074640\n",
      "Iteration 55, loss = 0.06854285\n",
      "Iteration 56, loss = 0.05761112\n",
      "Iteration 57, loss = 0.18872029\n",
      "Iteration 58, loss = 0.16354243\n",
      "Iteration 59, loss = 0.05893290\n",
      "Iteration 60, loss = 0.06447639\n",
      "Iteration 61, loss = 0.04150231\n",
      "Iteration 62, loss = 0.03529994\n",
      "Iteration 63, loss = 0.02874468\n",
      "Iteration 64, loss = 0.02807695\n",
      "Iteration 65, loss = 0.02734076\n",
      "Iteration 66, loss = 0.02430271\n",
      "Iteration 67, loss = 0.02394973\n",
      "Iteration 68, loss = 0.02179135\n",
      "Iteration 69, loss = 0.02328081\n",
      "Iteration 70, loss = 0.01886615\n",
      "Iteration 71, loss = 0.01777300\n",
      "Iteration 72, loss = 0.01733027\n",
      "Iteration 73, loss = 0.01638286\n",
      "Iteration 74, loss = 0.01628020\n",
      "Iteration 75, loss = 0.01572539\n",
      "Iteration 76, loss = 0.01452519\n",
      "Iteration 77, loss = 0.01415941\n",
      "Iteration 78, loss = 0.01335846\n",
      "Iteration 79, loss = 0.01300305\n",
      "Iteration 80, loss = 0.01263218\n",
      "Iteration 81, loss = 0.01236027\n",
      "Iteration 82, loss = 0.01245662\n",
      "Iteration 83, loss = 0.01136657\n",
      "Iteration 84, loss = 0.01134009\n",
      "Iteration 85, loss = 0.01128898\n",
      "Iteration 86, loss = 0.01049704\n",
      "Iteration 87, loss = 0.01006949\n",
      "Iteration 88, loss = 0.00994600\n",
      "Iteration 89, loss = 0.00961167\n",
      "Iteration 90, loss = 0.00927840\n",
      "Iteration 91, loss = 0.00907217\n",
      "Iteration 92, loss = 0.00890048\n",
      "Iteration 93, loss = 0.00871041\n",
      "Iteration 94, loss = 0.00866388\n",
      "Iteration 95, loss = 0.00852813\n",
      "Iteration 96, loss = 0.00826064\n",
      "Iteration 97, loss = 0.00809160\n",
      "Iteration 98, loss = 0.00774898\n",
      "Iteration 99, loss = 0.00759162\n",
      "Iteration 100, loss = 0.00753543\n",
      "Iteration 101, loss = 0.00740277\n",
      "Iteration 102, loss = 0.00719718\n",
      "Iteration 103, loss = 0.00705333\n",
      "Iteration 104, loss = 0.00690657\n",
      "Iteration 105, loss = 0.00678167\n",
      "Iteration 106, loss = 0.00673202\n",
      "Iteration 107, loss = 0.00660873\n",
      "Iteration 108, loss = 0.00643496\n",
      "Iteration 109, loss = 0.00638037\n",
      "Iteration 110, loss = 0.00628757\n",
      "Iteration 111, loss = 0.00614047\n",
      "Iteration 112, loss = 0.00608130\n",
      "Iteration 113, loss = 0.00601597\n",
      "Iteration 114, loss = 0.00586809\n",
      "Iteration 115, loss = 0.00578722\n",
      "Iteration 116, loss = 0.00572015\n",
      "Iteration 117, loss = 0.00561610\n",
      "Iteration 118, loss = 0.00555583\n",
      "Iteration 119, loss = 0.00543037\n",
      "Iteration 120, loss = 0.00535764\n",
      "Iteration 121, loss = 0.00533337\n",
      "Iteration 122, loss = 0.00522365\n",
      "Iteration 123, loss = 0.00517640\n",
      "Iteration 124, loss = 0.00506480\n",
      "Iteration 125, loss = 0.00503489\n",
      "Iteration 126, loss = 0.00495587\n",
      "Iteration 127, loss = 0.00489734\n",
      "Iteration 128, loss = 0.00485625\n",
      "Iteration 129, loss = 0.00474191\n",
      "Iteration 130, loss = 0.00468352\n",
      "Iteration 131, loss = 0.00463689\n",
      "Iteration 132, loss = 0.00456305\n",
      "Iteration 133, loss = 0.00451383\n",
      "Iteration 134, loss = 0.00445526\n",
      "Iteration 135, loss = 0.00440080\n",
      "Iteration 136, loss = 0.00436991\n",
      "Iteration 137, loss = 0.00431632\n",
      "Iteration 138, loss = 0.00425248\n",
      "Iteration 139, loss = 0.00422589\n",
      "Iteration 140, loss = 0.00416445\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 2.39483267\n",
      "Iteration 2, loss = 2.08464047\n",
      "Iteration 3, loss = 1.89754961\n",
      "Iteration 4, loss = 1.65002406\n",
      "Iteration 5, loss = 1.28806195\n",
      "Iteration 6, loss = 1.00191771\n",
      "Iteration 7, loss = 0.85114115\n",
      "Iteration 8, loss = 0.91094024\n",
      "Iteration 9, loss = 0.79769254\n",
      "Iteration 10, loss = 0.65994100\n",
      "Iteration 11, loss = 0.63383845\n",
      "Iteration 12, loss = 0.57978824\n",
      "Iteration 13, loss = 0.52767661\n",
      "Iteration 14, loss = 0.47279629\n",
      "Iteration 15, loss = 0.42834417\n",
      "Iteration 16, loss = 0.53550929\n",
      "Iteration 17, loss = 0.38150950\n",
      "Iteration 18, loss = 0.36193146\n",
      "Iteration 19, loss = 0.32793626\n",
      "Iteration 20, loss = 0.50887072\n",
      "Iteration 21, loss = 0.38671666\n",
      "Iteration 22, loss = 0.27172290\n",
      "Iteration 23, loss = 0.26271918\n",
      "Iteration 24, loss = 0.24900170\n",
      "Iteration 25, loss = 0.24259544\n",
      "Iteration 26, loss = 0.20463941\n",
      "Iteration 27, loss = 0.18929214\n",
      "Iteration 28, loss = 0.16204838\n",
      "Iteration 29, loss = 0.17101430\n",
      "Iteration 30, loss = 0.23324165\n",
      "Iteration 31, loss = 0.16511094\n",
      "Iteration 32, loss = 0.15112918\n",
      "Iteration 33, loss = 0.17519196\n",
      "Iteration 34, loss = 0.13266748\n",
      "Iteration 35, loss = 0.13339920\n",
      "Iteration 36, loss = 0.11817212\n",
      "Iteration 37, loss = 0.12222672\n",
      "Iteration 38, loss = 0.10325584\n",
      "Iteration 39, loss = 0.10979325\n",
      "Iteration 40, loss = 0.13159422\n",
      "Iteration 41, loss = 0.14192714\n",
      "Iteration 42, loss = 0.10570948\n",
      "Iteration 43, loss = 0.26155740\n",
      "Iteration 44, loss = 0.09867134\n",
      "Iteration 45, loss = 0.06511604\n",
      "Iteration 46, loss = 0.06931109\n",
      "Iteration 47, loss = 0.05702375\n",
      "Iteration 48, loss = 0.06351250\n",
      "Iteration 49, loss = 0.04711939\n",
      "Iteration 50, loss = 0.04322364\n",
      "Iteration 51, loss = 0.04234764\n",
      "Iteration 52, loss = 0.03879023\n",
      "Iteration 53, loss = 0.04260451\n",
      "Iteration 54, loss = 0.03468970\n",
      "Iteration 55, loss = 0.03506784\n",
      "Iteration 56, loss = 0.03547587\n",
      "Iteration 57, loss = 0.03910883\n",
      "Iteration 58, loss = 0.03427596\n",
      "Iteration 59, loss = 0.03046116\n",
      "Iteration 60, loss = 0.02780839\n",
      "Iteration 61, loss = 0.02944221\n",
      "Iteration 62, loss = 0.02474888\n",
      "Iteration 63, loss = 0.02402277\n",
      "Iteration 64, loss = 0.02360703\n",
      "Iteration 65, loss = 0.02219682\n",
      "Iteration 66, loss = 0.02297920\n",
      "Iteration 67, loss = 0.02267687\n",
      "Iteration 68, loss = 0.02078785\n",
      "Iteration 69, loss = 0.02017524\n",
      "Iteration 70, loss = 0.01975022\n",
      "Iteration 71, loss = 0.01897678\n",
      "Iteration 72, loss = 0.01906347\n",
      "Iteration 73, loss = 0.01798391\n",
      "Iteration 74, loss = 0.01832184\n",
      "Iteration 75, loss = 0.01709721\n",
      "Iteration 76, loss = 0.01694826\n",
      "Iteration 77, loss = 0.01633762\n",
      "Iteration 78, loss = 0.01738583\n",
      "Iteration 79, loss = 0.01565248\n",
      "Iteration 80, loss = 0.01577716\n",
      "Iteration 81, loss = 0.01504064\n",
      "Iteration 82, loss = 0.01470817\n",
      "Iteration 83, loss = 0.01449977\n",
      "Iteration 84, loss = 0.01427226\n",
      "Iteration 85, loss = 0.01419428\n",
      "Iteration 86, loss = 0.01438223\n",
      "Iteration 87, loss = 0.01366186\n",
      "Iteration 88, loss = 0.01327099\n",
      "Iteration 89, loss = 0.01317755\n",
      "Iteration 90, loss = 0.01287950\n",
      "Iteration 91, loss = 0.01294012\n",
      "Iteration 92, loss = 0.01245951\n",
      "Iteration 93, loss = 0.01238093\n",
      "Iteration 94, loss = 0.01244474\n",
      "Iteration 95, loss = 0.01190483\n",
      "Iteration 96, loss = 0.01185149\n",
      "Iteration 97, loss = 0.01186952\n",
      "Iteration 98, loss = 0.01154382\n",
      "Iteration 99, loss = 0.01142534\n",
      "Iteration 100, loss = 0.01115847\n",
      "Iteration 101, loss = 0.01102284\n",
      "Iteration 102, loss = 0.01094051\n",
      "Iteration 103, loss = 0.01078161\n",
      "Iteration 104, loss = 0.01060937\n",
      "Iteration 105, loss = 0.01065295\n",
      "Iteration 106, loss = 0.01039685\n",
      "Iteration 107, loss = 0.01031826\n",
      "Iteration 108, loss = 0.01017113\n",
      "Iteration 109, loss = 0.01001548\n",
      "Iteration 110, loss = 0.00992469\n",
      "Iteration 111, loss = 0.00982239\n",
      "Iteration 112, loss = 0.00972665\n",
      "Iteration 113, loss = 0.00970234\n",
      "Iteration 114, loss = 0.00968648\n",
      "Iteration 115, loss = 0.00961405\n",
      "Iteration 116, loss = 0.00930789\n",
      "Iteration 117, loss = 0.00922064\n",
      "Iteration 118, loss = 0.00912683\n",
      "Iteration 119, loss = 0.00909540\n",
      "Iteration 120, loss = 0.00908910\n",
      "Iteration 121, loss = 0.00906786\n",
      "Iteration 122, loss = 0.00890452\n",
      "Iteration 123, loss = 0.00885571\n",
      "Iteration 124, loss = 0.00869682\n",
      "Iteration 125, loss = 0.00860224\n",
      "Iteration 126, loss = 0.00848583\n",
      "Iteration 127, loss = 0.00841432\n",
      "Iteration 128, loss = 0.00829796\n",
      "Iteration 129, loss = 0.00828408\n",
      "Iteration 130, loss = 0.00824585\n",
      "Iteration 131, loss = 0.00829433\n",
      "Iteration 132, loss = 0.00812506\n",
      "Iteration 133, loss = 0.00796805\n",
      "Iteration 134, loss = 0.00791360\n",
      "Iteration 135, loss = 0.00784931\n",
      "Iteration 136, loss = 0.00776493\n",
      "Iteration 137, loss = 0.00772541\n",
      "Iteration 138, loss = 0.00764909\n",
      "Iteration 139, loss = 0.00760967\n",
      "Iteration 140, loss = 0.00756031\n",
      "Iteration 141, loss = 0.00745312\n",
      "Iteration 142, loss = 0.00740607\n",
      "Iteration 143, loss = 0.00733428\n",
      "Iteration 144, loss = 0.00729513\n",
      "Iteration 145, loss = 0.00721246\n",
      "Iteration 146, loss = 0.00716009\n",
      "Iteration 147, loss = 0.00710470\n",
      "Iteration 148, loss = 0.00703177\n",
      "Iteration 149, loss = 0.00695641\n",
      "Iteration 150, loss = 0.00688795\n",
      "Iteration 151, loss = 0.00683845\n",
      "Iteration 152, loss = 0.00677068\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 2.24105655\n",
      "Iteration 2, loss = 1.65921848\n",
      "Iteration 3, loss = 1.63644238\n",
      "Iteration 4, loss = 1.24797547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5, loss = 0.83901299\n",
      "Iteration 6, loss = 0.74998285\n",
      "Iteration 7, loss = 0.68667998\n",
      "Iteration 8, loss = 0.68335271\n",
      "Iteration 9, loss = 0.62336100\n",
      "Iteration 10, loss = 0.56570747\n",
      "Iteration 11, loss = 0.55338471\n",
      "Iteration 12, loss = 0.47903644\n",
      "Iteration 13, loss = 0.45258806\n",
      "Iteration 14, loss = 0.42137291\n",
      "Iteration 15, loss = 0.40490164\n",
      "Iteration 16, loss = 0.38374857\n",
      "Iteration 17, loss = 0.78299854\n",
      "Iteration 18, loss = 0.41154219\n",
      "Iteration 19, loss = 0.36828479\n",
      "Iteration 20, loss = 0.34422972\n",
      "Iteration 21, loss = 0.37637079\n",
      "Iteration 22, loss = 0.38590719\n",
      "Iteration 23, loss = 0.30532694\n",
      "Iteration 24, loss = 0.26075401\n",
      "Iteration 25, loss = 0.24408673\n",
      "Iteration 26, loss = 0.24266983\n",
      "Iteration 27, loss = 0.37144411\n",
      "Iteration 28, loss = 0.30045708\n",
      "Iteration 29, loss = 0.38914540\n",
      "Iteration 30, loss = 0.21440879\n",
      "Iteration 31, loss = 0.19049327\n",
      "Iteration 32, loss = 0.21173497\n",
      "Iteration 33, loss = 0.17839190\n",
      "Iteration 34, loss = 0.16557689\n",
      "Iteration 35, loss = 0.17775602\n",
      "Iteration 36, loss = 0.12776000\n",
      "Iteration 37, loss = 0.12712383\n",
      "Iteration 38, loss = 0.11257059\n",
      "Iteration 39, loss = 0.11088987\n",
      "Iteration 40, loss = 0.15625737\n",
      "Iteration 41, loss = 0.11596024\n",
      "Iteration 42, loss = 0.08876651\n",
      "Iteration 43, loss = 0.11916659\n",
      "Iteration 44, loss = 0.12020607\n",
      "Iteration 45, loss = 0.15219318\n",
      "Iteration 46, loss = 0.12313388\n",
      "Iteration 47, loss = 0.13347896\n",
      "Iteration 48, loss = 0.06520694\n",
      "Iteration 49, loss = 0.06863463\n",
      "Iteration 50, loss = 0.07222313\n",
      "Iteration 51, loss = 0.06111588\n",
      "Iteration 52, loss = 0.05714599\n",
      "Iteration 53, loss = 0.04376252\n",
      "Iteration 54, loss = 0.04964692\n",
      "Iteration 55, loss = 0.03796230\n",
      "Iteration 56, loss = 0.03712496\n",
      "Iteration 57, loss = 0.03337288\n",
      "Iteration 58, loss = 0.03627912\n",
      "Iteration 59, loss = 0.02987663\n",
      "Iteration 60, loss = 0.02780961\n",
      "Iteration 61, loss = 0.02642884\n",
      "Iteration 62, loss = 0.02597321\n",
      "Iteration 63, loss = 0.02433347\n",
      "Iteration 64, loss = 0.02598477\n",
      "Iteration 65, loss = 0.02617761\n",
      "Iteration 66, loss = 0.02508656\n",
      "Iteration 67, loss = 0.02121900\n",
      "Iteration 68, loss = 0.01958611\n",
      "Iteration 69, loss = 0.02003677\n",
      "Iteration 70, loss = 0.01891325\n",
      "Iteration 71, loss = 0.01789047\n",
      "Iteration 72, loss = 0.01671046\n",
      "Iteration 73, loss = 0.01602714\n",
      "Iteration 74, loss = 0.01598243\n",
      "Iteration 75, loss = 0.01540806\n",
      "Iteration 76, loss = 0.01466619\n",
      "Iteration 77, loss = 0.01441804\n",
      "Iteration 78, loss = 0.01360206\n",
      "Iteration 79, loss = 0.01303746\n",
      "Iteration 80, loss = 0.01275807\n",
      "Iteration 81, loss = 0.01317152\n",
      "Iteration 82, loss = 0.01351932\n",
      "Iteration 83, loss = 0.01287722\n",
      "Iteration 84, loss = 0.01168854\n",
      "Iteration 85, loss = 0.01271664\n",
      "Iteration 86, loss = 0.01123593\n",
      "Iteration 87, loss = 0.01073842\n",
      "Iteration 88, loss = 0.01109268\n",
      "Iteration 89, loss = 0.01058212\n",
      "Iteration 90, loss = 0.00993738\n",
      "Iteration 91, loss = 0.01036200\n",
      "Iteration 92, loss = 0.00961517\n",
      "Iteration 93, loss = 0.00970417\n",
      "Iteration 94, loss = 0.00946473\n",
      "Iteration 95, loss = 0.00933119\n",
      "Iteration 96, loss = 0.00867053\n",
      "Iteration 97, loss = 0.00876186\n",
      "Iteration 98, loss = 0.00828200\n",
      "Iteration 99, loss = 0.00814987\n",
      "Iteration 100, loss = 0.00797081\n",
      "Iteration 101, loss = 0.00781918\n",
      "Iteration 102, loss = 0.00777382\n",
      "Iteration 103, loss = 0.00762996\n",
      "Iteration 104, loss = 0.00740610\n",
      "Iteration 105, loss = 0.00727882\n",
      "Iteration 106, loss = 0.00744054\n",
      "Iteration 107, loss = 0.00750771\n",
      "Iteration 108, loss = 0.00712200\n",
      "Iteration 109, loss = 0.00673976\n",
      "Iteration 110, loss = 0.00690045\n",
      "Iteration 111, loss = 0.00704168\n",
      "Iteration 112, loss = 0.00651242\n",
      "Iteration 113, loss = 0.00643762\n",
      "Iteration 114, loss = 0.00632635\n",
      "Iteration 115, loss = 0.00629536\n",
      "Iteration 116, loss = 0.00622934\n",
      "Iteration 117, loss = 0.00595644\n",
      "Iteration 118, loss = 0.00597705\n",
      "Iteration 119, loss = 0.00586234\n",
      "Iteration 120, loss = 0.00582073\n",
      "Iteration 121, loss = 0.00563516\n",
      "Iteration 122, loss = 0.00560493\n",
      "Iteration 123, loss = 0.00555995\n",
      "Iteration 124, loss = 0.00550425\n",
      "Iteration 125, loss = 0.00530416\n",
      "Iteration 126, loss = 0.00532105\n",
      "Iteration 127, loss = 0.00520416\n",
      "Iteration 128, loss = 0.00512584\n",
      "Iteration 129, loss = 0.00517667\n",
      "Iteration 130, loss = 0.00510556\n",
      "Iteration 131, loss = 0.00503391\n",
      "Iteration 132, loss = 0.00492781\n",
      "Iteration 133, loss = 0.00482443\n",
      "Iteration 134, loss = 0.00474831\n",
      "Iteration 135, loss = 0.00478493\n",
      "Iteration 136, loss = 0.00463170\n",
      "Iteration 137, loss = 0.00463939\n",
      "Iteration 138, loss = 0.00460576\n",
      "Iteration 139, loss = 0.00452954\n",
      "Iteration 140, loss = 0.00443465\n",
      "Iteration 141, loss = 0.00438738\n",
      "Iteration 142, loss = 0.00434087\n",
      "Iteration 143, loss = 0.00439334\n",
      "Iteration 144, loss = 0.00422945\n",
      "Iteration 145, loss = 0.00422388\n",
      "Iteration 146, loss = 0.00415230\n",
      "Iteration 147, loss = 0.00409559\n",
      "Iteration 148, loss = 0.00407364\n",
      "Iteration 149, loss = 0.00404109\n",
      "Iteration 150, loss = 0.00401368\n",
      "Iteration 151, loss = 0.00397726\n",
      "Iteration 152, loss = 0.00394225\n",
      "Iteration 153, loss = 0.00386043\n",
      "Iteration 154, loss = 0.00392240\n",
      "Iteration 155, loss = 0.00382545\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 2.22598536\n",
      "Iteration 2, loss = 1.66338989\n",
      "Iteration 3, loss = 1.21886955\n",
      "Iteration 4, loss = 1.42428666\n",
      "Iteration 5, loss = 2.00491935\n",
      "Iteration 6, loss = 0.96253463\n",
      "Iteration 7, loss = 0.81568143\n",
      "Iteration 8, loss = 0.68149524\n",
      "Iteration 9, loss = 0.70918353\n",
      "Iteration 10, loss = 0.59697787\n",
      "Iteration 11, loss = 0.50638900\n",
      "Iteration 12, loss = 0.53175362\n",
      "Iteration 13, loss = 0.45092788\n",
      "Iteration 14, loss = 0.40553886\n",
      "Iteration 15, loss = 0.38025660\n",
      "Iteration 16, loss = 0.38561485\n",
      "Iteration 17, loss = 0.33673883\n",
      "Iteration 18, loss = 0.36383577\n",
      "Iteration 19, loss = 0.45951577\n",
      "Iteration 20, loss = 0.29114406\n",
      "Iteration 21, loss = 0.27585162\n",
      "Iteration 22, loss = 0.26858174\n",
      "Iteration 23, loss = 0.30991623\n",
      "Iteration 24, loss = 0.43279565\n",
      "Iteration 25, loss = 0.21953365\n",
      "Iteration 26, loss = 0.28910333\n",
      "Iteration 27, loss = 0.19276481\n",
      "Iteration 28, loss = 0.17442925\n",
      "Iteration 29, loss = 0.15894351\n",
      "Iteration 30, loss = 0.15190191\n",
      "Iteration 31, loss = 0.14186274\n",
      "Iteration 32, loss = 0.32367379\n",
      "Iteration 33, loss = 0.16668972\n",
      "Iteration 34, loss = 0.15099011\n",
      "Iteration 35, loss = 0.11856314\n",
      "Iteration 36, loss = 0.11353488\n",
      "Iteration 37, loss = 0.09100172\n",
      "Iteration 38, loss = 0.09065704\n",
      "Iteration 39, loss = 0.08062743\n",
      "Iteration 40, loss = 0.07702552\n",
      "Iteration 41, loss = 0.07346353\n",
      "Iteration 42, loss = 0.06502528\n",
      "Iteration 43, loss = 0.06325616\n",
      "Iteration 44, loss = 0.05658309\n",
      "Iteration 45, loss = 0.05221340\n",
      "Iteration 46, loss = 0.05343843\n",
      "Iteration 47, loss = 0.05175073\n",
      "Iteration 48, loss = 0.04362845\n",
      "Iteration 49, loss = 0.04274244\n",
      "Iteration 50, loss = 0.03916242\n",
      "Iteration 51, loss = 0.04103717\n",
      "Iteration 52, loss = 0.04904186\n",
      "Iteration 53, loss = 0.03353808\n",
      "Iteration 54, loss = 0.03611343\n",
      "Iteration 55, loss = 0.03797679\n",
      "Iteration 56, loss = 0.03325015\n",
      "Iteration 57, loss = 0.02905461\n",
      "Iteration 58, loss = 0.02544595\n",
      "Iteration 59, loss = 0.02426793\n",
      "Iteration 60, loss = 0.02570799\n",
      "Iteration 61, loss = 0.02444378\n",
      "Iteration 62, loss = 0.02351855\n",
      "Iteration 63, loss = 0.02115721\n",
      "Iteration 64, loss = 0.02029295\n",
      "Iteration 65, loss = 0.01840442\n",
      "Iteration 66, loss = 0.01855778\n",
      "Iteration 67, loss = 0.01761505\n",
      "Iteration 68, loss = 0.01662985\n",
      "Iteration 69, loss = 0.01584168\n",
      "Iteration 70, loss = 0.01597659\n",
      "Iteration 71, loss = 0.01565783\n",
      "Iteration 72, loss = 0.01420750\n",
      "Iteration 73, loss = 0.01398144\n",
      "Iteration 74, loss = 0.01354988\n",
      "Iteration 75, loss = 0.01311733\n",
      "Iteration 76, loss = 0.01254752\n",
      "Iteration 77, loss = 0.01228627\n",
      "Iteration 78, loss = 0.01182135\n",
      "Iteration 79, loss = 0.01152766\n",
      "Iteration 80, loss = 0.01132722\n",
      "Iteration 81, loss = 0.01124422\n",
      "Iteration 82, loss = 0.01082057\n",
      "Iteration 83, loss = 0.01086787\n",
      "Iteration 84, loss = 0.01040118\n",
      "Iteration 85, loss = 0.01004274\n",
      "Iteration 86, loss = 0.00979365\n",
      "Iteration 87, loss = 0.00949856\n",
      "Iteration 88, loss = 0.00967402\n",
      "Iteration 89, loss = 0.00947769\n",
      "Iteration 90, loss = 0.00903638\n",
      "Iteration 91, loss = 0.00897471\n",
      "Iteration 92, loss = 0.00867627\n",
      "Iteration 93, loss = 0.00852439\n",
      "Iteration 94, loss = 0.00858125\n",
      "Iteration 95, loss = 0.00800214\n",
      "Iteration 96, loss = 0.00811619\n",
      "Iteration 97, loss = 0.00769745\n",
      "Iteration 98, loss = 0.00764381\n",
      "Iteration 99, loss = 0.00740791\n",
      "Iteration 100, loss = 0.00733984\n",
      "Iteration 101, loss = 0.00709529\n",
      "Iteration 102, loss = 0.00732629\n",
      "Iteration 103, loss = 0.00712545\n",
      "Iteration 104, loss = 0.00677411\n",
      "Iteration 105, loss = 0.00679640\n",
      "Iteration 106, loss = 0.00653033\n",
      "Iteration 107, loss = 0.00656827\n",
      "Iteration 108, loss = 0.00647371\n",
      "Iteration 109, loss = 0.00623651\n",
      "Iteration 110, loss = 0.00634008\n",
      "Iteration 111, loss = 0.00630392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 112, loss = 0.00621256\n",
      "Iteration 113, loss = 0.00605259\n",
      "Iteration 114, loss = 0.00576394\n",
      "Iteration 115, loss = 0.00569658\n",
      "Iteration 116, loss = 0.00566304\n",
      "Iteration 117, loss = 0.00550276\n",
      "Iteration 118, loss = 0.00543955\n",
      "Iteration 119, loss = 0.00536034\n",
      "Iteration 120, loss = 0.00532569\n",
      "Iteration 121, loss = 0.00522370\n",
      "Iteration 122, loss = 0.00519043\n",
      "Iteration 123, loss = 0.00512822\n",
      "Iteration 124, loss = 0.00514564\n",
      "Iteration 125, loss = 0.00492619\n",
      "Iteration 126, loss = 0.00494332\n",
      "Iteration 127, loss = 0.00486799\n",
      "Iteration 128, loss = 0.00477057\n",
      "Iteration 129, loss = 0.00471337\n",
      "Iteration 130, loss = 0.00468324\n",
      "Iteration 131, loss = 0.00464793\n",
      "Iteration 132, loss = 0.00456722\n",
      "Iteration 133, loss = 0.00447479\n",
      "Iteration 134, loss = 0.00441875\n",
      "Iteration 135, loss = 0.00441111\n",
      "Iteration 136, loss = 0.00431252\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 2.23917861\n",
      "Iteration 2, loss = 1.72166456\n",
      "Iteration 3, loss = 2.51735744\n",
      "Iteration 4, loss = 1.11581564\n",
      "Iteration 5, loss = 0.90825373\n",
      "Iteration 6, loss = 0.79044510\n",
      "Iteration 7, loss = 0.85459203\n",
      "Iteration 8, loss = 0.74296666\n",
      "Iteration 9, loss = 0.64540618\n",
      "Iteration 10, loss = 0.59696578\n",
      "Iteration 11, loss = 0.57086529\n",
      "Iteration 12, loss = 0.51685333\n",
      "Iteration 13, loss = 0.47497202\n",
      "Iteration 14, loss = 0.42847564\n",
      "Iteration 15, loss = 0.40272740\n",
      "Iteration 16, loss = 0.37796610\n",
      "Iteration 17, loss = 0.39561266\n",
      "Iteration 18, loss = 0.32692957\n",
      "Iteration 19, loss = 0.30820733\n",
      "Iteration 20, loss = 0.32850359\n",
      "Iteration 21, loss = 0.40306988\n",
      "Iteration 22, loss = 0.33358225\n",
      "Iteration 23, loss = 0.30490652\n",
      "Iteration 24, loss = 0.35645347\n",
      "Iteration 25, loss = 0.35476364\n",
      "Iteration 26, loss = 0.26466440\n",
      "Iteration 27, loss = 0.23165528\n",
      "Iteration 28, loss = 0.19876838\n",
      "Iteration 29, loss = 0.20908637\n",
      "Iteration 30, loss = 0.18424047\n",
      "Iteration 31, loss = 0.14850557\n",
      "Iteration 32, loss = 0.19898135\n",
      "Iteration 33, loss = 0.29213127\n",
      "Iteration 34, loss = 0.29842315\n",
      "Iteration 35, loss = 0.15754959\n",
      "Iteration 36, loss = 0.11624581\n",
      "Iteration 37, loss = 0.10246887\n",
      "Iteration 38, loss = 0.09051502\n",
      "Iteration 39, loss = 0.09901269\n",
      "Iteration 40, loss = 0.10503614\n",
      "Iteration 41, loss = 0.09185670\n",
      "Iteration 42, loss = 0.06668738\n",
      "Iteration 43, loss = 0.08356753\n",
      "Iteration 44, loss = 0.05955198\n",
      "Iteration 45, loss = 0.05697617\n",
      "Iteration 46, loss = 0.07032330\n",
      "Iteration 47, loss = 0.04797098\n",
      "Iteration 48, loss = 0.04682329\n",
      "Iteration 49, loss = 0.04663091\n",
      "Iteration 50, loss = 0.04242849\n",
      "Iteration 51, loss = 0.03770229\n",
      "Iteration 52, loss = 0.03512288\n",
      "Iteration 53, loss = 0.03675132\n",
      "Iteration 54, loss = 0.03305175\n",
      "Iteration 55, loss = 0.03101417\n",
      "Iteration 56, loss = 0.02974516\n",
      "Iteration 57, loss = 0.02642668\n",
      "Iteration 58, loss = 0.02539444\n",
      "Iteration 59, loss = 0.02504994\n",
      "Iteration 60, loss = 0.02283745\n",
      "Iteration 61, loss = 0.02251126\n",
      "Iteration 62, loss = 0.02192483\n",
      "Iteration 63, loss = 0.02065117\n",
      "Iteration 64, loss = 0.01962368\n",
      "Iteration 65, loss = 0.01893925\n",
      "Iteration 66, loss = 0.01882964\n",
      "Iteration 67, loss = 0.01754045\n",
      "Iteration 68, loss = 0.01701827\n",
      "Iteration 69, loss = 0.01598087\n",
      "Iteration 70, loss = 0.01546907\n",
      "Iteration 71, loss = 0.01491594\n",
      "Iteration 72, loss = 0.01448984\n",
      "Iteration 73, loss = 0.01386927\n",
      "Iteration 74, loss = 0.01338285\n",
      "Iteration 75, loss = 0.01327078\n",
      "Iteration 76, loss = 0.01256958\n",
      "Iteration 77, loss = 0.01223438\n",
      "Iteration 78, loss = 0.01207474\n",
      "Iteration 79, loss = 0.01167998\n",
      "Iteration 80, loss = 0.01156699\n",
      "Iteration 81, loss = 0.01138021\n",
      "Iteration 82, loss = 0.01111309\n",
      "Iteration 83, loss = 0.01076152\n",
      "Iteration 84, loss = 0.01047905\n",
      "Iteration 85, loss = 0.01032508\n",
      "Iteration 86, loss = 0.00983416\n",
      "Iteration 87, loss = 0.00964172\n",
      "Iteration 88, loss = 0.00963284\n",
      "Iteration 89, loss = 0.00933339\n",
      "Iteration 90, loss = 0.00908618\n",
      "Iteration 91, loss = 0.00886808\n",
      "Iteration 92, loss = 0.00870094\n",
      "Iteration 93, loss = 0.00851537\n",
      "Iteration 94, loss = 0.00832747\n",
      "Iteration 95, loss = 0.00818977\n",
      "Iteration 96, loss = 0.00809710\n",
      "Iteration 97, loss = 0.00790103\n",
      "Iteration 98, loss = 0.00770401\n",
      "Iteration 99, loss = 0.00756024\n",
      "Iteration 100, loss = 0.00750077\n",
      "Iteration 101, loss = 0.00737622\n",
      "Iteration 102, loss = 0.00733419\n",
      "Iteration 103, loss = 0.00704233\n",
      "Iteration 104, loss = 0.00703392\n",
      "Iteration 105, loss = 0.00695488\n",
      "Iteration 106, loss = 0.00677066\n",
      "Iteration 107, loss = 0.00676656\n",
      "Iteration 108, loss = 0.00678150\n",
      "Iteration 109, loss = 0.00637984\n",
      "Iteration 110, loss = 0.00638591\n",
      "Iteration 111, loss = 0.00620375\n",
      "Iteration 112, loss = 0.00611701\n",
      "Iteration 113, loss = 0.00617345\n",
      "Iteration 114, loss = 0.00592975\n",
      "Iteration 115, loss = 0.00585429\n",
      "Iteration 116, loss = 0.00578866\n",
      "Iteration 117, loss = 0.00566001\n",
      "Iteration 118, loss = 0.00558965\n",
      "Iteration 119, loss = 0.00549576\n",
      "Iteration 120, loss = 0.00541056\n",
      "Iteration 121, loss = 0.00532507\n",
      "Iteration 122, loss = 0.00528599\n",
      "Iteration 123, loss = 0.00522701\n",
      "Iteration 124, loss = 0.00513876\n",
      "Iteration 125, loss = 0.00517449\n",
      "Iteration 126, loss = 0.00503182\n",
      "Iteration 127, loss = 0.00502995\n",
      "Iteration 128, loss = 0.00489563\n",
      "Iteration 129, loss = 0.00485799\n",
      "Iteration 130, loss = 0.00480494\n",
      "Iteration 131, loss = 0.00471043\n",
      "Iteration 132, loss = 0.00465442\n",
      "Iteration 133, loss = 0.00460160\n",
      "Iteration 134, loss = 0.00455905\n",
      "Iteration 135, loss = 0.00449211\n",
      "Iteration 136, loss = 0.00446144\n",
      "Iteration 137, loss = 0.00438225\n",
      "Iteration 138, loss = 0.00432911\n",
      "Iteration 139, loss = 0.00429371\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 2.27558639\n",
      "Iteration 2, loss = 1.70002444\n",
      "Iteration 3, loss = 1.72154785\n",
      "Iteration 4, loss = 1.00002264\n",
      "Iteration 5, loss = 0.79315017\n",
      "Iteration 6, loss = 0.71182266\n",
      "Iteration 7, loss = 0.70479886\n",
      "Iteration 8, loss = 0.73592224\n",
      "Iteration 9, loss = 0.57223047\n",
      "Iteration 10, loss = 0.53914584\n",
      "Iteration 11, loss = 0.49839823\n",
      "Iteration 12, loss = 0.45051530\n",
      "Iteration 13, loss = 0.47906231\n",
      "Iteration 14, loss = 0.38652429\n",
      "Iteration 15, loss = 0.38257624\n",
      "Iteration 16, loss = 0.43272396\n",
      "Iteration 17, loss = 0.34846575\n",
      "Iteration 18, loss = 0.38811314\n",
      "Iteration 19, loss = 0.37779500\n",
      "Iteration 20, loss = 0.26301331\n",
      "Iteration 21, loss = 0.25508771\n",
      "Iteration 22, loss = 0.24926549\n",
      "Iteration 23, loss = 0.21908096\n",
      "Iteration 24, loss = 0.33355307\n",
      "Iteration 25, loss = 0.29105299\n",
      "Iteration 26, loss = 0.23560067\n",
      "Iteration 27, loss = 0.21189032\n",
      "Iteration 28, loss = 0.18947675\n",
      "Iteration 29, loss = 0.28426228\n",
      "Iteration 30, loss = 0.18489164\n",
      "Iteration 31, loss = 0.14273219\n",
      "Iteration 32, loss = 0.12945459\n",
      "Iteration 33, loss = 0.11456701\n",
      "Iteration 34, loss = 0.13850638\n",
      "Iteration 35, loss = 0.10634751\n",
      "Iteration 36, loss = 0.11325577\n",
      "Iteration 37, loss = 0.09066398\n",
      "Iteration 38, loss = 0.11808332\n",
      "Iteration 39, loss = 0.10891279\n",
      "Iteration 40, loss = 0.08634014\n",
      "Iteration 41, loss = 0.06938420\n",
      "Iteration 42, loss = 0.05569142\n",
      "Iteration 43, loss = 0.06288095\n",
      "Iteration 44, loss = 0.05036854\n",
      "Iteration 45, loss = 0.04498995\n",
      "Iteration 46, loss = 0.05488132\n",
      "Iteration 47, loss = 0.04025741\n",
      "Iteration 48, loss = 0.04394906\n",
      "Iteration 49, loss = 0.03457899\n",
      "Iteration 50, loss = 0.03459947\n",
      "Iteration 51, loss = 0.03054812\n",
      "Iteration 52, loss = 0.02880813\n",
      "Iteration 53, loss = 0.02966205\n",
      "Iteration 54, loss = 0.02644401\n",
      "Iteration 55, loss = 0.02355166\n",
      "Iteration 56, loss = 0.02245220\n",
      "Iteration 57, loss = 0.02072736\n",
      "Iteration 58, loss = 0.02105993\n",
      "Iteration 59, loss = 0.01972291\n",
      "Iteration 60, loss = 0.01807838\n",
      "Iteration 61, loss = 0.02117128\n",
      "Iteration 62, loss = 0.01689919\n",
      "Iteration 63, loss = 0.01840742\n",
      "Iteration 64, loss = 0.01618321\n",
      "Iteration 65, loss = 0.01516388\n",
      "Iteration 66, loss = 0.01448292\n",
      "Iteration 67, loss = 0.01458739\n",
      "Iteration 68, loss = 0.01349161\n",
      "Iteration 69, loss = 0.01309665\n",
      "Iteration 70, loss = 0.01297237\n",
      "Iteration 71, loss = 0.01210545\n",
      "Iteration 72, loss = 0.01193137\n",
      "Iteration 73, loss = 0.01162850\n",
      "Iteration 74, loss = 0.01154402\n",
      "Iteration 75, loss = 0.01091271\n",
      "Iteration 76, loss = 0.01047078\n",
      "Iteration 77, loss = 0.01023115\n",
      "Iteration 78, loss = 0.01004408\n",
      "Iteration 79, loss = 0.00996212\n",
      "Iteration 80, loss = 0.00957368\n",
      "Iteration 81, loss = 0.00953388\n",
      "Iteration 82, loss = 0.00915750\n",
      "Iteration 83, loss = 0.00891826\n",
      "Iteration 84, loss = 0.00875656\n",
      "Iteration 85, loss = 0.00867194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 86, loss = 0.00831591\n",
      "Iteration 87, loss = 0.00817723\n",
      "Iteration 88, loss = 0.00805836\n",
      "Iteration 89, loss = 0.00819018\n",
      "Iteration 90, loss = 0.00811529\n",
      "Iteration 91, loss = 0.00751088\n",
      "Iteration 92, loss = 0.00737009\n",
      "Iteration 93, loss = 0.00727087\n",
      "Iteration 94, loss = 0.00719664\n",
      "Iteration 95, loss = 0.00692513\n",
      "Iteration 96, loss = 0.00682182\n",
      "Iteration 97, loss = 0.00674640\n",
      "Iteration 98, loss = 0.00656926\n",
      "Iteration 99, loss = 0.00649497\n",
      "Iteration 100, loss = 0.00643487\n",
      "Iteration 101, loss = 0.00642725\n",
      "Iteration 102, loss = 0.00615046\n",
      "Iteration 103, loss = 0.00599282\n",
      "Iteration 104, loss = 0.00589192\n",
      "Iteration 105, loss = 0.00594209\n",
      "Iteration 106, loss = 0.00582220\n",
      "Iteration 107, loss = 0.00566944\n",
      "Iteration 108, loss = 0.00554968\n",
      "Iteration 109, loss = 0.00554116\n",
      "Iteration 110, loss = 0.00543867\n",
      "Iteration 111, loss = 0.00534622\n",
      "Iteration 112, loss = 0.00522285\n",
      "Iteration 113, loss = 0.00522463\n",
      "Iteration 114, loss = 0.00514604\n",
      "Iteration 115, loss = 0.00502409\n",
      "Iteration 116, loss = 0.00518093\n",
      "Iteration 117, loss = 0.00486678\n",
      "Iteration 118, loss = 0.00485163\n",
      "Iteration 119, loss = 0.00473291\n",
      "Iteration 120, loss = 0.00473177\n",
      "Iteration 121, loss = 0.00467457\n",
      "Iteration 122, loss = 0.00464239\n",
      "Iteration 123, loss = 0.00455856\n",
      "Iteration 124, loss = 0.00450582\n",
      "Iteration 125, loss = 0.00440299\n",
      "Iteration 126, loss = 0.00440541\n",
      "Iteration 127, loss = 0.00434994\n",
      "Iteration 128, loss = 0.00426053\n",
      "Iteration 129, loss = 0.00421806\n",
      "Iteration 130, loss = 0.00420632\n",
      "Iteration 131, loss = 0.00408132\n",
      "Iteration 132, loss = 0.00405335\n",
      "Iteration 133, loss = 0.00400419\n",
      "Iteration 134, loss = 0.00396041\n",
      "Iteration 135, loss = 0.00392509\n",
      "Iteration 136, loss = 0.00386706\n",
      "Iteration 137, loss = 0.00382257\n",
      "Iteration 138, loss = 0.00378932\n",
      "Iteration 139, loss = 0.00378388\n",
      "Iteration 140, loss = 0.00377216\n",
      "Iteration 141, loss = 0.00368720\n",
      "Iteration 142, loss = 0.00366037\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 2.26174701\n",
      "Iteration 2, loss = 1.66603685\n",
      "Iteration 3, loss = 1.56380090\n",
      "Iteration 4, loss = 1.26306930\n",
      "Iteration 5, loss = 0.89734852\n",
      "Iteration 6, loss = 0.74698644\n",
      "Iteration 7, loss = 0.76264199\n",
      "Iteration 8, loss = 0.64953381\n",
      "Iteration 9, loss = 0.61770536\n",
      "Iteration 10, loss = 0.54637994\n",
      "Iteration 11, loss = 0.52095386\n",
      "Iteration 12, loss = 0.47956745\n",
      "Iteration 13, loss = 0.56612200\n",
      "Iteration 14, loss = 0.55918795\n",
      "Iteration 15, loss = 0.45269441\n",
      "Iteration 16, loss = 0.43139727\n",
      "Iteration 17, loss = 0.37496556\n",
      "Iteration 18, loss = 0.33990653\n",
      "Iteration 19, loss = 0.34182274\n",
      "Iteration 20, loss = 0.35415644\n",
      "Iteration 21, loss = 0.34901148\n",
      "Iteration 22, loss = 0.26909090\n",
      "Iteration 23, loss = 0.26062482\n",
      "Iteration 24, loss = 0.31184445\n",
      "Iteration 25, loss = 0.23110799\n",
      "Iteration 26, loss = 0.25612085\n",
      "Iteration 27, loss = 0.19155355\n",
      "Iteration 28, loss = 0.18104093\n",
      "Iteration 29, loss = 0.16869335\n",
      "Iteration 30, loss = 0.16702614\n",
      "Iteration 31, loss = 0.17687319\n",
      "Iteration 32, loss = 0.85109733\n",
      "Iteration 33, loss = 0.20645553\n",
      "Iteration 34, loss = 0.18111317\n",
      "Iteration 35, loss = 0.23856818\n",
      "Iteration 36, loss = 0.17382477\n",
      "Iteration 37, loss = 0.13427722\n",
      "Iteration 38, loss = 0.12435415\n",
      "Iteration 39, loss = 0.10376048\n",
      "Iteration 40, loss = 0.09896565\n",
      "Iteration 41, loss = 0.11421051\n",
      "Iteration 42, loss = 0.09148835\n",
      "Iteration 43, loss = 0.09829738\n",
      "Iteration 44, loss = 0.06837658\n",
      "Iteration 45, loss = 0.08659610\n",
      "Iteration 46, loss = 0.09636780\n",
      "Iteration 47, loss = 0.06143283\n",
      "Iteration 48, loss = 0.10751823\n",
      "Iteration 49, loss = 0.22803310\n",
      "Iteration 50, loss = 0.07192131\n",
      "Iteration 51, loss = 0.04636167\n",
      "Iteration 52, loss = 0.05191471\n",
      "Iteration 53, loss = 0.04545998\n",
      "Iteration 54, loss = 0.03961748\n",
      "Iteration 55, loss = 0.03808608\n",
      "Iteration 56, loss = 0.03369744\n",
      "Iteration 57, loss = 0.03537935\n",
      "Iteration 58, loss = 0.03236303\n",
      "Iteration 59, loss = 0.02805327\n",
      "Iteration 60, loss = 0.02602758\n",
      "Iteration 61, loss = 0.02432087\n",
      "Iteration 62, loss = 0.02344946\n",
      "Iteration 63, loss = 0.02270945\n",
      "Iteration 64, loss = 0.02251501\n",
      "Iteration 65, loss = 0.02743304\n",
      "Iteration 66, loss = 0.02063468\n",
      "Iteration 67, loss = 0.01909938\n",
      "Iteration 68, loss = 0.01876434\n",
      "Iteration 69, loss = 0.01693503\n",
      "Iteration 70, loss = 0.01710773\n",
      "Iteration 71, loss = 0.01578936\n",
      "Iteration 72, loss = 0.01488511\n",
      "Iteration 73, loss = 0.01443598\n",
      "Iteration 74, loss = 0.01438205\n",
      "Iteration 75, loss = 0.01352305\n",
      "Iteration 76, loss = 0.01330491\n",
      "Iteration 77, loss = 0.01287870\n",
      "Iteration 78, loss = 0.01248543\n",
      "Iteration 79, loss = 0.01258346\n",
      "Iteration 80, loss = 0.01174299\n",
      "Iteration 81, loss = 0.01159384\n",
      "Iteration 82, loss = 0.01184864\n",
      "Iteration 83, loss = 0.01137062\n",
      "Iteration 84, loss = 0.01066878\n",
      "Iteration 85, loss = 0.01069642\n",
      "Iteration 86, loss = 0.01024109\n",
      "Iteration 87, loss = 0.00995902\n",
      "Iteration 88, loss = 0.00977745\n",
      "Iteration 89, loss = 0.00964413\n",
      "Iteration 90, loss = 0.00934220\n",
      "Iteration 91, loss = 0.00942627\n",
      "Iteration 92, loss = 0.00895493\n",
      "Iteration 93, loss = 0.00880593\n",
      "Iteration 94, loss = 0.00857915\n",
      "Iteration 95, loss = 0.00846840\n",
      "Iteration 96, loss = 0.00819340\n",
      "Iteration 97, loss = 0.00807820\n",
      "Iteration 98, loss = 0.00803473\n",
      "Iteration 99, loss = 0.00794437\n",
      "Iteration 100, loss = 0.00778574\n",
      "Iteration 101, loss = 0.00757574\n",
      "Iteration 102, loss = 0.00744704\n",
      "Iteration 103, loss = 0.00721715\n",
      "Iteration 104, loss = 0.00719518\n",
      "Iteration 105, loss = 0.00710100\n",
      "Iteration 106, loss = 0.00690555\n",
      "Iteration 107, loss = 0.00680105\n",
      "Iteration 108, loss = 0.00674473\n",
      "Iteration 109, loss = 0.00676699\n",
      "Iteration 110, loss = 0.00651256\n",
      "Iteration 111, loss = 0.00640600\n",
      "Iteration 112, loss = 0.00632800\n",
      "Iteration 113, loss = 0.00618278\n",
      "Iteration 114, loss = 0.00604031\n",
      "Iteration 115, loss = 0.00610659\n",
      "Iteration 116, loss = 0.00597199\n",
      "Iteration 117, loss = 0.00578629\n",
      "Iteration 118, loss = 0.00569828\n",
      "Iteration 119, loss = 0.00567492\n",
      "Iteration 120, loss = 0.00559382\n",
      "Iteration 121, loss = 0.00553453\n",
      "Iteration 122, loss = 0.00547522\n",
      "Iteration 123, loss = 0.00533182\n",
      "Iteration 124, loss = 0.00535785\n",
      "Iteration 125, loss = 0.00519865\n",
      "Iteration 126, loss = 0.00512667\n",
      "Iteration 127, loss = 0.00505603\n",
      "Iteration 128, loss = 0.00500184\n",
      "Iteration 129, loss = 0.00492226\n",
      "Iteration 130, loss = 0.00487455\n",
      "Iteration 131, loss = 0.00481496\n",
      "Iteration 132, loss = 0.00479009\n",
      "Iteration 133, loss = 0.00471916\n",
      "Iteration 134, loss = 0.00467230\n",
      "Iteration 135, loss = 0.00459357\n",
      "Iteration 136, loss = 0.00453809\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 2.37648775\n",
      "Iteration 2, loss = 2.21091134\n",
      "Iteration 3, loss = 1.85803896\n",
      "Iteration 4, loss = 1.97115855\n",
      "Iteration 5, loss = 1.61873365\n",
      "Iteration 6, loss = 1.36504952\n",
      "Iteration 7, loss = 1.31365379\n",
      "Iteration 8, loss = 2.05305312\n",
      "Iteration 9, loss = 1.29945762\n",
      "Iteration 10, loss = 1.09278246\n",
      "Iteration 11, loss = 0.92343035\n",
      "Iteration 12, loss = 0.86648917\n",
      "Iteration 13, loss = 0.80441144\n",
      "Iteration 14, loss = 0.75212087\n",
      "Iteration 15, loss = 0.86053711\n",
      "Iteration 16, loss = 0.68116994\n",
      "Iteration 17, loss = 0.63406078\n",
      "Iteration 18, loss = 0.63204100\n",
      "Iteration 19, loss = 0.59240063\n",
      "Iteration 20, loss = 0.55901577\n",
      "Iteration 21, loss = 0.50778174\n",
      "Iteration 22, loss = 0.49405629\n",
      "Iteration 23, loss = 0.47145123\n",
      "Iteration 24, loss = 0.43389615\n",
      "Iteration 25, loss = 0.41346516\n",
      "Iteration 26, loss = 0.42794915\n",
      "Iteration 27, loss = 0.37429680\n",
      "Iteration 28, loss = 0.40384376\n",
      "Iteration 29, loss = 0.38302753\n",
      "Iteration 30, loss = 0.34886532\n",
      "Iteration 31, loss = 0.33721056\n",
      "Iteration 32, loss = 0.40686373\n",
      "Iteration 33, loss = 0.29410803\n",
      "Iteration 34, loss = 0.30448146\n",
      "Iteration 35, loss = 0.61781174\n",
      "Iteration 36, loss = 0.53657728\n",
      "Iteration 37, loss = 0.80017496\n",
      "Iteration 38, loss = 0.41115501\n",
      "Iteration 39, loss = 0.37015766\n",
      "Iteration 40, loss = 0.33376275\n",
      "Iteration 41, loss = 0.29230326\n",
      "Iteration 42, loss = 0.26252604\n",
      "Iteration 43, loss = 0.24687216\n",
      "Iteration 44, loss = 0.29613401\n",
      "Iteration 45, loss = 0.24653152\n",
      "Iteration 46, loss = 0.19990382\n",
      "Iteration 47, loss = 0.19568685\n",
      "Iteration 48, loss = 0.17947085\n",
      "Iteration 49, loss = 0.17880185\n",
      "Iteration 50, loss = 0.17785521\n",
      "Iteration 51, loss = 0.67808706\n",
      "Iteration 52, loss = 0.43969920\n",
      "Iteration 53, loss = 0.33968654\n",
      "Iteration 54, loss = 0.28569175\n",
      "Iteration 55, loss = 0.25125499\n",
      "Iteration 56, loss = 0.24811173\n",
      "Iteration 57, loss = 0.23187337\n",
      "Iteration 58, loss = 0.23946602\n",
      "Iteration 59, loss = 0.33880056\n",
      "Iteration 60, loss = 0.20398312\n",
      "Iteration 61, loss = 0.20198545\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 2.37348416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2, loss = 2.18704279\n",
      "Iteration 3, loss = 2.03610258\n",
      "Iteration 4, loss = 1.66543926\n",
      "Iteration 5, loss = 1.49365075\n",
      "Iteration 6, loss = 2.25773322\n",
      "Iteration 7, loss = 1.57829047\n",
      "Iteration 8, loss = 1.24922661\n",
      "Iteration 9, loss = 1.02351679\n",
      "Iteration 10, loss = 0.92064533\n",
      "Iteration 11, loss = 0.94343738\n",
      "Iteration 12, loss = 0.88656467\n",
      "Iteration 13, loss = 0.96937360\n",
      "Iteration 14, loss = 0.67594963\n",
      "Iteration 15, loss = 0.64213699\n",
      "Iteration 16, loss = 0.60577182\n",
      "Iteration 17, loss = 0.59112006\n",
      "Iteration 18, loss = 0.51747395\n",
      "Iteration 19, loss = 0.47897530\n",
      "Iteration 20, loss = 0.46034033\n",
      "Iteration 21, loss = 0.44603143\n",
      "Iteration 22, loss = 0.74649878\n",
      "Iteration 23, loss = 0.46720651\n",
      "Iteration 24, loss = 0.40937417\n",
      "Iteration 25, loss = 0.37071176\n",
      "Iteration 26, loss = 0.36018423\n",
      "Iteration 27, loss = 0.41152108\n",
      "Iteration 28, loss = 0.33321619\n",
      "Iteration 29, loss = 0.35502738\n",
      "Iteration 30, loss = 0.42847742\n",
      "Iteration 31, loss = 0.39507966\n",
      "Iteration 32, loss = 0.28130538\n",
      "Iteration 33, loss = 0.27805490\n",
      "Iteration 34, loss = 0.26294165\n",
      "Iteration 35, loss = 0.24284175\n",
      "Iteration 36, loss = 0.21386816\n",
      "Iteration 37, loss = 0.20774191\n",
      "Iteration 38, loss = 0.22511674\n",
      "Iteration 39, loss = 0.18832570\n",
      "Iteration 40, loss = 0.16198775\n",
      "Iteration 41, loss = 0.29899044\n",
      "Iteration 42, loss = 0.16937297\n",
      "Iteration 43, loss = 0.19029118\n",
      "Iteration 44, loss = 0.65893718\n",
      "Iteration 45, loss = 6.05302995\n",
      "Iteration 46, loss = 3.21357379\n",
      "Iteration 47, loss = 1.70849495\n",
      "Iteration 48, loss = 1.58437611\n",
      "Iteration 49, loss = 1.50686041\n",
      "Iteration 50, loss = 1.40645173\n",
      "Iteration 51, loss = 1.32672247\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 2.39002290\n",
      "Iteration 2, loss = 2.20601823\n",
      "Iteration 3, loss = 1.97352897\n",
      "Iteration 4, loss = 2.31246619\n",
      "Iteration 5, loss = 1.61468971\n",
      "Iteration 6, loss = 1.31785537\n",
      "Iteration 7, loss = 1.76331881\n",
      "Iteration 8, loss = 1.41813311\n",
      "Iteration 9, loss = 1.13253881\n",
      "Iteration 10, loss = 0.99374856\n",
      "Iteration 11, loss = 0.83368195\n",
      "Iteration 12, loss = 1.16257039\n",
      "Iteration 13, loss = 0.92447046\n",
      "Iteration 14, loss = 0.74991553\n",
      "Iteration 15, loss = 0.71491936\n",
      "Iteration 16, loss = 0.69900680\n",
      "Iteration 17, loss = 0.68455073\n",
      "Iteration 18, loss = 0.89839576\n",
      "Iteration 19, loss = 0.61989815\n",
      "Iteration 20, loss = 0.57439957\n",
      "Iteration 21, loss = 0.51485625\n",
      "Iteration 22, loss = 0.47725420\n",
      "Iteration 23, loss = 0.46203860\n",
      "Iteration 24, loss = 0.48744027\n",
      "Iteration 25, loss = 0.48261033\n",
      "Iteration 26, loss = 0.40209490\n",
      "Iteration 27, loss = 1.17629011\n",
      "Iteration 28, loss = 1.22511153\n",
      "Iteration 29, loss = 0.64980916\n",
      "Iteration 30, loss = 0.57019142\n",
      "Iteration 31, loss = 0.50115534\n",
      "Iteration 32, loss = 0.58874412\n",
      "Iteration 33, loss = 0.45910313\n",
      "Iteration 34, loss = 0.43112936\n",
      "Iteration 35, loss = 0.41113752\n",
      "Iteration 36, loss = 0.43955368\n",
      "Iteration 37, loss = 0.36189444\n",
      "Iteration 38, loss = 0.39240672\n",
      "Iteration 39, loss = 0.72688181\n",
      "Iteration 40, loss = 0.41333458\n",
      "Iteration 41, loss = 0.49263794\n",
      "Iteration 42, loss = 0.33361859\n",
      "Iteration 43, loss = 0.34037936\n",
      "Iteration 44, loss = 0.41939210\n",
      "Iteration 45, loss = 0.28370919\n",
      "Iteration 46, loss = 0.28486488\n",
      "Iteration 47, loss = 0.25521801\n",
      "Iteration 48, loss = 0.30639441\n",
      "Iteration 49, loss = 0.23610975\n",
      "Iteration 50, loss = 0.20848065\n",
      "Iteration 51, loss = 0.21021077\n",
      "Iteration 52, loss = 0.22303527\n",
      "Iteration 53, loss = 0.26236929\n",
      "Iteration 54, loss = 0.18781872\n",
      "Iteration 55, loss = 0.16583543\n",
      "Iteration 56, loss = 0.14970003\n",
      "Iteration 57, loss = 0.14840068\n",
      "Iteration 58, loss = 0.31548923\n",
      "Iteration 59, loss = 1.34325606\n",
      "Iteration 60, loss = 1.78258794\n",
      "Iteration 61, loss = 1.59351898\n",
      "Iteration 62, loss = 1.66438793\n",
      "Iteration 63, loss = 1.12505115\n",
      "Iteration 64, loss = 0.96703682\n",
      "Iteration 65, loss = 0.75601562\n",
      "Iteration 66, loss = 0.71403062\n",
      "Iteration 67, loss = 0.58230380\n",
      "Iteration 68, loss = 0.49885564\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 2.38142929\n",
      "Iteration 2, loss = 2.23123256\n",
      "Iteration 3, loss = 2.10134125\n",
      "Iteration 4, loss = 1.69448050\n",
      "Iteration 5, loss = 1.96733640\n",
      "Iteration 6, loss = 1.39092873\n",
      "Iteration 7, loss = 1.56264417\n",
      "Iteration 8, loss = 1.23680863\n",
      "Iteration 9, loss = 1.03393054\n",
      "Iteration 10, loss = 0.86869291\n",
      "Iteration 11, loss = 0.92862200\n",
      "Iteration 12, loss = 0.74748996\n",
      "Iteration 13, loss = 0.80827999\n",
      "Iteration 14, loss = 0.72228280\n",
      "Iteration 15, loss = 1.19146694\n",
      "Iteration 16, loss = 0.74502301\n",
      "Iteration 17, loss = 0.66871206\n",
      "Iteration 18, loss = 0.61399050\n",
      "Iteration 19, loss = 0.56253889\n",
      "Iteration 20, loss = 0.54120518\n",
      "Iteration 21, loss = 0.52714103\n",
      "Iteration 22, loss = 0.51254046\n",
      "Iteration 23, loss = 0.43560708\n",
      "Iteration 24, loss = 0.52462716\n",
      "Iteration 25, loss = 0.43835859\n",
      "Iteration 26, loss = 0.39495817\n",
      "Iteration 27, loss = 0.38300475\n",
      "Iteration 28, loss = 0.35082913\n",
      "Iteration 29, loss = 0.43747128\n",
      "Iteration 30, loss = 0.41157054\n",
      "Iteration 31, loss = 0.34284968\n",
      "Iteration 32, loss = 0.29712899\n",
      "Iteration 33, loss = 0.31474012\n",
      "Iteration 34, loss = 0.26673182\n",
      "Iteration 35, loss = 0.31213165\n",
      "Iteration 36, loss = 0.31957569\n",
      "Iteration 37, loss = 0.23929794\n",
      "Iteration 38, loss = 0.23864665\n",
      "Iteration 39, loss = 0.40616812\n",
      "Iteration 40, loss = 0.25352229\n",
      "Iteration 41, loss = 0.21961523\n",
      "Iteration 42, loss = 0.19052639\n",
      "Iteration 43, loss = 0.18654633\n",
      "Iteration 44, loss = 0.32760401\n",
      "Iteration 45, loss = 0.27245941\n",
      "Iteration 46, loss = 1.33886126\n",
      "Iteration 47, loss = 1.08077108\n",
      "Iteration 48, loss = 0.67256879\n",
      "Iteration 49, loss = 0.53102925\n",
      "Iteration 50, loss = 0.43116216\n",
      "Iteration 51, loss = 0.42573558\n",
      "Iteration 52, loss = 0.37158758\n",
      "Iteration 53, loss = 0.35239415\n",
      "Iteration 54, loss = 0.34744883\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 2.37764501\n",
      "Iteration 2, loss = 2.23518649\n",
      "Iteration 3, loss = 1.93945874\n",
      "Iteration 4, loss = 2.33350896\n",
      "Iteration 5, loss = 1.64084985\n",
      "Iteration 6, loss = 1.41645457\n",
      "Iteration 7, loss = 1.19874785\n",
      "Iteration 8, loss = 0.94590666\n",
      "Iteration 9, loss = 0.95101941\n",
      "Iteration 10, loss = 1.23319037\n",
      "Iteration 11, loss = 0.89055963\n",
      "Iteration 12, loss = 0.78154071\n",
      "Iteration 13, loss = 0.72816269\n",
      "Iteration 14, loss = 0.66665682\n",
      "Iteration 15, loss = 0.66317428\n",
      "Iteration 16, loss = 0.67734997\n",
      "Iteration 17, loss = 0.56543749\n",
      "Iteration 18, loss = 0.53404152\n",
      "Iteration 19, loss = 0.48183945\n",
      "Iteration 20, loss = 0.48900348\n",
      "Iteration 21, loss = 0.55010435\n",
      "Iteration 22, loss = 0.39945064\n",
      "Iteration 23, loss = 0.41172814\n",
      "Iteration 24, loss = 0.43767800\n",
      "Iteration 25, loss = 0.35781591\n",
      "Iteration 26, loss = 0.32717139\n",
      "Iteration 27, loss = 0.30471413\n",
      "Iteration 28, loss = 0.26651500\n",
      "Iteration 29, loss = 0.35111947\n",
      "Iteration 30, loss = 0.29639704\n",
      "Iteration 31, loss = 0.28531088\n",
      "Iteration 32, loss = 0.50094853\n",
      "Iteration 33, loss = 0.33194954\n",
      "Iteration 34, loss = 0.23496311\n",
      "Iteration 35, loss = 0.25920801\n",
      "Iteration 36, loss = 0.20555702\n",
      "Iteration 37, loss = 0.51464784\n",
      "Iteration 38, loss = 1.53470083\n",
      "Iteration 39, loss = 0.93289035\n",
      "Iteration 40, loss = 0.82756315\n",
      "Iteration 41, loss = 0.67434700\n",
      "Iteration 42, loss = 0.79851396\n",
      "Iteration 43, loss = 0.47361091\n",
      "Iteration 44, loss = 0.42328343\n",
      "Iteration 45, loss = 0.38952917\n",
      "Iteration 46, loss = 0.33136063\n",
      "Iteration 47, loss = 0.38497002\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 2.29993558\n",
      "Iteration 2, loss = 2.06679320\n",
      "Iteration 3, loss = 1.98045651\n",
      "Iteration 4, loss = 2.06005094\n",
      "Iteration 5, loss = 1.54842194\n",
      "Iteration 6, loss = 1.21082328\n",
      "Iteration 7, loss = 1.26774085\n",
      "Iteration 8, loss = 4.05343311\n",
      "Iteration 9, loss = 1.68266083\n",
      "Iteration 10, loss = 1.58360742\n",
      "Iteration 11, loss = 1.46270610\n",
      "Iteration 12, loss = 1.30737224\n",
      "Iteration 13, loss = 1.16663582\n",
      "Iteration 14, loss = 1.06685224\n",
      "Iteration 15, loss = 0.98627132\n",
      "Iteration 16, loss = 1.11814500\n",
      "Iteration 17, loss = 0.94313965\n",
      "Iteration 18, loss = 0.89360049\n",
      "Iteration 19, loss = 0.86895287\n",
      "Iteration 20, loss = 0.79949165\n",
      "Iteration 21, loss = 0.76019299\n",
      "Iteration 22, loss = 0.73635332\n",
      "Iteration 23, loss = 0.69685452\n",
      "Iteration 24, loss = 0.67643788\n",
      "Iteration 25, loss = 0.65879631\n",
      "Iteration 26, loss = 0.65551123\n",
      "Iteration 27, loss = 0.69846806\n",
      "Iteration 28, loss = 0.60445603\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 29, loss = 0.57010232\n",
      "Iteration 30, loss = 0.55666730\n",
      "Iteration 31, loss = 0.54095995\n",
      "Iteration 32, loss = 0.53825205\n",
      "Iteration 33, loss = 0.54381753\n",
      "Iteration 34, loss = 0.48639403\n",
      "Iteration 35, loss = 0.48771569\n",
      "Iteration 36, loss = 0.58772693\n",
      "Iteration 37, loss = 0.50467840\n",
      "Iteration 38, loss = 0.42494546\n",
      "Iteration 39, loss = 0.39474382\n",
      "Iteration 40, loss = 0.37564814\n",
      "Iteration 41, loss = 0.93012233\n",
      "Iteration 42, loss = 0.76380376\n",
      "Iteration 43, loss = 0.49418678\n",
      "Iteration 44, loss = 0.42028700\n",
      "Iteration 45, loss = 0.39306650\n",
      "Iteration 46, loss = 0.41479567\n",
      "Iteration 47, loss = 0.42483058\n",
      "Iteration 48, loss = 0.34374343\n",
      "Iteration 49, loss = 0.34215791\n",
      "Iteration 50, loss = 0.36777215\n",
      "Iteration 51, loss = 0.32847960\n",
      "Iteration 52, loss = 0.33679599\n",
      "Iteration 53, loss = 0.29256201\n",
      "Iteration 54, loss = 0.36218946\n",
      "Iteration 55, loss = 0.46171987\n",
      "Iteration 56, loss = 0.30571140\n",
      "Iteration 57, loss = 0.39140873\n",
      "Iteration 58, loss = 0.33215053\n",
      "Iteration 59, loss = 0.29125520\n",
      "Iteration 60, loss = 0.32178653\n",
      "Iteration 61, loss = 0.26295064\n",
      "Iteration 62, loss = 0.25120132\n",
      "Iteration 63, loss = 0.27150751\n",
      "Iteration 64, loss = 0.28835397\n",
      "Iteration 65, loss = 0.21031038\n",
      "Iteration 66, loss = 0.24323600\n",
      "Iteration 67, loss = 0.41984327\n",
      "Iteration 68, loss = 0.22871344\n",
      "Iteration 69, loss = 0.21369344\n",
      "Iteration 70, loss = 0.21333463\n",
      "Iteration 71, loss = 0.18433193\n",
      "Iteration 72, loss = 0.18551047\n",
      "Iteration 73, loss = 0.17719480\n",
      "Iteration 74, loss = 0.28633508\n",
      "Iteration 75, loss = 0.18256531\n",
      "Iteration 76, loss = 0.17527520\n",
      "Iteration 77, loss = 0.16580740\n",
      "Iteration 78, loss = 0.16036760\n",
      "Iteration 79, loss = 0.13993206\n",
      "Iteration 80, loss = 0.16547908\n",
      "Iteration 81, loss = 0.13611977\n",
      "Iteration 82, loss = 0.17011848\n",
      "Iteration 83, loss = 0.25810508\n",
      "Iteration 84, loss = 0.13588022\n",
      "Iteration 85, loss = 0.11268942\n",
      "Iteration 86, loss = 0.11537575\n",
      "Iteration 87, loss = 0.09860217\n",
      "Iteration 88, loss = 0.09123991\n",
      "Iteration 89, loss = 0.09288460\n",
      "Iteration 90, loss = 0.07611629\n",
      "Iteration 91, loss = 0.07555118\n",
      "Iteration 92, loss = 0.09691727\n",
      "Iteration 93, loss = 0.09087004\n",
      "Iteration 94, loss = 0.16815547\n",
      "Iteration 95, loss = 3.02735756\n",
      "Iteration 96, loss = 2.27450421\n",
      "Iteration 97, loss = 2.18577437\n",
      "Iteration 98, loss = 1.48939085\n",
      "Iteration 99, loss = 1.27717726\n",
      "Iteration 100, loss = 1.05856059\n",
      "Iteration 101, loss = 0.98554544\n",
      "Iteration 102, loss = 0.94042782\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 2.30269176\n",
      "Iteration 2, loss = 2.05078546\n",
      "Iteration 3, loss = 1.99383964\n",
      "Iteration 4, loss = 2.00845299\n",
      "Iteration 5, loss = 1.45302588\n",
      "Iteration 6, loss = 1.36368615\n",
      "Iteration 7, loss = 1.56696480\n",
      "Iteration 8, loss = 2.25081740\n",
      "Iteration 9, loss = 1.39007082\n",
      "Iteration 10, loss = 1.21014702\n",
      "Iteration 11, loss = 1.00888369\n",
      "Iteration 12, loss = 0.98764080\n",
      "Iteration 13, loss = 1.23966421\n",
      "Iteration 14, loss = 0.89111154\n",
      "Iteration 15, loss = 0.83935606\n",
      "Iteration 16, loss = 0.75419653\n",
      "Iteration 17, loss = 0.69639802\n",
      "Iteration 18, loss = 0.76354178\n",
      "Iteration 19, loss = 0.56212570\n",
      "Iteration 20, loss = 0.56771500\n",
      "Iteration 21, loss = 0.51654153\n",
      "Iteration 22, loss = 0.60101408\n",
      "Iteration 23, loss = 0.47737201\n",
      "Iteration 24, loss = 0.47276434\n",
      "Iteration 25, loss = 0.39756007\n",
      "Iteration 26, loss = 0.39476246\n",
      "Iteration 27, loss = 0.35249931\n",
      "Iteration 28, loss = 0.33367374\n",
      "Iteration 29, loss = 0.33020933\n",
      "Iteration 30, loss = 0.31993294\n",
      "Iteration 31, loss = 0.27703247\n",
      "Iteration 32, loss = 0.59879101\n",
      "Iteration 33, loss = 0.95464608\n",
      "Iteration 34, loss = 2.47235517\n",
      "Iteration 35, loss = 5.01243702\n",
      "Iteration 36, loss = 2.04091917\n",
      "Iteration 37, loss = 1.72686046\n",
      "Iteration 38, loss = 1.59586419\n",
      "Iteration 39, loss = 1.40085871\n",
      "Iteration 40, loss = 1.28992291\n",
      "Iteration 41, loss = 1.14414186\n",
      "Iteration 42, loss = 0.98654678\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 2.30957008\n",
      "Iteration 2, loss = 2.05487083\n",
      "Iteration 3, loss = 1.97087105\n",
      "Iteration 4, loss = 2.80658712\n",
      "Iteration 5, loss = 1.90355764\n",
      "Iteration 6, loss = 1.72282241\n",
      "Iteration 7, loss = 1.91741513\n",
      "Iteration 8, loss = 1.85035978\n",
      "Iteration 9, loss = 1.49574603\n",
      "Iteration 10, loss = 1.29689999\n",
      "Iteration 11, loss = 1.26006124\n",
      "Iteration 12, loss = 1.38374866\n",
      "Iteration 13, loss = 1.08643907\n",
      "Iteration 14, loss = 0.95008171\n",
      "Iteration 15, loss = 1.40101592\n",
      "Iteration 16, loss = 1.01919730\n",
      "Iteration 17, loss = 0.86747871\n",
      "Iteration 18, loss = 0.79109434\n",
      "Iteration 19, loss = 0.73700224\n",
      "Iteration 20, loss = 0.68867804\n",
      "Iteration 21, loss = 0.67296682\n",
      "Iteration 22, loss = 0.61655916\n",
      "Iteration 23, loss = 0.64770663\n",
      "Iteration 24, loss = 0.59963234\n",
      "Iteration 25, loss = 0.58253583\n",
      "Iteration 26, loss = 0.52873621\n",
      "Iteration 27, loss = 0.63271433\n",
      "Iteration 28, loss = 0.52067843\n",
      "Iteration 29, loss = 0.48575504\n",
      "Iteration 30, loss = 0.95714715\n",
      "Iteration 31, loss = 0.76746396\n",
      "Iteration 32, loss = 0.57115979\n",
      "Iteration 33, loss = 0.48858976\n",
      "Iteration 34, loss = 0.48265332\n",
      "Iteration 35, loss = 0.45903576\n",
      "Iteration 36, loss = 0.43677637\n",
      "Iteration 37, loss = 0.43575439\n",
      "Iteration 38, loss = 0.39983247\n",
      "Iteration 39, loss = 0.47328121\n",
      "Iteration 40, loss = 0.39563751\n",
      "Iteration 41, loss = 0.40697936\n",
      "Iteration 42, loss = 0.34386566\n",
      "Iteration 43, loss = 0.32252578\n",
      "Iteration 44, loss = 0.30657652\n",
      "Iteration 45, loss = 0.47040248\n",
      "Iteration 46, loss = 0.32395135\n",
      "Iteration 47, loss = 0.28949455\n",
      "Iteration 48, loss = 0.34157361\n",
      "Iteration 49, loss = 0.29164121\n",
      "Iteration 50, loss = 0.24743548\n",
      "Iteration 51, loss = 0.30780101\n",
      "Iteration 52, loss = 0.74702360\n",
      "Iteration 53, loss = 0.37219573\n",
      "Iteration 54, loss = 0.27089919\n",
      "Iteration 55, loss = 0.48253718\n",
      "Iteration 56, loss = 3.16219628\n",
      "Iteration 57, loss = 5.05989194\n",
      "Iteration 58, loss = 2.58020479\n",
      "Iteration 59, loss = 2.27941210\n",
      "Iteration 60, loss = 2.46955334\n",
      "Iteration 61, loss = 2.39241534\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 2.31121923\n",
      "Iteration 2, loss = 2.08194710\n",
      "Iteration 3, loss = 1.90291872\n",
      "Iteration 4, loss = 1.52994780\n",
      "Iteration 5, loss = 1.63089409\n",
      "Iteration 6, loss = 1.10886051\n",
      "Iteration 7, loss = 0.98170838\n",
      "Iteration 8, loss = 1.03566254\n",
      "Iteration 9, loss = 1.63054571\n",
      "Iteration 10, loss = 1.07684095\n",
      "Iteration 11, loss = 0.89612166\n",
      "Iteration 12, loss = 0.82257615\n",
      "Iteration 13, loss = 0.70458561\n",
      "Iteration 14, loss = 0.75280391\n",
      "Iteration 15, loss = 0.64056375\n",
      "Iteration 16, loss = 0.61046296\n",
      "Iteration 17, loss = 0.53459401\n",
      "Iteration 18, loss = 0.53430361\n",
      "Iteration 19, loss = 0.48437001\n",
      "Iteration 20, loss = 0.45663562\n",
      "Iteration 21, loss = 0.41095271\n",
      "Iteration 22, loss = 0.39320190\n",
      "Iteration 23, loss = 0.56434875\n",
      "Iteration 24, loss = 0.43667117\n",
      "Iteration 25, loss = 0.35706324\n",
      "Iteration 26, loss = 0.35170952\n",
      "Iteration 27, loss = 0.33988304\n",
      "Iteration 28, loss = 0.37235024\n",
      "Iteration 29, loss = 0.33338187\n",
      "Iteration 30, loss = 0.27764189\n",
      "Iteration 31, loss = 0.27642766\n",
      "Iteration 32, loss = 0.29171385\n",
      "Iteration 33, loss = 0.23671068\n",
      "Iteration 34, loss = 0.30965284\n",
      "Iteration 35, loss = 0.27093477\n",
      "Iteration 36, loss = 0.20935526\n",
      "Iteration 37, loss = 0.25610226\n",
      "Iteration 38, loss = 0.21219349\n",
      "Iteration 39, loss = 0.21197000\n",
      "Iteration 40, loss = 0.56038200\n",
      "Iteration 41, loss = 1.51473811\n",
      "Iteration 42, loss = 1.43164869\n",
      "Iteration 43, loss = 0.83172125\n",
      "Iteration 44, loss = 0.76001121\n",
      "Iteration 45, loss = 0.60025163\n",
      "Iteration 46, loss = 0.48813303\n",
      "Iteration 47, loss = 0.50211050\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 2.30810657\n",
      "Iteration 2, loss = 2.05828441\n",
      "Iteration 3, loss = 1.78140474\n",
      "Iteration 4, loss = 3.28949588\n",
      "Iteration 5, loss = 2.08191483\n",
      "Iteration 6, loss = 1.85168506\n",
      "Iteration 7, loss = 1.74238076\n",
      "Iteration 8, loss = 1.47934734\n",
      "Iteration 9, loss = 1.41334897\n",
      "Iteration 10, loss = 1.24180134\n",
      "Iteration 11, loss = 1.89886433\n",
      "Iteration 12, loss = 1.26089270\n",
      "Iteration 13, loss = 1.00781634\n",
      "Iteration 14, loss = 0.96037102\n",
      "Iteration 15, loss = 0.82255007\n",
      "Iteration 16, loss = 0.83901335\n",
      "Iteration 17, loss = 0.75557094\n",
      "Iteration 18, loss = 0.73216653\n",
      "Iteration 19, loss = 0.78789043\n",
      "Iteration 20, loss = 0.64767619\n",
      "Iteration 21, loss = 0.66114440\n",
      "Iteration 22, loss = 0.62091648\n",
      "Iteration 23, loss = 0.57669455\n",
      "Iteration 24, loss = 0.54435729\n",
      "Iteration 25, loss = 0.48878467\n",
      "Iteration 26, loss = 0.55677686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 27, loss = 0.59928144\n",
      "Iteration 28, loss = 0.51219334\n",
      "Iteration 29, loss = 0.46423577\n",
      "Iteration 30, loss = 0.45184121\n",
      "Iteration 31, loss = 0.39158915\n",
      "Iteration 32, loss = 0.38553387\n",
      "Iteration 33, loss = 0.76277872\n",
      "Iteration 34, loss = 0.76630198\n",
      "Iteration 35, loss = 0.53922896\n",
      "Iteration 36, loss = 0.44921793\n",
      "Iteration 37, loss = 0.41921034\n",
      "Iteration 38, loss = 0.38874892\n",
      "Iteration 39, loss = 0.37497836\n",
      "Iteration 40, loss = 0.34269084\n",
      "Iteration 41, loss = 0.33006944\n",
      "Iteration 42, loss = 0.38295259\n",
      "Iteration 43, loss = 0.33710289\n",
      "Iteration 44, loss = 0.81639637\n",
      "Iteration 45, loss = 16.80634023\n",
      "Iteration 46, loss = 20.69066711\n",
      "Iteration 47, loss = 2.81225376\n",
      "Iteration 48, loss = 2.54295907\n",
      "Iteration 49, loss = 2.43216884\n",
      "Iteration 50, loss = 2.38947613\n",
      "Iteration 51, loss = 2.35391769\n",
      "Iteration 52, loss = 2.32556219\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 2.20485345\n",
      "Iteration 2, loss = 1.62051344\n",
      "Iteration 3, loss = 1.24406950\n",
      "Iteration 4, loss = 1.23530074\n",
      "Iteration 5, loss = 1.24145971\n",
      "Iteration 6, loss = 0.74564829\n",
      "Iteration 7, loss = 0.71932846\n",
      "Iteration 8, loss = 0.63503212\n",
      "Iteration 9, loss = 0.59080905\n",
      "Iteration 10, loss = 0.55970783\n",
      "Iteration 11, loss = 0.52515438\n",
      "Iteration 12, loss = 0.51899442\n",
      "Iteration 13, loss = 0.46506884\n",
      "Iteration 14, loss = 0.44406281\n",
      "Iteration 15, loss = 0.40232172\n",
      "Iteration 16, loss = 0.42085276\n",
      "Iteration 17, loss = 0.38495861\n",
      "Iteration 18, loss = 0.38503937\n",
      "Iteration 19, loss = 0.32563631\n",
      "Iteration 20, loss = 0.31044885\n",
      "Iteration 21, loss = 0.28524739\n",
      "Iteration 22, loss = 0.28131445\n",
      "Iteration 23, loss = 0.44317750\n",
      "Iteration 24, loss = 0.26951814\n",
      "Iteration 25, loss = 0.25421755\n",
      "Iteration 26, loss = 0.26648545\n",
      "Iteration 27, loss = 0.23759493\n",
      "Iteration 28, loss = 0.20895787\n",
      "Iteration 29, loss = 0.18179799\n",
      "Iteration 30, loss = 0.20933904\n",
      "Iteration 31, loss = 0.18645588\n",
      "Iteration 32, loss = 0.17184690\n",
      "Iteration 33, loss = 0.15181045\n",
      "Iteration 34, loss = 0.20576277\n",
      "Iteration 35, loss = 0.13783655\n",
      "Iteration 36, loss = 0.14067970\n",
      "Iteration 37, loss = 0.15885171\n",
      "Iteration 38, loss = 0.17164467\n",
      "Iteration 39, loss = 0.46097936\n",
      "Iteration 40, loss = 0.24826637\n",
      "Iteration 41, loss = 0.16186184\n",
      "Iteration 42, loss = 0.14504180\n",
      "Iteration 43, loss = 0.12648808\n",
      "Iteration 44, loss = 0.11864307\n",
      "Iteration 45, loss = 0.09382786\n",
      "Iteration 46, loss = 0.09320959\n",
      "Iteration 47, loss = 0.08345105\n",
      "Iteration 48, loss = 0.08360585\n",
      "Iteration 49, loss = 0.07651177\n",
      "Iteration 50, loss = 0.07051021\n",
      "Iteration 51, loss = 0.06778700\n",
      "Iteration 52, loss = 0.06120152\n",
      "Iteration 53, loss = 0.05956561\n",
      "Iteration 54, loss = 0.05648803\n",
      "Iteration 55, loss = 0.05514387\n",
      "Iteration 56, loss = 0.05337569\n",
      "Iteration 57, loss = 0.05848565\n",
      "Iteration 58, loss = 0.14961833\n",
      "Iteration 59, loss = 0.09809776\n",
      "Iteration 60, loss = 0.04795043\n",
      "Iteration 61, loss = 0.05454463\n",
      "Iteration 62, loss = 0.04229513\n",
      "Iteration 63, loss = 0.03646297\n",
      "Iteration 64, loss = 0.03333252\n",
      "Iteration 65, loss = 0.03236155\n",
      "Iteration 66, loss = 0.03202656\n",
      "Iteration 67, loss = 0.03089973\n",
      "Iteration 68, loss = 0.02858857\n",
      "Iteration 69, loss = 0.02797465\n",
      "Iteration 70, loss = 0.02859657\n",
      "Iteration 71, loss = 0.02723684\n",
      "Iteration 72, loss = 0.02326925\n",
      "Iteration 73, loss = 0.02257369\n",
      "Iteration 74, loss = 0.02202808\n",
      "Iteration 75, loss = 0.02128362\n",
      "Iteration 76, loss = 0.02084466\n",
      "Iteration 77, loss = 0.02052087\n",
      "Iteration 78, loss = 0.02038825\n",
      "Iteration 79, loss = 0.01828399\n",
      "Iteration 80, loss = 0.01881109\n",
      "Iteration 81, loss = 0.01772810\n",
      "Iteration 82, loss = 0.01670621\n",
      "Iteration 83, loss = 0.01657730\n",
      "Iteration 84, loss = 0.01601201\n",
      "Iteration 85, loss = 0.01532315\n",
      "Iteration 86, loss = 0.01501431\n",
      "Iteration 87, loss = 0.01478330\n",
      "Iteration 88, loss = 0.01438153\n",
      "Iteration 89, loss = 0.01415472\n",
      "Iteration 90, loss = 0.01357195\n",
      "Iteration 91, loss = 0.01316325\n",
      "Iteration 92, loss = 0.01291149\n",
      "Iteration 93, loss = 0.01257647\n",
      "Iteration 94, loss = 0.01239129\n",
      "Iteration 95, loss = 0.01217603\n",
      "Iteration 96, loss = 0.01212543\n",
      "Iteration 97, loss = 0.01174406\n",
      "Iteration 98, loss = 0.01155491\n",
      "Iteration 99, loss = 0.01139906\n",
      "Iteration 100, loss = 0.01133955\n",
      "Iteration 101, loss = 0.01074304\n",
      "Iteration 102, loss = 0.01038810\n",
      "Iteration 103, loss = 0.01048556\n",
      "Iteration 104, loss = 0.01000483\n",
      "Iteration 105, loss = 0.00979298\n",
      "Iteration 106, loss = 0.00958043\n",
      "Iteration 107, loss = 0.00946056\n",
      "Iteration 108, loss = 0.00922548\n",
      "Iteration 109, loss = 0.00914611\n",
      "Iteration 110, loss = 0.00915033\n",
      "Iteration 111, loss = 0.00909281\n",
      "Iteration 112, loss = 0.00877428\n",
      "Iteration 113, loss = 0.00838300\n",
      "Iteration 114, loss = 0.00840080\n",
      "Iteration 115, loss = 0.00829172\n",
      "Iteration 116, loss = 0.00796273\n",
      "Iteration 117, loss = 0.00783411\n",
      "Iteration 118, loss = 0.00780848\n",
      "Iteration 119, loss = 0.00759831\n",
      "Iteration 120, loss = 0.00748540\n",
      "Iteration 121, loss = 0.00738879\n",
      "Iteration 122, loss = 0.00737267\n",
      "Iteration 123, loss = 0.00716451\n",
      "Iteration 124, loss = 0.00703571\n",
      "Iteration 125, loss = 0.00716088\n",
      "Iteration 126, loss = 0.00691828\n",
      "Iteration 127, loss = 0.00686214\n",
      "Iteration 128, loss = 0.00677160\n",
      "Iteration 129, loss = 0.00655595\n",
      "Iteration 130, loss = 0.00657073\n",
      "Iteration 131, loss = 0.00650088\n",
      "Iteration 132, loss = 0.00631932\n",
      "Iteration 133, loss = 0.00628030\n",
      "Iteration 134, loss = 0.00620276\n",
      "Iteration 135, loss = 0.00616483\n",
      "Iteration 136, loss = 0.00620342\n",
      "Iteration 137, loss = 0.00608832\n",
      "Iteration 138, loss = 0.00591736\n",
      "Iteration 139, loss = 0.00588280\n",
      "Iteration 140, loss = 0.00574936\n",
      "Iteration 141, loss = 0.00564446\n",
      "Iteration 142, loss = 0.00561287\n",
      "Iteration 143, loss = 0.00549993\n",
      "Iteration 144, loss = 0.00544532\n",
      "Iteration 145, loss = 0.00536067\n",
      "Iteration 146, loss = 0.00527862\n",
      "Iteration 147, loss = 0.00524952\n",
      "Iteration 148, loss = 0.00520420\n",
      "Iteration 149, loss = 0.00518879\n",
      "Iteration 150, loss = 0.00512455\n",
      "Iteration 151, loss = 0.00506638\n",
      "Iteration 152, loss = 0.00493392\n",
      "Iteration 153, loss = 0.00490551\n",
      "Iteration 154, loss = 0.00484017\n",
      "Iteration 155, loss = 0.00482867\n",
      "Iteration 156, loss = 0.00480590\n",
      "Iteration 157, loss = 0.00475258\n",
      "Iteration 158, loss = 0.00466966\n",
      "Iteration 159, loss = 0.00469947\n",
      "Iteration 160, loss = 0.00457124\n",
      "Iteration 161, loss = 0.00451901\n",
      "Iteration 162, loss = 0.00446561\n",
      "Iteration 163, loss = 0.00442643\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "RESULTS FOR NN\n",
      "\n",
      "Best parameters set found:\n",
      "{'hidden_layer_sizes': (30,)}\n",
      "Score with best parameters:\n",
      "0.7833333333333333\n",
      "\n",
      "All scores on the grid:\n",
      "[0.58333333 0.77833333 0.78333333 0.69       0.42166667]\n"
     ]
    }
   ],
   "source": [
    "# these are sample values but feel free to change them as you like, try to experiment with different sizes!!\n",
    "parameters = {'hidden_layer_sizes': [(10,), (20,), (30,), (20,20,), (30,30,20) ]}\n",
    "\n",
    "mlp = MLPClassifier(max_iter=250, alpha=1e-4, solver='sgd',\n",
    "                    tol=1e-4, random_state=ID,\n",
    "                    learning_rate_init=.1, verbose=True)\n",
    "\n",
    "mlp_kfold = GridSearchCV(mlp, parameters, cv=5, return_train_score=True)\n",
    "mlp_kfold.fit(X_train, y_train)\n",
    "\n",
    "print ('RESULTS FOR NN\\n')\n",
    "\n",
    "print(\"Best parameters set found:\")\n",
    "print(mlp_kfold.best_params_)\n",
    "\n",
    "print(\"Score with best parameters:\")\n",
    "print(mlp_kfold.best_score_)\n",
    "\n",
    "print(\"\\nAll scores on the grid:\")\n",
    "print(mlp_kfold.cv_results_['mean_test_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO DO 2\n",
    "\n",
    "Now try also different batch sizes, while keeping the best NN architecture you have found above. Remember that the batch size was previously set to the default value, i.e., min(200, n_samples). \n",
    "Recall that a batch size of 1 corresponds to baseline SGD, while using all the 480 training samples (there are 600 samples but in cross validation with 5 folders we use 1/5 of them for validation at each round) corresponds to standard GD and using a different mini-batch size lies in the middle between the two extreme cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 7.22823824\n",
      "Iteration 2, loss = 6.78953663\n",
      "Iteration 3, loss = 6.38841166\n",
      "Iteration 4, loss = 6.02593414\n",
      "Iteration 5, loss = 5.70610607\n",
      "Iteration 6, loss = 5.40698610\n",
      "Iteration 7, loss = 5.13075197\n",
      "Iteration 8, loss = 4.89486985\n",
      "Iteration 9, loss = 4.66997669\n",
      "Iteration 10, loss = 4.49007721\n",
      "Iteration 11, loss = 4.30769876\n",
      "Iteration 12, loss = 4.11209874\n",
      "Iteration 13, loss = 4.00713857\n",
      "Iteration 14, loss = 3.84883153\n",
      "Iteration 15, loss = 3.78276618\n",
      "Iteration 16, loss = 3.63390220\n",
      "Iteration 17, loss = 3.54051108\n",
      "Iteration 18, loss = 3.46488105\n",
      "Iteration 19, loss = 3.36661845\n",
      "Iteration 20, loss = 3.28931136\n",
      "Iteration 21, loss = 3.22701227\n",
      "Iteration 22, loss = 3.16085562\n",
      "Iteration 23, loss = 3.09575550\n",
      "Iteration 24, loss = 3.04204729\n",
      "Iteration 25, loss = 2.98161382\n",
      "Iteration 26, loss = 2.95395017\n",
      "Iteration 27, loss = 2.92405484\n",
      "Iteration 28, loss = 2.85267819\n",
      "Iteration 29, loss = 2.84313786\n",
      "Iteration 30, loss = 2.78894148\n",
      "Iteration 31, loss = 2.78858016\n",
      "Iteration 32, loss = 2.79136310\n",
      "Iteration 33, loss = 2.75317878\n",
      "Iteration 34, loss = 2.70713443\n",
      "Iteration 35, loss = 2.71963041\n",
      "Iteration 36, loss = 2.67641398\n",
      "Iteration 37, loss = 2.67900524\n",
      "Iteration 38, loss = 2.68650475\n",
      "Iteration 39, loss = 2.63328679\n",
      "Iteration 40, loss = 2.65818994\n",
      "Iteration 41, loss = 2.67121794\n",
      "Iteration 42, loss = 2.62878736\n",
      "Iteration 43, loss = 2.59025969\n",
      "Iteration 44, loss = 2.59718428\n",
      "Iteration 45, loss = 2.60090135\n",
      "Iteration 46, loss = 2.56813994\n",
      "Iteration 47, loss = 2.60193751\n",
      "Iteration 48, loss = 2.56899208\n",
      "Iteration 49, loss = 2.58555781\n",
      "Iteration 50, loss = 2.56864390\n",
      "Iteration 51, loss = 2.57593858\n",
      "Iteration 52, loss = 2.57640860\n",
      "Iteration 53, loss = 2.54981009\n",
      "Iteration 54, loss = 2.56274553\n",
      "Iteration 55, loss = 2.55455185\n",
      "Iteration 56, loss = 2.57780721\n",
      "Iteration 57, loss = 2.49133028\n",
      "Iteration 58, loss = 2.51271806\n",
      "Iteration 59, loss = 2.55211083\n",
      "Iteration 60, loss = 2.53389415\n",
      "Iteration 61, loss = 2.54720516\n",
      "Iteration 62, loss = 2.54344399\n",
      "Iteration 63, loss = 2.52749239\n",
      "Iteration 64, loss = 2.52705630\n",
      "Iteration 65, loss = 2.51869260\n",
      "Iteration 66, loss = 2.52813611\n",
      "Iteration 67, loss = 2.54246356\n",
      "Iteration 68, loss = 2.53859960\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 3.18297230\n",
      "Iteration 2, loss = 3.17302456\n",
      "Iteration 3, loss = 3.17571123\n",
      "Iteration 4, loss = 3.10864518\n",
      "Iteration 5, loss = 3.04876378\n",
      "Iteration 6, loss = 3.00132625\n",
      "Iteration 7, loss = 2.94597121\n",
      "Iteration 8, loss = 2.91739970\n",
      "Iteration 9, loss = 2.85553062\n",
      "Iteration 10, loss = 2.85228397\n",
      "Iteration 11, loss = 2.82369218\n",
      "Iteration 12, loss = 2.77744631\n",
      "Iteration 13, loss = 2.74855173\n",
      "Iteration 14, loss = 2.72836428\n",
      "Iteration 15, loss = 2.69395005\n",
      "Iteration 16, loss = 2.69684264\n",
      "Iteration 17, loss = 2.68444429\n",
      "Iteration 18, loss = 2.68553754\n",
      "Iteration 19, loss = 2.67619987\n",
      "Iteration 20, loss = 2.63723289\n",
      "Iteration 21, loss = 2.68504477\n",
      "Iteration 22, loss = 2.61779205\n",
      "Iteration 23, loss = 2.60790523\n",
      "Iteration 24, loss = 2.60867454\n",
      "Iteration 25, loss = 2.58650165\n",
      "Iteration 26, loss = 2.60073239\n",
      "Iteration 27, loss = 2.59096127\n",
      "Iteration 28, loss = 2.56889037\n",
      "Iteration 29, loss = 2.57624618\n",
      "Iteration 30, loss = 2.52194547\n",
      "Iteration 31, loss = 2.54768132\n",
      "Iteration 32, loss = 2.58184671\n",
      "Iteration 33, loss = 2.54899082\n",
      "Iteration 34, loss = 2.53942126\n",
      "Iteration 35, loss = 2.55733539\n",
      "Iteration 36, loss = 2.52797719\n",
      "Iteration 37, loss = 2.56550874\n",
      "Iteration 38, loss = 2.57098808\n",
      "Iteration 39, loss = 2.52582761\n",
      "Iteration 40, loss = 2.56617909\n",
      "Iteration 41, loss = 2.55369650\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 2.94491287\n",
      "Iteration 2, loss = 2.76293494\n",
      "Iteration 3, loss = 2.77044233\n",
      "Iteration 4, loss = 2.75428874\n",
      "Iteration 5, loss = 2.69264707\n",
      "Iteration 6, loss = 2.68685856\n",
      "Iteration 7, loss = 2.69380441\n",
      "Iteration 8, loss = 2.66167018\n",
      "Iteration 9, loss = 2.62728317\n",
      "Iteration 10, loss = 2.63544892\n",
      "Iteration 11, loss = 2.65543423\n",
      "Iteration 12, loss = 2.62868375\n",
      "Iteration 13, loss = 2.59856886\n",
      "Iteration 14, loss = 2.59428327\n",
      "Iteration 15, loss = 2.59208473\n",
      "Iteration 16, loss = 2.61063208\n",
      "Iteration 17, loss = 2.57317042\n",
      "Iteration 18, loss = 2.56648090\n",
      "Iteration 19, loss = 2.58503560\n",
      "Iteration 20, loss = 2.56062200\n",
      "Iteration 21, loss = 2.57071775\n",
      "Iteration 22, loss = 2.54917661\n",
      "Iteration 23, loss = 2.54639332\n",
      "Iteration 24, loss = 2.55325188\n",
      "Iteration 25, loss = 2.53236366\n",
      "Iteration 26, loss = 2.55280133\n",
      "Iteration 27, loss = 2.53843668\n",
      "Iteration 28, loss = 2.51026516\n",
      "Iteration 29, loss = 2.53501470\n",
      "Iteration 30, loss = 2.50582879\n",
      "Iteration 31, loss = 2.54157404\n",
      "Iteration 32, loss = 2.55711772\n",
      "Iteration 33, loss = 2.50537317\n",
      "Iteration 34, loss = 2.54126734\n",
      "Iteration 35, loss = 2.50226692\n",
      "Iteration 36, loss = 2.53597014\n",
      "Iteration 37, loss = 2.55144244\n",
      "Iteration 38, loss = 2.55471089\n",
      "Iteration 39, loss = 2.52292261\n",
      "Iteration 40, loss = 2.53646821\n",
      "Iteration 41, loss = 2.52674225\n",
      "Iteration 42, loss = 2.53828312\n",
      "Iteration 43, loss = 2.53308128\n",
      "Iteration 44, loss = 2.51185830\n",
      "Iteration 45, loss = 2.53165621\n",
      "Iteration 46, loss = 2.50256210\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 3.08495718\n",
      "Iteration 2, loss = 2.88897076\n",
      "Iteration 3, loss = 2.85228862\n",
      "Iteration 4, loss = 2.79867047\n",
      "Iteration 5, loss = 2.75277687\n",
      "Iteration 6, loss = 2.73645641\n",
      "Iteration 7, loss = 2.73103314\n",
      "Iteration 8, loss = 2.70694957\n",
      "Iteration 9, loss = 2.70096114\n",
      "Iteration 10, loss = 2.66732483\n",
      "Iteration 11, loss = 2.69468381\n",
      "Iteration 12, loss = 2.66019499\n",
      "Iteration 13, loss = 2.63930539\n",
      "Iteration 14, loss = 2.62664250\n",
      "Iteration 15, loss = 2.62737922\n",
      "Iteration 16, loss = 2.62137295\n",
      "Iteration 17, loss = 2.60462678\n",
      "Iteration 18, loss = 2.60720313\n",
      "Iteration 19, loss = 2.58857729\n",
      "Iteration 20, loss = 2.59492000\n",
      "Iteration 21, loss = 2.58336045\n",
      "Iteration 22, loss = 2.55241543\n",
      "Iteration 23, loss = 2.55906921\n",
      "Iteration 24, loss = 2.57007285\n",
      "Iteration 25, loss = 2.56249075\n",
      "Iteration 26, loss = 2.58195707\n",
      "Iteration 27, loss = 2.55828370\n",
      "Iteration 28, loss = 2.53774741\n",
      "Iteration 29, loss = 2.55187768\n",
      "Iteration 30, loss = 2.52613911\n",
      "Iteration 31, loss = 2.53082417\n",
      "Iteration 32, loss = 2.53888423\n",
      "Iteration 33, loss = 2.51433412\n",
      "Iteration 34, loss = 2.53709489\n",
      "Iteration 35, loss = 2.51692597\n",
      "Iteration 36, loss = 2.52543114\n",
      "Iteration 37, loss = 2.52792228\n",
      "Iteration 38, loss = 2.55740344\n",
      "Iteration 39, loss = 2.50747414\n",
      "Iteration 40, loss = 2.54302711\n",
      "Iteration 41, loss = 2.52720438\n",
      "Iteration 42, loss = 2.53441389\n",
      "Iteration 43, loss = 2.54156225\n",
      "Iteration 44, loss = 2.51519294\n",
      "Iteration 45, loss = 2.50603362\n",
      "Iteration 46, loss = 2.50978497\n",
      "Iteration 47, loss = 2.54156661\n",
      "Iteration 48, loss = 2.50189533\n",
      "Iteration 49, loss = 2.51243844\n",
      "Iteration 50, loss = 2.51770011\n",
      "Iteration 51, loss = 2.53405668\n",
      "Iteration 52, loss = 2.51851466\n",
      "Iteration 53, loss = 2.54187939\n",
      "Iteration 54, loss = 2.53326015\n",
      "Iteration 55, loss = 2.51382067\n",
      "Iteration 56, loss = 2.50434611\n",
      "Iteration 57, loss = 2.51169539\n",
      "Iteration 58, loss = 2.55061526\n",
      "Iteration 59, loss = 2.52893912\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 3.15405558\n",
      "Iteration 2, loss = 3.00107065\n",
      "Iteration 3, loss = 2.97430486\n",
      "Iteration 4, loss = 2.86618792\n",
      "Iteration 5, loss = 2.86439845\n",
      "Iteration 6, loss = 2.83778403\n",
      "Iteration 7, loss = 2.80089310\n",
      "Iteration 8, loss = 2.76338383\n",
      "Iteration 9, loss = 2.75477941\n",
      "Iteration 10, loss = 2.70441835\n",
      "Iteration 11, loss = 2.72784311\n",
      "Iteration 12, loss = 2.71815022\n",
      "Iteration 13, loss = 2.66921899\n",
      "Iteration 14, loss = 2.67713282\n",
      "Iteration 15, loss = 2.67172263\n",
      "Iteration 16, loss = 2.63820913\n",
      "Iteration 17, loss = 2.62012313\n",
      "Iteration 18, loss = 2.62699053\n",
      "Iteration 19, loss = 2.60846637\n",
      "Iteration 20, loss = 2.62055847\n",
      "Iteration 21, loss = 2.58535624\n",
      "Iteration 22, loss = 2.58522060\n",
      "Iteration 23, loss = 2.57661529\n",
      "Iteration 24, loss = 2.57959306\n",
      "Iteration 25, loss = 2.58709278\n",
      "Iteration 26, loss = 2.60169631\n",
      "Iteration 27, loss = 2.56607214\n",
      "Iteration 28, loss = 2.55635091\n",
      "Iteration 29, loss = 2.55164550\n",
      "Iteration 30, loss = 2.55328752\n",
      "Iteration 31, loss = 2.54919551\n",
      "Iteration 32, loss = 2.50621858\n",
      "Iteration 33, loss = 2.50430365\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 34, loss = 2.53056351\n",
      "Iteration 35, loss = 2.54183092\n",
      "Iteration 36, loss = 2.52550714\n",
      "Iteration 37, loss = 2.50495490\n",
      "Iteration 38, loss = 2.51893606\n",
      "Iteration 39, loss = 2.48644027\n",
      "Iteration 40, loss = 2.56345381\n",
      "Iteration 41, loss = 2.52899212\n",
      "Iteration 42, loss = 2.51182937\n",
      "Iteration 43, loss = 2.54416600\n",
      "Iteration 44, loss = 2.51374971\n",
      "Iteration 45, loss = 2.52413806\n",
      "Iteration 46, loss = 2.52196076\n",
      "Iteration 47, loss = 2.54333997\n",
      "Iteration 48, loss = 2.51525153\n",
      "Iteration 49, loss = 2.53038329\n",
      "Iteration 50, loss = 2.51564213\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.82436858\n",
      "Iteration 2, loss = 1.07105829\n",
      "Iteration 3, loss = 0.85228112\n",
      "Iteration 4, loss = 0.67882213\n",
      "Iteration 5, loss = 0.70808230\n",
      "Iteration 6, loss = 0.63922619\n",
      "Iteration 7, loss = 0.74575030\n",
      "Iteration 8, loss = 0.76220515\n",
      "Iteration 9, loss = 0.59764238\n",
      "Iteration 10, loss = 0.50681014\n",
      "Iteration 11, loss = 0.52129871\n",
      "Iteration 12, loss = 0.47655522\n",
      "Iteration 13, loss = 0.40647124\n",
      "Iteration 14, loss = 0.36401830\n",
      "Iteration 15, loss = 0.32841388\n",
      "Iteration 16, loss = 0.35326766\n",
      "Iteration 17, loss = 0.32045019\n",
      "Iteration 18, loss = 0.27819720\n",
      "Iteration 19, loss = 0.30517149\n",
      "Iteration 20, loss = 0.27616618\n",
      "Iteration 21, loss = 0.24576649\n",
      "Iteration 22, loss = 0.28069634\n",
      "Iteration 23, loss = 0.24116164\n",
      "Iteration 24, loss = 0.20786620\n",
      "Iteration 25, loss = 0.24094933\n",
      "Iteration 26, loss = 0.24743026\n",
      "Iteration 27, loss = 0.21283650\n",
      "Iteration 28, loss = 0.21841959\n",
      "Iteration 29, loss = 0.17286953\n",
      "Iteration 30, loss = 0.16222138\n",
      "Iteration 31, loss = 0.16847582\n",
      "Iteration 32, loss = 0.17101938\n",
      "Iteration 33, loss = 0.14659291\n",
      "Iteration 34, loss = 0.17102866\n",
      "Iteration 35, loss = 0.14018161\n",
      "Iteration 36, loss = 0.14063963\n",
      "Iteration 37, loss = 0.11590301\n",
      "Iteration 38, loss = 0.12734884\n",
      "Iteration 39, loss = 0.11999405\n",
      "Iteration 40, loss = 0.14876900\n",
      "Iteration 41, loss = 0.11844745\n",
      "Iteration 42, loss = 0.10997929\n",
      "Iteration 43, loss = 0.09989951\n",
      "Iteration 44, loss = 0.12134232\n",
      "Iteration 45, loss = 0.11272144\n",
      "Iteration 46, loss = 0.12068207\n",
      "Iteration 47, loss = 0.14875063\n",
      "Iteration 48, loss = 0.12730927\n",
      "Iteration 49, loss = 0.07561052\n",
      "Iteration 50, loss = 0.08860733\n",
      "Iteration 51, loss = 0.13960077\n",
      "Iteration 52, loss = 0.09165724\n",
      "Iteration 53, loss = 0.06890364\n",
      "Iteration 54, loss = 0.06515187\n",
      "Iteration 55, loss = 0.08725654\n",
      "Iteration 56, loss = 0.07166005\n",
      "Iteration 57, loss = 0.05553447\n",
      "Iteration 58, loss = 0.06779664\n",
      "Iteration 59, loss = 0.12244261\n",
      "Iteration 60, loss = 0.18952816\n",
      "Iteration 61, loss = 0.12859065\n",
      "Iteration 62, loss = 0.08362039\n",
      "Iteration 63, loss = 0.20594074\n",
      "Iteration 64, loss = 0.12323888\n",
      "Iteration 65, loss = 0.15511684\n",
      "Iteration 66, loss = 0.18048254\n",
      "Iteration 67, loss = 0.13381986\n",
      "Iteration 68, loss = 0.14228794\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.68036447\n",
      "Iteration 2, loss = 0.92164233\n",
      "Iteration 3, loss = 0.79745898\n",
      "Iteration 4, loss = 0.62878998\n",
      "Iteration 5, loss = 0.64300095\n",
      "Iteration 6, loss = 0.49661233\n",
      "Iteration 7, loss = 0.45506218\n",
      "Iteration 8, loss = 0.44919525\n",
      "Iteration 9, loss = 0.35888911\n",
      "Iteration 10, loss = 0.60118318\n",
      "Iteration 11, loss = 0.57680461\n",
      "Iteration 12, loss = 0.39266922\n",
      "Iteration 13, loss = 0.30171192\n",
      "Iteration 14, loss = 0.24391964\n",
      "Iteration 15, loss = 0.27224469\n",
      "Iteration 16, loss = 0.25389606\n",
      "Iteration 17, loss = 0.20144962\n",
      "Iteration 18, loss = 0.19441188\n",
      "Iteration 19, loss = 0.15194399\n",
      "Iteration 20, loss = 0.12898412\n",
      "Iteration 21, loss = 0.12369839\n",
      "Iteration 22, loss = 0.09338549\n",
      "Iteration 23, loss = 0.11478854\n",
      "Iteration 24, loss = 0.23527959\n",
      "Iteration 25, loss = 0.24006691\n",
      "Iteration 26, loss = 0.29592563\n",
      "Iteration 27, loss = 0.17884056\n",
      "Iteration 28, loss = 0.09045683\n",
      "Iteration 29, loss = 0.06159267\n",
      "Iteration 30, loss = 0.08299591\n",
      "Iteration 31, loss = 0.09219342\n",
      "Iteration 32, loss = 0.05665902\n",
      "Iteration 33, loss = 0.05268988\n",
      "Iteration 34, loss = 0.04968002\n",
      "Iteration 35, loss = 0.03948088\n",
      "Iteration 36, loss = 0.03570436\n",
      "Iteration 37, loss = 0.03525592\n",
      "Iteration 38, loss = 0.03512080\n",
      "Iteration 39, loss = 0.03182195\n",
      "Iteration 40, loss = 0.03802417\n",
      "Iteration 41, loss = 0.03010152\n",
      "Iteration 42, loss = 0.03106173\n",
      "Iteration 43, loss = 0.03142287\n",
      "Iteration 44, loss = 0.03997612\n",
      "Iteration 45, loss = 0.03817816\n",
      "Iteration 46, loss = 0.02960966\n",
      "Iteration 47, loss = 0.02777573\n",
      "Iteration 48, loss = 0.02673471\n",
      "Iteration 49, loss = 0.02537356\n",
      "Iteration 50, loss = 0.02386532\n",
      "Iteration 51, loss = 0.02354314\n",
      "Iteration 52, loss = 0.02383887\n",
      "Iteration 53, loss = 0.02316325\n",
      "Iteration 54, loss = 0.02221679\n",
      "Iteration 55, loss = 0.02167214\n",
      "Iteration 56, loss = 0.02131772\n",
      "Iteration 57, loss = 0.02076158\n",
      "Iteration 58, loss = 0.02212327\n",
      "Iteration 59, loss = 0.02118117\n",
      "Iteration 60, loss = 0.02012545\n",
      "Iteration 61, loss = 0.01984983\n",
      "Iteration 62, loss = 0.01939006\n",
      "Iteration 63, loss = 0.01997099\n",
      "Iteration 64, loss = 0.01910036\n",
      "Iteration 65, loss = 0.01930088\n",
      "Iteration 66, loss = 0.01784361\n",
      "Iteration 67, loss = 0.01796576\n",
      "Iteration 68, loss = 0.01740900\n",
      "Iteration 69, loss = 0.01732921\n",
      "Iteration 70, loss = 0.01708700\n",
      "Iteration 71, loss = 0.01706783\n",
      "Iteration 72, loss = 0.01643915\n",
      "Iteration 73, loss = 0.01684008\n",
      "Iteration 74, loss = 0.01610556\n",
      "Iteration 75, loss = 0.01593688\n",
      "Iteration 76, loss = 0.01582111\n",
      "Iteration 77, loss = 0.01540886\n",
      "Iteration 78, loss = 0.01548696\n",
      "Iteration 79, loss = 0.01499635\n",
      "Iteration 80, loss = 0.01484347\n",
      "Iteration 81, loss = 0.01468219\n",
      "Iteration 82, loss = 0.01449411\n",
      "Iteration 83, loss = 0.01443693\n",
      "Iteration 84, loss = 0.01412775\n",
      "Iteration 85, loss = 0.01419254\n",
      "Iteration 86, loss = 0.01393792\n",
      "Iteration 87, loss = 0.01374137\n",
      "Iteration 88, loss = 0.01370583\n",
      "Iteration 89, loss = 0.01366786\n",
      "Iteration 90, loss = 0.01397003\n",
      "Iteration 91, loss = 0.01350523\n",
      "Iteration 92, loss = 0.01335675\n",
      "Iteration 93, loss = 0.01313070\n",
      "Iteration 94, loss = 0.01302743\n",
      "Iteration 95, loss = 0.01289219\n",
      "Iteration 96, loss = 0.01281555\n",
      "Iteration 97, loss = 0.01276096\n",
      "Iteration 98, loss = 0.01270233\n",
      "Iteration 99, loss = 0.01261105\n",
      "Iteration 100, loss = 0.01245371\n",
      "Iteration 101, loss = 0.01244453\n",
      "Iteration 102, loss = 0.01241663\n",
      "Iteration 103, loss = 0.01231846\n",
      "Iteration 104, loss = 0.01217516\n",
      "Iteration 105, loss = 0.01208073\n",
      "Iteration 106, loss = 0.01200885\n",
      "Iteration 107, loss = 0.01207478\n",
      "Iteration 108, loss = 0.01196607\n",
      "Iteration 109, loss = 0.01182369\n",
      "Iteration 110, loss = 0.01177106\n",
      "Iteration 111, loss = 0.01168826\n",
      "Iteration 112, loss = 0.01164454\n",
      "Iteration 113, loss = 0.01157643\n",
      "Iteration 114, loss = 0.01151649\n",
      "Iteration 115, loss = 0.01147422\n",
      "Iteration 116, loss = 0.01138617\n",
      "Iteration 117, loss = 0.01134335\n",
      "Iteration 118, loss = 0.01130650\n",
      "Iteration 119, loss = 0.01126999\n",
      "Iteration 120, loss = 0.01117743\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.89974084\n",
      "Iteration 2, loss = 0.98548892\n",
      "Iteration 3, loss = 0.80682842\n",
      "Iteration 4, loss = 0.67377626\n",
      "Iteration 5, loss = 0.67108379\n",
      "Iteration 6, loss = 0.54520118\n",
      "Iteration 7, loss = 0.52677429\n",
      "Iteration 8, loss = 0.46185736\n",
      "Iteration 9, loss = 0.45518977\n",
      "Iteration 10, loss = 0.42553949\n",
      "Iteration 11, loss = 0.38953636\n",
      "Iteration 12, loss = 0.39356997\n",
      "Iteration 13, loss = 0.38370483\n",
      "Iteration 14, loss = 0.33719460\n",
      "Iteration 15, loss = 0.29054897\n",
      "Iteration 16, loss = 0.27569839\n",
      "Iteration 17, loss = 0.25478273\n",
      "Iteration 18, loss = 0.22255735\n",
      "Iteration 19, loss = 0.24954484\n",
      "Iteration 20, loss = 0.23740590\n",
      "Iteration 21, loss = 0.21999225\n",
      "Iteration 22, loss = 0.17384415\n",
      "Iteration 23, loss = 0.16212036\n",
      "Iteration 24, loss = 0.18731027\n",
      "Iteration 25, loss = 0.20948638\n",
      "Iteration 26, loss = 0.19868472\n",
      "Iteration 27, loss = 0.14508123\n",
      "Iteration 28, loss = 0.12651154\n",
      "Iteration 29, loss = 0.21650683\n",
      "Iteration 30, loss = 0.21802381\n",
      "Iteration 31, loss = 0.16336437\n",
      "Iteration 32, loss = 0.21581265\n",
      "Iteration 33, loss = 0.21997107\n",
      "Iteration 34, loss = 0.14682326\n",
      "Iteration 35, loss = 0.12294856\n",
      "Iteration 36, loss = 0.17000567\n",
      "Iteration 37, loss = 0.15430407\n",
      "Iteration 38, loss = 0.21582619\n",
      "Iteration 39, loss = 0.27768129\n",
      "Iteration 40, loss = 0.29067768\n",
      "Iteration 41, loss = 0.16758809\n",
      "Iteration 42, loss = 0.40250307\n",
      "Iteration 43, loss = 0.55480959\n",
      "Iteration 44, loss = 0.32883219\n",
      "Iteration 45, loss = 0.26489915\n",
      "Iteration 46, loss = 0.31617290\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.80735517\n",
      "Iteration 2, loss = 1.02560396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3, loss = 0.74458831\n",
      "Iteration 4, loss = 0.65886188\n",
      "Iteration 5, loss = 0.54851962\n",
      "Iteration 6, loss = 0.49332512\n",
      "Iteration 7, loss = 0.46579286\n",
      "Iteration 8, loss = 0.47755855\n",
      "Iteration 9, loss = 0.36658944\n",
      "Iteration 10, loss = 0.34110439\n",
      "Iteration 11, loss = 0.33424070\n",
      "Iteration 12, loss = 0.39554412\n",
      "Iteration 13, loss = 0.32045001\n",
      "Iteration 14, loss = 0.31869883\n",
      "Iteration 15, loss = 0.31235478\n",
      "Iteration 16, loss = 0.29424421\n",
      "Iteration 17, loss = 0.27510943\n",
      "Iteration 18, loss = 0.27850017\n",
      "Iteration 19, loss = 0.24720496\n",
      "Iteration 20, loss = 0.18992057\n",
      "Iteration 21, loss = 0.17297149\n",
      "Iteration 22, loss = 0.16182664\n",
      "Iteration 23, loss = 0.88167858\n",
      "Iteration 24, loss = 0.74513600\n",
      "Iteration 25, loss = 0.56793784\n",
      "Iteration 26, loss = 0.51751022\n",
      "Iteration 27, loss = 0.42577265\n",
      "Iteration 28, loss = 0.39521140\n",
      "Iteration 29, loss = 0.39152324\n",
      "Iteration 30, loss = 0.38171299\n",
      "Iteration 31, loss = 0.35821428\n",
      "Iteration 32, loss = 0.34533698\n",
      "Iteration 33, loss = 0.32352109\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.71006968\n",
      "Iteration 2, loss = 0.93033319\n",
      "Iteration 3, loss = 0.74394784\n",
      "Iteration 4, loss = 0.61017794\n",
      "Iteration 5, loss = 0.61478453\n",
      "Iteration 6, loss = 0.58091302\n",
      "Iteration 7, loss = 0.54101809\n",
      "Iteration 8, loss = 0.57666496\n",
      "Iteration 9, loss = 0.65620007\n",
      "Iteration 10, loss = 0.52333142\n",
      "Iteration 11, loss = 0.47675575\n",
      "Iteration 12, loss = 0.41902601\n",
      "Iteration 13, loss = 0.38432661\n",
      "Iteration 14, loss = 0.37612856\n",
      "Iteration 15, loss = 0.37344384\n",
      "Iteration 16, loss = 0.33548850\n",
      "Iteration 17, loss = 0.42599246\n",
      "Iteration 18, loss = 0.37015298\n",
      "Iteration 19, loss = 0.28078151\n",
      "Iteration 20, loss = 0.30267940\n",
      "Iteration 21, loss = 0.28374918\n",
      "Iteration 22, loss = 0.29780298\n",
      "Iteration 23, loss = 0.28335715\n",
      "Iteration 24, loss = 0.33486707\n",
      "Iteration 25, loss = 0.24899365\n",
      "Iteration 26, loss = 0.27896248\n",
      "Iteration 27, loss = 0.23771617\n",
      "Iteration 28, loss = 0.18484931\n",
      "Iteration 29, loss = 0.17311356\n",
      "Iteration 30, loss = 0.15426602\n",
      "Iteration 31, loss = 0.12547153\n",
      "Iteration 32, loss = 0.15716262\n",
      "Iteration 33, loss = 0.16404500\n",
      "Iteration 34, loss = 0.18931955\n",
      "Iteration 35, loss = 0.16765197\n",
      "Iteration 36, loss = 0.09814404\n",
      "Iteration 37, loss = 0.10679669\n",
      "Iteration 38, loss = 0.07630871\n",
      "Iteration 39, loss = 0.14498864\n",
      "Iteration 40, loss = 0.15771256\n",
      "Iteration 41, loss = 0.08286840\n",
      "Iteration 42, loss = 0.07128651\n",
      "Iteration 43, loss = 0.08794955\n",
      "Iteration 44, loss = 0.06752805\n",
      "Iteration 45, loss = 0.04058900\n",
      "Iteration 46, loss = 0.04269144\n",
      "Iteration 47, loss = 0.03187009\n",
      "Iteration 48, loss = 0.02784169\n",
      "Iteration 49, loss = 0.01820977\n",
      "Iteration 50, loss = 0.01737569\n",
      "Iteration 51, loss = 0.01590289\n",
      "Iteration 52, loss = 0.01824548\n",
      "Iteration 53, loss = 0.01415843\n",
      "Iteration 54, loss = 0.01251812\n",
      "Iteration 55, loss = 0.01325874\n",
      "Iteration 56, loss = 0.01520212\n",
      "Iteration 57, loss = 0.01240696\n",
      "Iteration 58, loss = 0.01124393\n",
      "Iteration 59, loss = 0.01040575\n",
      "Iteration 60, loss = 0.01081239\n",
      "Iteration 61, loss = 0.01194465\n",
      "Iteration 62, loss = 0.01050587\n",
      "Iteration 63, loss = 0.00971957\n",
      "Iteration 64, loss = 0.00918154\n",
      "Iteration 65, loss = 0.00897841\n",
      "Iteration 66, loss = 0.01097582\n",
      "Iteration 67, loss = 0.01037049\n",
      "Iteration 68, loss = 0.01022731\n",
      "Iteration 69, loss = 0.00876873\n",
      "Iteration 70, loss = 0.00830097\n",
      "Iteration 71, loss = 0.00805356\n",
      "Iteration 72, loss = 0.00859356\n",
      "Iteration 73, loss = 0.01054612\n",
      "Iteration 74, loss = 0.00864927\n",
      "Iteration 75, loss = 0.00793580\n",
      "Iteration 76, loss = 0.00757087\n",
      "Iteration 77, loss = 0.00728606\n",
      "Iteration 78, loss = 0.00717019\n",
      "Iteration 79, loss = 0.00705965\n",
      "Iteration 80, loss = 0.00839945\n",
      "Iteration 81, loss = 0.01198763\n",
      "Iteration 82, loss = 0.00888226\n",
      "Iteration 83, loss = 0.00770842\n",
      "Iteration 84, loss = 0.00712832\n",
      "Iteration 85, loss = 0.00676028\n",
      "Iteration 86, loss = 0.00656122\n",
      "Iteration 87, loss = 0.00639285\n",
      "Iteration 88, loss = 0.00633143\n",
      "Iteration 89, loss = 0.00849262\n",
      "Iteration 90, loss = 0.00940738\n",
      "Iteration 91, loss = 0.00722024\n",
      "Iteration 92, loss = 0.00626672\n",
      "Iteration 93, loss = 0.00592170\n",
      "Iteration 94, loss = 0.00750196\n",
      "Iteration 95, loss = 0.00661926\n",
      "Iteration 96, loss = 0.00605535\n",
      "Iteration 97, loss = 0.00588608\n",
      "Iteration 98, loss = 0.00598197\n",
      "Iteration 99, loss = 0.00607401\n",
      "Iteration 100, loss = 0.00754507\n",
      "Iteration 101, loss = 0.00622337\n",
      "Iteration 102, loss = 0.00524517\n",
      "Iteration 103, loss = 0.00489522\n",
      "Iteration 104, loss = 0.00477397\n",
      "Iteration 105, loss = 0.00462850\n",
      "Iteration 106, loss = 0.00450963\n",
      "Iteration 107, loss = 0.00442601\n",
      "Iteration 108, loss = 0.00432930\n",
      "Iteration 109, loss = 0.00448393\n",
      "Iteration 110, loss = 0.66142601\n",
      "Iteration 111, loss = 0.74341438\n",
      "Iteration 112, loss = 0.99065084\n",
      "Iteration 113, loss = 0.50249428\n",
      "Iteration 114, loss = 0.36889670\n",
      "Iteration 115, loss = 0.36694800\n",
      "Iteration 116, loss = 0.38752296\n",
      "Iteration 117, loss = 0.37517302\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 2.37613799\n",
      "Iteration 2, loss = 2.18532147\n",
      "Iteration 3, loss = 1.97996054\n",
      "Iteration 4, loss = 1.75708397\n",
      "Iteration 5, loss = 1.53559383\n",
      "Iteration 6, loss = 1.32738585\n",
      "Iteration 7, loss = 1.14156959\n",
      "Iteration 8, loss = 1.00756866\n",
      "Iteration 9, loss = 1.04142751\n",
      "Iteration 10, loss = 1.54271923\n",
      "Iteration 11, loss = 2.41892614\n",
      "Iteration 12, loss = 2.07695025\n",
      "Iteration 13, loss = 1.40643148\n",
      "Iteration 14, loss = 1.16819021\n",
      "Iteration 15, loss = 0.94500748\n",
      "Iteration 16, loss = 0.92561435\n",
      "Iteration 17, loss = 0.88439948\n",
      "Iteration 18, loss = 0.82643303\n",
      "Iteration 19, loss = 0.76786112\n",
      "Iteration 20, loss = 0.71352647\n",
      "Iteration 21, loss = 0.67547240\n",
      "Iteration 22, loss = 0.65627905\n",
      "Iteration 23, loss = 0.63663011\n",
      "Iteration 24, loss = 0.61184756\n",
      "Iteration 25, loss = 0.59269171\n",
      "Iteration 26, loss = 0.57482200\n",
      "Iteration 27, loss = 0.55675628\n",
      "Iteration 28, loss = 0.53989055\n",
      "Iteration 29, loss = 0.52345874\n",
      "Iteration 30, loss = 0.50742741\n",
      "Iteration 31, loss = 0.49236111\n",
      "Iteration 32, loss = 0.47804492\n",
      "Iteration 33, loss = 0.46442560\n",
      "Iteration 34, loss = 0.45134080\n",
      "Iteration 35, loss = 0.43889771\n",
      "Iteration 36, loss = 0.42693188\n",
      "Iteration 37, loss = 0.41539533\n",
      "Iteration 38, loss = 0.40453497\n",
      "Iteration 39, loss = 0.39572851\n",
      "Iteration 40, loss = 0.39124233\n",
      "Iteration 41, loss = 0.39950763\n",
      "Iteration 42, loss = 0.41761035\n",
      "Iteration 43, loss = 0.46322993\n",
      "Iteration 44, loss = 0.46039320\n",
      "Iteration 45, loss = 0.44303812\n",
      "Iteration 46, loss = 0.39239030\n",
      "Iteration 47, loss = 0.36893812\n",
      "Iteration 48, loss = 0.34479528\n",
      "Iteration 49, loss = 0.32176648\n",
      "Iteration 50, loss = 0.30550974\n",
      "Iteration 51, loss = 0.29199381\n",
      "Iteration 52, loss = 0.28197128\n",
      "Iteration 53, loss = 0.27367927\n",
      "Iteration 54, loss = 0.26656340\n",
      "Iteration 55, loss = 0.25997733\n",
      "Iteration 56, loss = 0.25378096\n",
      "Iteration 57, loss = 0.24790449\n",
      "Iteration 58, loss = 0.24214993\n",
      "Iteration 59, loss = 0.23654550\n",
      "Iteration 60, loss = 0.23111290\n",
      "Iteration 61, loss = 0.22585590\n",
      "Iteration 62, loss = 0.22073593\n",
      "Iteration 63, loss = 0.21570526\n",
      "Iteration 64, loss = 0.21075337\n",
      "Iteration 65, loss = 0.20584953\n",
      "Iteration 66, loss = 0.20099366\n",
      "Iteration 67, loss = 0.19617942\n",
      "Iteration 68, loss = 0.19147039\n",
      "Iteration 69, loss = 0.18678863\n",
      "Iteration 70, loss = 0.18219447\n",
      "Iteration 71, loss = 0.17770840\n",
      "Iteration 72, loss = 0.17330904\n",
      "Iteration 73, loss = 0.16900081\n",
      "Iteration 74, loss = 0.16478216\n",
      "Iteration 75, loss = 0.16063085\n",
      "Iteration 76, loss = 0.15662057\n",
      "Iteration 77, loss = 0.15275913\n",
      "Iteration 78, loss = 0.14903489\n",
      "Iteration 79, loss = 0.14562296\n",
      "Iteration 80, loss = 0.14285646\n",
      "Iteration 81, loss = 0.14099501\n",
      "Iteration 82, loss = 0.14236927\n",
      "Iteration 83, loss = 0.14699698\n",
      "Iteration 84, loss = 0.17030888\n",
      "Iteration 85, loss = 0.20556425\n",
      "Iteration 86, loss = 0.33087213\n",
      "Iteration 87, loss = 0.38964079\n",
      "Iteration 88, loss = 0.29459037\n",
      "Iteration 89, loss = 0.19898122\n",
      "Iteration 90, loss = 0.13879804\n",
      "Iteration 91, loss = 0.12733720\n",
      "Iteration 92, loss = 0.12314639\n",
      "Iteration 93, loss = 0.11849420\n",
      "Iteration 94, loss = 0.11366026\n",
      "Iteration 95, loss = 0.10905757\n",
      "Iteration 96, loss = 0.10482684\n",
      "Iteration 97, loss = 0.10143467\n",
      "Iteration 98, loss = 0.09847841\n",
      "Iteration 99, loss = 0.09554958\n",
      "Iteration 100, loss = 0.09289141\n",
      "Iteration 101, loss = 0.09048399\n",
      "Iteration 102, loss = 0.08831362\n",
      "Iteration 103, loss = 0.08626340\n",
      "Iteration 104, loss = 0.08435710\n",
      "Iteration 105, loss = 0.08247821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 106, loss = 0.08066051\n",
      "Iteration 107, loss = 0.07896727\n",
      "Iteration 108, loss = 0.07745968\n",
      "Iteration 109, loss = 0.07626704\n",
      "Iteration 110, loss = 0.07528423\n",
      "Iteration 111, loss = 0.07475322\n",
      "Iteration 112, loss = 0.07469229\n",
      "Iteration 113, loss = 0.07551365\n",
      "Iteration 114, loss = 0.07701332\n",
      "Iteration 115, loss = 0.08092336\n",
      "Iteration 116, loss = 0.08720354\n",
      "Iteration 117, loss = 0.10274194\n",
      "Iteration 118, loss = 0.13064736\n",
      "Iteration 119, loss = 0.21651633\n",
      "Iteration 120, loss = 0.37334208\n",
      "Iteration 121, loss = 0.56698862\n",
      "Iteration 122, loss = 0.52750582\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 2.36183547\n",
      "Iteration 2, loss = 2.18680129\n",
      "Iteration 3, loss = 2.00965333\n",
      "Iteration 4, loss = 1.80425219\n",
      "Iteration 5, loss = 1.58666664\n",
      "Iteration 6, loss = 1.37816626\n",
      "Iteration 7, loss = 1.19838573\n",
      "Iteration 8, loss = 1.12109615\n",
      "Iteration 9, loss = 1.36526104\n",
      "Iteration 10, loss = 2.09191263\n",
      "Iteration 11, loss = 1.39118190\n",
      "Iteration 12, loss = 1.19503615\n",
      "Iteration 13, loss = 1.13303279\n",
      "Iteration 14, loss = 0.96052356\n",
      "Iteration 15, loss = 0.81666672\n",
      "Iteration 16, loss = 0.73377771\n",
      "Iteration 17, loss = 0.72135430\n",
      "Iteration 18, loss = 0.70079340\n",
      "Iteration 19, loss = 0.67074541\n",
      "Iteration 20, loss = 0.64464022\n",
      "Iteration 21, loss = 0.61955474\n",
      "Iteration 22, loss = 0.59592087\n",
      "Iteration 23, loss = 0.57501899\n",
      "Iteration 24, loss = 0.55506333\n",
      "Iteration 25, loss = 0.53629510\n",
      "Iteration 26, loss = 0.51961437\n",
      "Iteration 27, loss = 0.50406041\n",
      "Iteration 28, loss = 0.48953289\n",
      "Iteration 29, loss = 0.47590710\n",
      "Iteration 30, loss = 0.46272907\n",
      "Iteration 31, loss = 0.44983198\n",
      "Iteration 32, loss = 0.43775963\n",
      "Iteration 33, loss = 0.42760003\n",
      "Iteration 34, loss = 0.42181266\n",
      "Iteration 35, loss = 0.42689721\n",
      "Iteration 36, loss = 0.45790853\n",
      "Iteration 37, loss = 0.51381310\n",
      "Iteration 38, loss = 0.55909441\n",
      "Iteration 39, loss = 0.52074094\n",
      "Iteration 40, loss = 0.42800072\n",
      "Iteration 41, loss = 0.37449347\n",
      "Iteration 42, loss = 0.35480372\n",
      "Iteration 43, loss = 0.33740185\n",
      "Iteration 44, loss = 0.32207334\n",
      "Iteration 45, loss = 0.31059260\n",
      "Iteration 46, loss = 0.30051692\n",
      "Iteration 47, loss = 0.29101433\n",
      "Iteration 48, loss = 0.28203142\n",
      "Iteration 49, loss = 0.27363040\n",
      "Iteration 50, loss = 0.26577279\n",
      "Iteration 51, loss = 0.25817824\n",
      "Iteration 52, loss = 0.25076348\n",
      "Iteration 53, loss = 0.24367874\n",
      "Iteration 54, loss = 0.23679131\n",
      "Iteration 55, loss = 0.23027262\n",
      "Iteration 56, loss = 0.22474083\n",
      "Iteration 57, loss = 0.22073331\n",
      "Iteration 58, loss = 0.22422194\n",
      "Iteration 59, loss = 0.23380137\n",
      "Iteration 60, loss = 0.30808780\n",
      "Iteration 61, loss = 0.27660383\n",
      "Iteration 62, loss = 0.45056360\n",
      "Iteration 63, loss = 0.21905623\n",
      "Iteration 64, loss = 0.19968011\n",
      "Iteration 65, loss = 0.19574002\n",
      "Iteration 66, loss = 0.19313483\n",
      "Iteration 67, loss = 0.18483176\n",
      "Iteration 68, loss = 0.18558053\n",
      "Iteration 69, loss = 0.17476979\n",
      "Iteration 70, loss = 0.17676963\n",
      "Iteration 71, loss = 0.16651821\n",
      "Iteration 72, loss = 0.17116433\n",
      "Iteration 73, loss = 0.16055286\n",
      "Iteration 74, loss = 0.16739293\n",
      "Iteration 75, loss = 0.15676913\n",
      "Iteration 76, loss = 0.16685843\n",
      "Iteration 77, loss = 0.15378302\n",
      "Iteration 78, loss = 0.16418860\n",
      "Iteration 79, loss = 0.14933069\n",
      "Iteration 80, loss = 0.15623311\n",
      "Iteration 81, loss = 0.13782285\n",
      "Iteration 82, loss = 0.13568481\n",
      "Iteration 83, loss = 0.12248017\n",
      "Iteration 84, loss = 0.11723112\n",
      "Iteration 85, loss = 0.11082036\n",
      "Iteration 86, loss = 0.10639601\n",
      "Iteration 87, loss = 0.10222999\n",
      "Iteration 88, loss = 0.09900063\n",
      "Iteration 89, loss = 0.09595281\n",
      "Iteration 90, loss = 0.09331719\n",
      "Iteration 91, loss = 0.09084011\n",
      "Iteration 92, loss = 0.08846425\n",
      "Iteration 93, loss = 0.08610867\n",
      "Iteration 94, loss = 0.08388906\n",
      "Iteration 95, loss = 0.08174583\n",
      "Iteration 96, loss = 0.07966261\n",
      "Iteration 97, loss = 0.07764334\n",
      "Iteration 98, loss = 0.07574119\n",
      "Iteration 99, loss = 0.07384938\n",
      "Iteration 100, loss = 0.07204303\n",
      "Iteration 101, loss = 0.07028383\n",
      "Iteration 102, loss = 0.06856610\n",
      "Iteration 103, loss = 0.06695489\n",
      "Iteration 104, loss = 0.06533225\n",
      "Iteration 105, loss = 0.06374195\n",
      "Iteration 106, loss = 0.06225150\n",
      "Iteration 107, loss = 0.06080745\n",
      "Iteration 108, loss = 0.05937087\n",
      "Iteration 109, loss = 0.05800474\n",
      "Iteration 110, loss = 0.05669288\n",
      "Iteration 111, loss = 0.05538261\n",
      "Iteration 112, loss = 0.05410792\n",
      "Iteration 113, loss = 0.05288774\n",
      "Iteration 114, loss = 0.05171968\n",
      "Iteration 115, loss = 0.05060338\n",
      "Iteration 116, loss = 0.04948750\n",
      "Iteration 117, loss = 0.04841138\n",
      "Iteration 118, loss = 0.04738057\n",
      "Iteration 119, loss = 0.04637955\n",
      "Iteration 120, loss = 0.04539896\n",
      "Iteration 121, loss = 0.04446883\n",
      "Iteration 122, loss = 0.04356029\n",
      "Iteration 123, loss = 0.04267180\n",
      "Iteration 124, loss = 0.04177058\n",
      "Iteration 125, loss = 0.04094963\n",
      "Iteration 126, loss = 0.04011074\n",
      "Iteration 127, loss = 0.03930502\n",
      "Iteration 128, loss = 0.03857136\n",
      "Iteration 129, loss = 0.03781233\n",
      "Iteration 130, loss = 0.03707046\n",
      "Iteration 131, loss = 0.03637731\n",
      "Iteration 132, loss = 0.03568496\n",
      "Iteration 133, loss = 0.03502866\n",
      "Iteration 134, loss = 0.03437019\n",
      "Iteration 135, loss = 0.03374992\n",
      "Iteration 136, loss = 0.03313921\n",
      "Iteration 137, loss = 0.03256777\n",
      "Iteration 138, loss = 0.03197134\n",
      "Iteration 139, loss = 0.03140985\n",
      "Iteration 140, loss = 0.03086849\n",
      "Iteration 141, loss = 0.03033328\n",
      "Iteration 142, loss = 0.02981910\n",
      "Iteration 143, loss = 0.02933405\n",
      "Iteration 144, loss = 0.02884314\n",
      "Iteration 145, loss = 0.02836802\n",
      "Iteration 146, loss = 0.02790389\n",
      "Iteration 147, loss = 0.02746357\n",
      "Iteration 148, loss = 0.02703665\n",
      "Iteration 149, loss = 0.02661281\n",
      "Iteration 150, loss = 0.02619193\n",
      "Iteration 151, loss = 0.02579879\n",
      "Iteration 152, loss = 0.02540798\n",
      "Iteration 153, loss = 0.02501721\n",
      "Iteration 154, loss = 0.02464762\n",
      "Iteration 155, loss = 0.02428262\n",
      "Iteration 156, loss = 0.02392416\n",
      "Iteration 157, loss = 0.02357958\n",
      "Iteration 158, loss = 0.02324829\n",
      "Iteration 159, loss = 0.02291729\n",
      "Iteration 160, loss = 0.02259203\n",
      "Iteration 161, loss = 0.02227791\n",
      "Iteration 162, loss = 0.02197282\n",
      "Iteration 163, loss = 0.02167382\n",
      "Iteration 164, loss = 0.02138329\n",
      "Iteration 165, loss = 0.02109757\n",
      "Iteration 166, loss = 0.02082049\n",
      "Iteration 167, loss = 0.02054475\n",
      "Iteration 168, loss = 0.02027754\n",
      "Iteration 169, loss = 0.02001998\n",
      "Iteration 170, loss = 0.01976176\n",
      "Iteration 171, loss = 0.01951052\n",
      "Iteration 172, loss = 0.01927167\n",
      "Iteration 173, loss = 0.01902588\n",
      "Iteration 174, loss = 0.01879936\n",
      "Iteration 175, loss = 0.01857219\n",
      "Iteration 176, loss = 0.01834133\n",
      "Iteration 177, loss = 0.01812722\n",
      "Iteration 178, loss = 0.01791181\n",
      "Iteration 179, loss = 0.01769923\n",
      "Iteration 180, loss = 0.01749450\n",
      "Iteration 181, loss = 0.01729521\n",
      "Iteration 182, loss = 0.01709451\n",
      "Iteration 183, loss = 0.01690508\n",
      "Iteration 184, loss = 0.01671413\n",
      "Iteration 185, loss = 0.01652655\n",
      "Iteration 186, loss = 0.01634387\n",
      "Iteration 187, loss = 0.01616558\n",
      "Iteration 188, loss = 0.01598912\n",
      "Iteration 189, loss = 0.01581513\n",
      "Iteration 190, loss = 0.01565118\n",
      "Iteration 191, loss = 0.01548119\n",
      "Iteration 192, loss = 0.01532181\n",
      "Iteration 193, loss = 0.01515939\n",
      "Iteration 194, loss = 0.01500392\n",
      "Iteration 195, loss = 0.01485437\n",
      "Iteration 196, loss = 0.01469835\n",
      "Iteration 197, loss = 0.01454894\n",
      "Iteration 198, loss = 0.01440497\n",
      "Iteration 199, loss = 0.01426335\n",
      "Iteration 200, loss = 0.01412076\n",
      "Iteration 201, loss = 0.01398505\n",
      "Iteration 202, loss = 0.01384858\n",
      "Iteration 203, loss = 0.01371491\n",
      "Iteration 204, loss = 0.01358239\n",
      "Iteration 205, loss = 0.01345461\n",
      "Iteration 206, loss = 0.01332686\n",
      "Iteration 207, loss = 0.01320184\n",
      "Iteration 208, loss = 0.01308210\n",
      "Iteration 209, loss = 0.01296159\n",
      "Iteration 210, loss = 0.01284066\n",
      "Iteration 211, loss = 0.01272559\n",
      "Iteration 212, loss = 0.01261051\n",
      "Iteration 213, loss = 0.01249631\n",
      "Iteration 214, loss = 0.01238632\n",
      "Iteration 215, loss = 0.01227714\n",
      "Iteration 216, loss = 0.01216983\n",
      "Iteration 217, loss = 0.01206191\n",
      "Iteration 218, loss = 0.01195834\n",
      "Iteration 219, loss = 0.01185652\n",
      "Iteration 220, loss = 0.01175664\n",
      "Iteration 221, loss = 0.01165542\n",
      "Iteration 222, loss = 0.01155874\n",
      "Iteration 223, loss = 0.01146176\n",
      "Iteration 224, loss = 0.01136603\n",
      "Iteration 225, loss = 0.01127326\n",
      "Iteration 226, loss = 0.01118016\n",
      "Iteration 227, loss = 0.01109098\n",
      "Iteration 228, loss = 0.01100034\n",
      "Iteration 229, loss = 0.01091139\n",
      "Iteration 230, loss = 0.01082522\n",
      "Iteration 231, loss = 0.01073791\n",
      "Iteration 232, loss = 0.01065509\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 2.37046478\n",
      "Iteration 2, loss = 2.17539952\n",
      "Iteration 3, loss = 1.98382903\n",
      "Iteration 4, loss = 1.76198328\n",
      "Iteration 5, loss = 1.54726926\n",
      "Iteration 6, loss = 1.37676546\n",
      "Iteration 7, loss = 1.37602536\n",
      "Iteration 8, loss = 1.50338275\n",
      "Iteration 9, loss = 1.65773955\n",
      "Iteration 10, loss = 1.36132582\n",
      "Iteration 11, loss = 1.36519575\n",
      "Iteration 12, loss = 1.01952101\n",
      "Iteration 13, loss = 0.90011360\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 14, loss = 0.80028632\n",
      "Iteration 15, loss = 0.73239205\n",
      "Iteration 16, loss = 0.71002662\n",
      "Iteration 17, loss = 0.68889077\n",
      "Iteration 18, loss = 0.65479904\n",
      "Iteration 19, loss = 0.62711664\n",
      "Iteration 20, loss = 0.60360077\n",
      "Iteration 21, loss = 0.58267065\n",
      "Iteration 22, loss = 0.56377543\n",
      "Iteration 23, loss = 0.54634641\n",
      "Iteration 24, loss = 0.53001510\n",
      "Iteration 25, loss = 0.51431788\n",
      "Iteration 26, loss = 0.49930944\n",
      "Iteration 27, loss = 0.48478312\n",
      "Iteration 28, loss = 0.47085324\n",
      "Iteration 29, loss = 0.45741998\n",
      "Iteration 30, loss = 0.44440415\n",
      "Iteration 31, loss = 0.43176761\n",
      "Iteration 32, loss = 0.41958697\n",
      "Iteration 33, loss = 0.40784153\n",
      "Iteration 34, loss = 0.39658140\n",
      "Iteration 35, loss = 0.38606082\n",
      "Iteration 36, loss = 0.37758144\n",
      "Iteration 37, loss = 0.37813231\n",
      "Iteration 38, loss = 0.41504559\n",
      "Iteration 39, loss = 0.61120381\n",
      "Iteration 40, loss = 0.70221793\n",
      "Iteration 41, loss = 0.70225404\n",
      "Iteration 42, loss = 0.40867730\n",
      "Iteration 43, loss = 0.34276117\n",
      "Iteration 44, loss = 0.33620150\n",
      "Iteration 45, loss = 0.32520413\n",
      "Iteration 46, loss = 0.31410711\n",
      "Iteration 47, loss = 0.30471699\n",
      "Iteration 48, loss = 0.29620681\n",
      "Iteration 49, loss = 0.28798082\n",
      "Iteration 50, loss = 0.28039616\n",
      "Iteration 51, loss = 0.27338858\n",
      "Iteration 52, loss = 0.26650965\n",
      "Iteration 53, loss = 0.25964248\n",
      "Iteration 54, loss = 0.25294444\n",
      "Iteration 55, loss = 0.24648891\n",
      "Iteration 56, loss = 0.24016226\n",
      "Iteration 57, loss = 0.23409940\n",
      "Iteration 58, loss = 0.22820039\n",
      "Iteration 59, loss = 0.22248135\n",
      "Iteration 60, loss = 0.21690609\n",
      "Iteration 61, loss = 0.21144104\n",
      "Iteration 62, loss = 0.20610571\n",
      "Iteration 63, loss = 0.20086769\n",
      "Iteration 64, loss = 0.19575670\n",
      "Iteration 65, loss = 0.19075902\n",
      "Iteration 66, loss = 0.18585196\n",
      "Iteration 67, loss = 0.18106690\n",
      "Iteration 68, loss = 0.17648746\n",
      "Iteration 69, loss = 0.17228451\n",
      "Iteration 70, loss = 0.16885176\n",
      "Iteration 71, loss = 0.16719373\n",
      "Iteration 72, loss = 0.17218424\n",
      "Iteration 73, loss = 0.18910640\n",
      "Iteration 74, loss = 0.25899220\n",
      "Iteration 75, loss = 0.35033022\n",
      "Iteration 76, loss = 0.37924130\n",
      "Iteration 77, loss = 0.39104229\n",
      "Iteration 78, loss = 0.22080789\n",
      "Iteration 79, loss = 0.18416048\n",
      "Iteration 80, loss = 0.15676053\n",
      "Iteration 81, loss = 0.14849927\n",
      "Iteration 82, loss = 0.14235451\n",
      "Iteration 83, loss = 0.13601448\n",
      "Iteration 84, loss = 0.13045519\n",
      "Iteration 85, loss = 0.12600834\n",
      "Iteration 86, loss = 0.12237232\n",
      "Iteration 87, loss = 0.11898697\n",
      "Iteration 88, loss = 0.11579473\n",
      "Iteration 89, loss = 0.11266057\n",
      "Iteration 90, loss = 0.10953817\n",
      "Iteration 91, loss = 0.10650837\n",
      "Iteration 92, loss = 0.10357358\n",
      "Iteration 93, loss = 0.10084648\n",
      "Iteration 94, loss = 0.09824752\n",
      "Iteration 95, loss = 0.09574709\n",
      "Iteration 96, loss = 0.09337338\n",
      "Iteration 97, loss = 0.09120033\n",
      "Iteration 98, loss = 0.08925690\n",
      "Iteration 99, loss = 0.08773872\n",
      "Iteration 100, loss = 0.08658234\n",
      "Iteration 101, loss = 0.08683675\n",
      "Iteration 102, loss = 0.08701194\n",
      "Iteration 103, loss = 0.09223473\n",
      "Iteration 104, loss = 0.09257584\n",
      "Iteration 105, loss = 0.10653493\n",
      "Iteration 106, loss = 0.10276756\n",
      "Iteration 107, loss = 0.12695707\n",
      "Iteration 108, loss = 0.11447733\n",
      "Iteration 109, loss = 0.13949706\n",
      "Iteration 110, loss = 0.11402997\n",
      "Iteration 111, loss = 0.11857253\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 2.37224699\n",
      "Iteration 2, loss = 2.17701203\n",
      "Iteration 3, loss = 1.97057086\n",
      "Iteration 4, loss = 1.74991500\n",
      "Iteration 5, loss = 1.52481206\n",
      "Iteration 6, loss = 1.31700250\n",
      "Iteration 7, loss = 1.17545471\n",
      "Iteration 8, loss = 1.28341660\n",
      "Iteration 9, loss = 1.64241790\n",
      "Iteration 10, loss = 1.85829446\n",
      "Iteration 11, loss = 1.63001479\n",
      "Iteration 12, loss = 1.39739270\n",
      "Iteration 13, loss = 1.12351249\n",
      "Iteration 14, loss = 1.00572966\n",
      "Iteration 15, loss = 0.93572616\n",
      "Iteration 16, loss = 0.87371015\n",
      "Iteration 17, loss = 0.81355325\n",
      "Iteration 18, loss = 0.75816750\n",
      "Iteration 19, loss = 0.70471439\n",
      "Iteration 20, loss = 0.66921838\n",
      "Iteration 21, loss = 0.64348591\n",
      "Iteration 22, loss = 0.61281927\n",
      "Iteration 23, loss = 0.58814200\n",
      "Iteration 24, loss = 0.57027030\n",
      "Iteration 25, loss = 0.55424589\n",
      "Iteration 26, loss = 0.53929706\n",
      "Iteration 27, loss = 0.52525247\n",
      "Iteration 28, loss = 0.51143344\n",
      "Iteration 29, loss = 0.49782842\n",
      "Iteration 30, loss = 0.48408768\n",
      "Iteration 31, loss = 0.47064217\n",
      "Iteration 32, loss = 0.45764813\n",
      "Iteration 33, loss = 0.44548073\n",
      "Iteration 34, loss = 0.43389678\n",
      "Iteration 35, loss = 0.42290449\n",
      "Iteration 36, loss = 0.41273691\n",
      "Iteration 37, loss = 0.40332319\n",
      "Iteration 38, loss = 0.39560520\n",
      "Iteration 39, loss = 0.39122981\n",
      "Iteration 40, loss = 0.39724077\n",
      "Iteration 41, loss = 0.42116564\n",
      "Iteration 42, loss = 0.48828616\n",
      "Iteration 43, loss = 0.56362359\n",
      "Iteration 44, loss = 0.50307073\n",
      "Iteration 45, loss = 0.44678387\n",
      "Iteration 46, loss = 0.40961208\n",
      "Iteration 47, loss = 0.39317051\n",
      "Iteration 48, loss = 0.37413712\n",
      "Iteration 49, loss = 0.34641037\n",
      "Iteration 50, loss = 0.32681438\n",
      "Iteration 51, loss = 0.31291722\n",
      "Iteration 52, loss = 0.30297138\n",
      "Iteration 53, loss = 0.29513783\n",
      "Iteration 54, loss = 0.28864468\n",
      "Iteration 55, loss = 0.28278897\n",
      "Iteration 56, loss = 0.27725923\n",
      "Iteration 57, loss = 0.27189838\n",
      "Iteration 58, loss = 0.26665693\n",
      "Iteration 59, loss = 0.26146228\n",
      "Iteration 60, loss = 0.25623645\n",
      "Iteration 61, loss = 0.25116282\n",
      "Iteration 62, loss = 0.24619497\n",
      "Iteration 63, loss = 0.24131808\n",
      "Iteration 64, loss = 0.23650019\n",
      "Iteration 65, loss = 0.23173858\n",
      "Iteration 66, loss = 0.22704068\n",
      "Iteration 67, loss = 0.22239367\n",
      "Iteration 68, loss = 0.21779963\n",
      "Iteration 69, loss = 0.21326400\n",
      "Iteration 70, loss = 0.20877958\n",
      "Iteration 71, loss = 0.20433372\n",
      "Iteration 72, loss = 0.19995439\n",
      "Iteration 73, loss = 0.19562125\n",
      "Iteration 74, loss = 0.19134385\n",
      "Iteration 75, loss = 0.18712348\n",
      "Iteration 76, loss = 0.18295873\n",
      "Iteration 77, loss = 0.17883385\n",
      "Iteration 78, loss = 0.17478136\n",
      "Iteration 79, loss = 0.17082665\n",
      "Iteration 80, loss = 0.16687514\n",
      "Iteration 81, loss = 0.16303760\n",
      "Iteration 82, loss = 0.15945674\n",
      "Iteration 83, loss = 0.15616112\n",
      "Iteration 84, loss = 0.15330826\n",
      "Iteration 85, loss = 0.15123332\n",
      "Iteration 86, loss = 0.14989872\n",
      "Iteration 87, loss = 0.15213891\n",
      "Iteration 88, loss = 0.15603339\n",
      "Iteration 89, loss = 0.17200438\n",
      "Iteration 90, loss = 0.18945241\n",
      "Iteration 91, loss = 0.23690878\n",
      "Iteration 92, loss = 0.26962106\n",
      "Iteration 93, loss = 0.25720871\n",
      "Iteration 94, loss = 0.24558954\n",
      "Iteration 95, loss = 0.18018359\n",
      "Iteration 96, loss = 0.14960963\n",
      "Iteration 97, loss = 0.13028381\n",
      "Iteration 98, loss = 0.12157677\n",
      "Iteration 99, loss = 0.11699012\n",
      "Iteration 100, loss = 0.11418086\n",
      "Iteration 101, loss = 0.11065815\n",
      "Iteration 102, loss = 0.10836813\n",
      "Iteration 103, loss = 0.10517314\n",
      "Iteration 104, loss = 0.10302687\n",
      "Iteration 105, loss = 0.09980967\n",
      "Iteration 106, loss = 0.09781358\n",
      "Iteration 107, loss = 0.09530604\n",
      "Iteration 108, loss = 0.09375383\n",
      "Iteration 109, loss = 0.09145610\n",
      "Iteration 110, loss = 0.09016613\n",
      "Iteration 111, loss = 0.08785096\n",
      "Iteration 112, loss = 0.08676758\n",
      "Iteration 113, loss = 0.08451900\n",
      "Iteration 114, loss = 0.08350841\n",
      "Iteration 115, loss = 0.08118428\n",
      "Iteration 116, loss = 0.08005752\n",
      "Iteration 117, loss = 0.07766769\n",
      "Iteration 118, loss = 0.07635391\n",
      "Iteration 119, loss = 0.07380080\n",
      "Iteration 120, loss = 0.07217754\n",
      "Iteration 121, loss = 0.06918772\n",
      "Iteration 122, loss = 0.06692715\n",
      "Iteration 123, loss = 0.06424734\n",
      "Iteration 124, loss = 0.06214156\n",
      "Iteration 125, loss = 0.06010053\n",
      "Iteration 126, loss = 0.05846438\n",
      "Iteration 127, loss = 0.05680609\n",
      "Iteration 128, loss = 0.05531910\n",
      "Iteration 129, loss = 0.05392119\n",
      "Iteration 130, loss = 0.05261923\n",
      "Iteration 131, loss = 0.05140836\n",
      "Iteration 132, loss = 0.05022320\n",
      "Iteration 133, loss = 0.04909664\n",
      "Iteration 134, loss = 0.04804516\n",
      "Iteration 135, loss = 0.04701512\n",
      "Iteration 136, loss = 0.04601317\n",
      "Iteration 137, loss = 0.04503581\n",
      "Iteration 138, loss = 0.04409475\n",
      "Iteration 139, loss = 0.04319350\n",
      "Iteration 140, loss = 0.04230713\n",
      "Iteration 141, loss = 0.04144850\n",
      "Iteration 142, loss = 0.04061347\n",
      "Iteration 143, loss = 0.03980269\n",
      "Iteration 144, loss = 0.03902951\n",
      "Iteration 145, loss = 0.03826297\n",
      "Iteration 146, loss = 0.03752727\n",
      "Iteration 147, loss = 0.03681675\n",
      "Iteration 148, loss = 0.03611803\n",
      "Iteration 149, loss = 0.03544431\n",
      "Iteration 150, loss = 0.03479050\n",
      "Iteration 151, loss = 0.03415441\n",
      "Iteration 152, loss = 0.03353709\n",
      "Iteration 153, loss = 0.03293513\n",
      "Iteration 154, loss = 0.03235341\n",
      "Iteration 155, loss = 0.03179145\n",
      "Iteration 156, loss = 0.03123439\n",
      "Iteration 157, loss = 0.03069722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 158, loss = 0.03017269\n",
      "Iteration 159, loss = 0.02966346\n",
      "Iteration 160, loss = 0.02917215\n",
      "Iteration 161, loss = 0.02868404\n",
      "Iteration 162, loss = 0.02821463\n",
      "Iteration 163, loss = 0.02775668\n",
      "Iteration 164, loss = 0.02731160\n",
      "Iteration 165, loss = 0.02687930\n",
      "Iteration 166, loss = 0.02645599\n",
      "Iteration 167, loss = 0.02604329\n",
      "Iteration 168, loss = 0.02563706\n",
      "Iteration 169, loss = 0.02524648\n",
      "Iteration 170, loss = 0.02486550\n",
      "Iteration 171, loss = 0.02448964\n",
      "Iteration 172, loss = 0.02412660\n",
      "Iteration 173, loss = 0.02377276\n",
      "Iteration 174, loss = 0.02342632\n",
      "Iteration 175, loss = 0.02308717\n",
      "Iteration 176, loss = 0.02275829\n",
      "Iteration 177, loss = 0.02243924\n",
      "Iteration 178, loss = 0.02212199\n",
      "Iteration 179, loss = 0.02181667\n",
      "Iteration 180, loss = 0.02151446\n",
      "Iteration 181, loss = 0.02122057\n",
      "Iteration 182, loss = 0.02093772\n",
      "Iteration 183, loss = 0.02065347\n",
      "Iteration 184, loss = 0.02038057\n",
      "Iteration 185, loss = 0.02011447\n",
      "Iteration 186, loss = 0.01984934\n",
      "Iteration 187, loss = 0.01959496\n",
      "Iteration 188, loss = 0.01934561\n",
      "Iteration 189, loss = 0.01909932\n",
      "Iteration 190, loss = 0.01886000\n",
      "Iteration 191, loss = 0.01862581\n",
      "Iteration 192, loss = 0.01839596\n",
      "Iteration 193, loss = 0.01817120\n",
      "Iteration 194, loss = 0.01795100\n",
      "Iteration 195, loss = 0.01773533\n",
      "Iteration 196, loss = 0.01752358\n",
      "Iteration 197, loss = 0.01731923\n",
      "Iteration 198, loss = 0.01711522\n",
      "Iteration 199, loss = 0.01691714\n",
      "Iteration 200, loss = 0.01672373\n",
      "Iteration 201, loss = 0.01653161\n",
      "Iteration 202, loss = 0.01634575\n",
      "Iteration 203, loss = 0.01616398\n",
      "Iteration 204, loss = 0.01598236\n",
      "Iteration 205, loss = 0.01580655\n",
      "Iteration 206, loss = 0.01563418\n",
      "Iteration 207, loss = 0.01546432\n",
      "Iteration 208, loss = 0.01529927\n",
      "Iteration 209, loss = 0.01513525\n",
      "Iteration 210, loss = 0.01497624\n",
      "Iteration 211, loss = 0.01481895\n",
      "Iteration 212, loss = 0.01466616\n",
      "Iteration 213, loss = 0.01451542\n",
      "Iteration 214, loss = 0.01436711\n",
      "Iteration 215, loss = 0.01422138\n",
      "Iteration 216, loss = 0.01407895\n",
      "Iteration 217, loss = 0.01393874\n",
      "Iteration 218, loss = 0.01380082\n",
      "Iteration 219, loss = 0.01366517\n",
      "Iteration 220, loss = 0.01353245\n",
      "Iteration 221, loss = 0.01340156\n",
      "Iteration 222, loss = 0.01327335\n",
      "Iteration 223, loss = 0.01314753\n",
      "Iteration 224, loss = 0.01302207\n",
      "Iteration 225, loss = 0.01290036\n",
      "Iteration 226, loss = 0.01278048\n",
      "Iteration 227, loss = 0.01266273\n",
      "Iteration 228, loss = 0.01254622\n",
      "Iteration 229, loss = 0.01243189\n",
      "Iteration 230, loss = 0.01231990\n",
      "Iteration 231, loss = 0.01220889\n",
      "Iteration 232, loss = 0.01210025\n",
      "Iteration 233, loss = 0.01199310\n",
      "Iteration 234, loss = 0.01188859\n",
      "Iteration 235, loss = 0.01178334\n",
      "Iteration 236, loss = 0.01168192\n",
      "Iteration 237, loss = 0.01158138\n",
      "Iteration 238, loss = 0.01148230\n",
      "Iteration 239, loss = 0.01138418\n",
      "Iteration 240, loss = 0.01128896\n",
      "Iteration 241, loss = 0.01119390\n",
      "Iteration 242, loss = 0.01110050\n",
      "Iteration 243, loss = 0.01100853\n",
      "Iteration 244, loss = 0.01091846\n",
      "Iteration 245, loss = 0.01082955\n",
      "Iteration 246, loss = 0.01074131\n",
      "Iteration 247, loss = 0.01065493\n",
      "Iteration 248, loss = 0.01056975\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 2.36959837\n",
      "Iteration 2, loss = 2.16415860\n",
      "Iteration 3, loss = 1.96615452\n",
      "Iteration 4, loss = 1.74000418\n",
      "Iteration 5, loss = 1.52954177\n",
      "Iteration 6, loss = 1.32893460\n",
      "Iteration 7, loss = 1.15518943\n",
      "Iteration 8, loss = 1.03673073\n",
      "Iteration 9, loss = 1.08508067\n",
      "Iteration 10, loss = 1.62985315\n",
      "Iteration 11, loss = 1.19333218\n",
      "Iteration 12, loss = 1.31795136\n",
      "Iteration 13, loss = 1.20113882\n",
      "Iteration 14, loss = 0.95607414\n",
      "Iteration 15, loss = 0.81860256\n",
      "Iteration 16, loss = 0.71377844\n",
      "Iteration 17, loss = 0.68611330\n",
      "Iteration 18, loss = 0.66192791\n",
      "Iteration 19, loss = 0.64034075\n",
      "Iteration 20, loss = 0.62240971\n",
      "Iteration 21, loss = 0.60530912\n",
      "Iteration 22, loss = 0.58958261\n",
      "Iteration 23, loss = 0.57496546\n",
      "Iteration 24, loss = 0.56081957\n",
      "Iteration 25, loss = 0.54670354\n",
      "Iteration 26, loss = 0.53266940\n",
      "Iteration 27, loss = 0.51887029\n",
      "Iteration 28, loss = 0.50523497\n",
      "Iteration 29, loss = 0.49197292\n",
      "Iteration 30, loss = 0.47910640\n",
      "Iteration 31, loss = 0.46651702\n",
      "Iteration 32, loss = 0.45438210\n",
      "Iteration 33, loss = 0.44272485\n",
      "Iteration 34, loss = 0.43226580\n",
      "Iteration 35, loss = 0.42475450\n",
      "Iteration 36, loss = 0.42569328\n",
      "Iteration 37, loss = 0.45072783\n",
      "Iteration 38, loss = 0.48838021\n",
      "Iteration 39, loss = 0.55172270\n",
      "Iteration 40, loss = 0.43362305\n",
      "Iteration 41, loss = 0.41484518\n",
      "Iteration 42, loss = 0.39919163\n",
      "Iteration 43, loss = 0.40252242\n",
      "Iteration 44, loss = 0.39119354\n",
      "Iteration 45, loss = 0.38431807\n",
      "Iteration 46, loss = 0.35964540\n",
      "Iteration 47, loss = 0.33615809\n",
      "Iteration 48, loss = 0.32376712\n",
      "Iteration 49, loss = 0.30851224\n",
      "Iteration 50, loss = 0.30217083\n",
      "Iteration 51, loss = 0.28960834\n",
      "Iteration 52, loss = 0.28444901\n",
      "Iteration 53, loss = 0.27545408\n",
      "Iteration 54, loss = 0.27356306\n",
      "Iteration 55, loss = 0.26618221\n",
      "Iteration 56, loss = 0.26967526\n",
      "Iteration 57, loss = 0.26281400\n",
      "Iteration 58, loss = 0.27741108\n",
      "Iteration 59, loss = 0.26330223\n",
      "Iteration 60, loss = 0.28140682\n",
      "Iteration 61, loss = 0.25367239\n",
      "Iteration 62, loss = 0.26175104\n",
      "Iteration 63, loss = 0.23369867\n",
      "Iteration 64, loss = 0.23477407\n",
      "Iteration 65, loss = 0.22076119\n",
      "Iteration 66, loss = 0.22642421\n",
      "Iteration 67, loss = 0.21255091\n",
      "Iteration 68, loss = 0.22003087\n",
      "Iteration 69, loss = 0.20238771\n",
      "Iteration 70, loss = 0.20880119\n",
      "Iteration 71, loss = 0.20212168\n",
      "Iteration 72, loss = 0.21438873\n",
      "Iteration 73, loss = 0.23616215\n",
      "Iteration 74, loss = 0.25811748\n",
      "Iteration 75, loss = 0.30463499\n",
      "Iteration 76, loss = 0.29443105\n",
      "Iteration 77, loss = 0.29298847\n",
      "Iteration 78, loss = 0.24384020\n",
      "Iteration 79, loss = 0.20297441\n",
      "Iteration 80, loss = 0.16002914\n",
      "Iteration 81, loss = 0.14139779\n",
      "Iteration 82, loss = 0.13465668\n",
      "Iteration 83, loss = 0.13043448\n",
      "Iteration 84, loss = 0.12651485\n",
      "Iteration 85, loss = 0.12270368\n",
      "Iteration 86, loss = 0.11901389\n",
      "Iteration 87, loss = 0.11541496\n",
      "Iteration 88, loss = 0.11206879\n",
      "Iteration 89, loss = 0.10890548\n",
      "Iteration 90, loss = 0.10592065\n",
      "Iteration 91, loss = 0.10310109\n",
      "Iteration 92, loss = 0.10069344\n",
      "Iteration 93, loss = 0.09921067\n",
      "Iteration 94, loss = 0.09852950\n",
      "Iteration 95, loss = 0.10176400\n",
      "Iteration 96, loss = 0.10823170\n",
      "Iteration 97, loss = 0.12832123\n",
      "Iteration 98, loss = 0.15304720\n",
      "Iteration 99, loss = 0.26293376\n",
      "Iteration 100, loss = 0.21884244\n",
      "Iteration 101, loss = 0.37379496\n",
      "Iteration 102, loss = 0.17475270\n",
      "Iteration 103, loss = 0.12812854\n",
      "Iteration 104, loss = 0.10425291\n",
      "Iteration 105, loss = 0.08496951\n",
      "Iteration 106, loss = 0.08058326\n",
      "Iteration 107, loss = 0.07767177\n",
      "Iteration 108, loss = 0.07441803\n",
      "Iteration 109, loss = 0.07145280\n",
      "Iteration 110, loss = 0.06898275\n",
      "Iteration 111, loss = 0.06691225\n",
      "Iteration 112, loss = 0.06486569\n",
      "Iteration 113, loss = 0.06287792\n",
      "Iteration 114, loss = 0.06106187\n",
      "Iteration 115, loss = 0.05938521\n",
      "Iteration 116, loss = 0.05781182\n",
      "Iteration 117, loss = 0.05627793\n",
      "Iteration 118, loss = 0.05482534\n",
      "Iteration 119, loss = 0.05342103\n",
      "Iteration 120, loss = 0.05205940\n",
      "Iteration 121, loss = 0.05075540\n",
      "Iteration 122, loss = 0.04951120\n",
      "Iteration 123, loss = 0.04831636\n",
      "Iteration 124, loss = 0.04715698\n",
      "Iteration 125, loss = 0.04607298\n",
      "Iteration 126, loss = 0.04501907\n",
      "Iteration 127, loss = 0.04401178\n",
      "Iteration 128, loss = 0.04303498\n",
      "Iteration 129, loss = 0.04209773\n",
      "Iteration 130, loss = 0.04117677\n",
      "Iteration 131, loss = 0.04028218\n",
      "Iteration 132, loss = 0.03942997\n",
      "Iteration 133, loss = 0.03861354\n",
      "Iteration 134, loss = 0.03782620\n",
      "Iteration 135, loss = 0.03706544\n",
      "Iteration 136, loss = 0.03632552\n",
      "Iteration 137, loss = 0.03560886\n",
      "Iteration 138, loss = 0.03493750\n",
      "Iteration 139, loss = 0.03425048\n",
      "Iteration 140, loss = 0.03358568\n",
      "Iteration 141, loss = 0.03295108\n",
      "Iteration 142, loss = 0.03233778\n",
      "Iteration 143, loss = 0.03173815\n",
      "Iteration 144, loss = 0.03115585\n",
      "Iteration 145, loss = 0.03059398\n",
      "Iteration 146, loss = 0.03004869\n",
      "Iteration 147, loss = 0.02951890\n",
      "Iteration 148, loss = 0.02900598\n",
      "Iteration 149, loss = 0.02851688\n",
      "Iteration 150, loss = 0.02806308\n",
      "Iteration 151, loss = 0.02756695\n",
      "Iteration 152, loss = 0.02708164\n",
      "Iteration 153, loss = 0.02664723\n",
      "Iteration 154, loss = 0.02622261\n",
      "Iteration 155, loss = 0.02579030\n",
      "Iteration 156, loss = 0.02538799\n",
      "Iteration 157, loss = 0.02497858\n",
      "Iteration 158, loss = 0.02458818\n",
      "Iteration 159, loss = 0.02420599\n",
      "Iteration 160, loss = 0.02384293\n",
      "Iteration 161, loss = 0.02348220\n",
      "Iteration 162, loss = 0.02313306\n",
      "Iteration 163, loss = 0.02279948\n",
      "Iteration 164, loss = 0.02246351\n",
      "Iteration 165, loss = 0.02213699\n",
      "Iteration 166, loss = 0.02182139\n",
      "Iteration 167, loss = 0.02152503\n",
      "Iteration 168, loss = 0.02122071\n",
      "Iteration 169, loss = 0.02091931\n",
      "Iteration 170, loss = 0.02063975\n",
      "Iteration 171, loss = 0.02036741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 172, loss = 0.02009583\n",
      "Iteration 173, loss = 0.01983616\n",
      "Iteration 174, loss = 0.01956375\n",
      "Iteration 175, loss = 0.01930602\n",
      "Iteration 176, loss = 0.01905931\n",
      "Iteration 177, loss = 0.01881471\n",
      "Iteration 178, loss = 0.01857923\n",
      "Iteration 179, loss = 0.01835495\n",
      "Iteration 180, loss = 0.01812586\n",
      "Iteration 181, loss = 0.01790222\n",
      "Iteration 182, loss = 0.01768267\n",
      "Iteration 183, loss = 0.01747523\n",
      "Iteration 184, loss = 0.01727246\n",
      "Iteration 185, loss = 0.01706420\n",
      "Iteration 186, loss = 0.01686844\n",
      "Iteration 187, loss = 0.01666820\n",
      "Iteration 188, loss = 0.01648056\n",
      "Iteration 189, loss = 0.01629814\n",
      "Iteration 190, loss = 0.01611110\n",
      "Iteration 191, loss = 0.01592874\n",
      "Iteration 192, loss = 0.01575479\n",
      "Iteration 193, loss = 0.01558463\n",
      "Iteration 194, loss = 0.01542290\n",
      "Iteration 195, loss = 0.01525043\n",
      "Iteration 196, loss = 0.01508932\n",
      "Iteration 197, loss = 0.01492710\n",
      "Iteration 198, loss = 0.01477074\n",
      "Iteration 199, loss = 0.01462300\n",
      "Iteration 200, loss = 0.01447114\n",
      "Iteration 201, loss = 0.01432374\n",
      "Iteration 202, loss = 0.01418481\n",
      "Iteration 203, loss = 0.01403466\n",
      "Iteration 204, loss = 0.01389437\n",
      "Iteration 205, loss = 0.01376320\n",
      "Iteration 206, loss = 0.01362270\n",
      "Iteration 207, loss = 0.01349022\n",
      "Iteration 208, loss = 0.01335957\n",
      "Iteration 209, loss = 0.01323526\n",
      "Iteration 210, loss = 0.01310738\n",
      "Iteration 211, loss = 0.01298871\n",
      "Iteration 212, loss = 0.01286053\n",
      "Iteration 213, loss = 0.01274063\n",
      "Iteration 214, loss = 0.01262971\n",
      "Iteration 215, loss = 0.01250994\n",
      "Iteration 216, loss = 0.01239474\n",
      "Iteration 217, loss = 0.01228496\n",
      "Iteration 218, loss = 0.01217259\n",
      "Iteration 219, loss = 0.01206642\n",
      "Iteration 220, loss = 0.01196293\n",
      "Iteration 221, loss = 0.01185424\n",
      "Iteration 222, loss = 0.01175109\n",
      "Iteration 223, loss = 0.01165011\n",
      "Iteration 224, loss = 0.01155625\n",
      "Iteration 225, loss = 0.01145258\n",
      "Iteration 226, loss = 0.01135691\n",
      "Iteration 227, loss = 0.01126388\n",
      "Iteration 228, loss = 0.01116913\n",
      "Iteration 229, loss = 0.01107809\n",
      "Iteration 230, loss = 0.01098583\n",
      "Iteration 231, loss = 0.01089621\n",
      "Iteration 232, loss = 0.01080736\n",
      "Iteration 233, loss = 0.01072211\n",
      "Iteration 234, loss = 0.01063604\n",
      "Iteration 235, loss = 0.01055160\n",
      "Iteration 236, loss = 0.01046890\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 2.33375455\n",
      "Iteration 2, loss = 1.95395769\n",
      "Iteration 3, loss = 1.63170695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:  3.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4, loss = 1.37117934\n",
      "Iteration 5, loss = 1.34924124\n",
      "Iteration 6, loss = 1.19630673\n",
      "Iteration 7, loss = 0.95599480\n",
      "Iteration 8, loss = 0.74890833\n",
      "Iteration 9, loss = 0.75256401\n",
      "Iteration 10, loss = 0.75506096\n",
      "Iteration 11, loss = 0.63115578\n",
      "Iteration 12, loss = 0.68642097\n",
      "Iteration 13, loss = 0.58672869\n",
      "Iteration 14, loss = 0.57074384\n",
      "Iteration 15, loss = 0.57889236\n",
      "Iteration 16, loss = 0.53305251\n",
      "Iteration 17, loss = 0.53576294\n",
      "Iteration 18, loss = 0.48046269\n",
      "Iteration 19, loss = 0.47154722\n",
      "Iteration 20, loss = 0.46451914\n",
      "Iteration 21, loss = 0.48091467\n",
      "Iteration 22, loss = 0.44566212\n",
      "Iteration 23, loss = 0.40889144\n",
      "Iteration 24, loss = 0.39389645\n",
      "Iteration 25, loss = 0.47869172\n",
      "Iteration 26, loss = 0.38591744\n",
      "Iteration 27, loss = 0.35246264\n",
      "Iteration 28, loss = 0.33539610\n",
      "Iteration 29, loss = 0.32369078\n",
      "Iteration 30, loss = 0.40196540\n",
      "Iteration 31, loss = 0.39611063\n",
      "Iteration 32, loss = 0.29047479\n",
      "Iteration 33, loss = 0.30375363\n",
      "Iteration 34, loss = 0.34274974\n",
      "Iteration 35, loss = 0.34112010\n",
      "Iteration 36, loss = 0.29945944\n",
      "Iteration 37, loss = 0.27866129\n",
      "Iteration 38, loss = 0.24221548\n",
      "Iteration 39, loss = 0.23142195\n",
      "Iteration 40, loss = 0.23120384\n",
      "Iteration 41, loss = 0.22347360\n",
      "Iteration 42, loss = 0.23006830\n",
      "Iteration 43, loss = 0.25553134\n",
      "Iteration 44, loss = 0.21189415\n",
      "Iteration 45, loss = 0.18039387\n",
      "Iteration 46, loss = 0.19038450\n",
      "Iteration 47, loss = 0.23714989\n",
      "Iteration 48, loss = 0.33310093\n",
      "Iteration 49, loss = 0.25258873\n",
      "Iteration 50, loss = 0.18348793\n",
      "Iteration 51, loss = 0.23505218\n",
      "Iteration 52, loss = 0.21653795\n",
      "Iteration 53, loss = 0.22314512\n",
      "Iteration 54, loss = 0.15730780\n",
      "Iteration 55, loss = 0.13386422\n",
      "Iteration 56, loss = 0.12739659\n",
      "Iteration 57, loss = 0.11317256\n",
      "Iteration 58, loss = 0.17665348\n",
      "Iteration 59, loss = 0.11275631\n",
      "Iteration 60, loss = 0.10933439\n",
      "Iteration 61, loss = 0.10880576\n",
      "Iteration 62, loss = 0.14479497\n",
      "Iteration 63, loss = 0.28422746\n",
      "Iteration 64, loss = 0.19377238\n",
      "Iteration 65, loss = 0.12445746\n",
      "Iteration 66, loss = 0.10827854\n",
      "Iteration 67, loss = 0.13592126\n",
      "Iteration 68, loss = 0.11991485\n",
      "Iteration 69, loss = 0.10442919\n",
      "Iteration 70, loss = 0.08283064\n",
      "Iteration 71, loss = 0.08625352\n",
      "Iteration 72, loss = 0.08306020\n",
      "Iteration 73, loss = 0.06626740\n",
      "Iteration 74, loss = 0.07142397\n",
      "Iteration 75, loss = 0.09009059\n",
      "Iteration 76, loss = 0.07494747\n",
      "Iteration 77, loss = 0.07647144\n",
      "Iteration 78, loss = 0.07443952\n",
      "Iteration 79, loss = 0.05301079\n",
      "Iteration 80, loss = 0.04703205\n",
      "Iteration 81, loss = 0.04398246\n",
      "Iteration 82, loss = 0.04386514\n",
      "Iteration 83, loss = 0.04321328\n",
      "Iteration 84, loss = 0.03917493\n",
      "Iteration 85, loss = 0.03658973\n",
      "Iteration 86, loss = 0.03730476\n",
      "Iteration 87, loss = 0.03698167\n",
      "Iteration 88, loss = 0.03702329\n",
      "Iteration 89, loss = 0.04530057\n",
      "Iteration 90, loss = 0.03560652\n",
      "Iteration 91, loss = 0.03520234\n",
      "Iteration 92, loss = 0.03133217\n",
      "Iteration 93, loss = 0.02905291\n",
      "Iteration 94, loss = 0.02761130\n",
      "Iteration 95, loss = 0.02787854\n",
      "Iteration 96, loss = 0.02621049\n",
      "Iteration 97, loss = 0.02608868\n",
      "Iteration 98, loss = 0.02543080\n",
      "Iteration 99, loss = 0.02864170\n",
      "Iteration 100, loss = 0.02375486\n",
      "Iteration 101, loss = 0.02449328\n",
      "Iteration 102, loss = 0.02287560\n",
      "Iteration 103, loss = 0.02402987\n",
      "Iteration 104, loss = 0.02218135\n",
      "Iteration 105, loss = 0.02082091\n",
      "Iteration 106, loss = 0.02306657\n",
      "Iteration 107, loss = 0.02052284\n",
      "Iteration 108, loss = 0.01990471\n",
      "Iteration 109, loss = 0.02017000\n",
      "Iteration 110, loss = 0.01897832\n",
      "Iteration 111, loss = 0.01996771\n",
      "Iteration 112, loss = 0.01842195\n",
      "Iteration 113, loss = 0.01718448\n",
      "Iteration 114, loss = 0.01752210\n",
      "Iteration 115, loss = 0.01721764\n",
      "Iteration 116, loss = 0.01691346\n",
      "Iteration 117, loss = 0.01661378\n",
      "Iteration 118, loss = 0.01574833\n",
      "Iteration 119, loss = 0.01729862\n",
      "Iteration 120, loss = 0.01508698\n",
      "Iteration 121, loss = 0.01531907\n",
      "Iteration 122, loss = 0.01600076\n",
      "Iteration 123, loss = 0.01423411\n",
      "Iteration 124, loss = 0.01395857\n",
      "Iteration 125, loss = 0.01389018\n",
      "Iteration 126, loss = 0.01484122\n",
      "Iteration 127, loss = 0.01383949\n",
      "Iteration 128, loss = 0.01321943\n",
      "Iteration 129, loss = 0.01338153\n",
      "Iteration 130, loss = 0.01302325\n",
      "Iteration 131, loss = 0.01332781\n",
      "Iteration 132, loss = 0.01236109\n",
      "Iteration 133, loss = 0.01323727\n",
      "Iteration 134, loss = 0.01195623\n",
      "Iteration 135, loss = 0.01190768\n",
      "Iteration 136, loss = 0.01232117\n",
      "Iteration 137, loss = 0.01251488\n",
      "Iteration 138, loss = 0.01131679\n",
      "Iteration 139, loss = 0.01136297\n",
      "Iteration 140, loss = 0.01136313\n",
      "Iteration 141, loss = 0.01093677\n",
      "Iteration 142, loss = 0.01063422\n",
      "Iteration 143, loss = 0.01060228\n",
      "Iteration 144, loss = 0.01037425\n",
      "Iteration 145, loss = 0.01018780\n",
      "Iteration 146, loss = 0.01014770\n",
      "Iteration 147, loss = 0.01011029\n",
      "Iteration 148, loss = 0.00989661\n",
      "Iteration 149, loss = 0.00977594\n",
      "Iteration 150, loss = 0.00958801\n",
      "Iteration 151, loss = 0.00971153\n",
      "Iteration 152, loss = 0.00946077\n",
      "Iteration 153, loss = 0.00931185\n",
      "Iteration 154, loss = 0.00921052\n",
      "Iteration 155, loss = 0.00906172\n",
      "Iteration 156, loss = 0.00911090\n",
      "Iteration 157, loss = 0.00896655\n",
      "Iteration 158, loss = 0.00874790\n",
      "Iteration 159, loss = 0.00865950\n",
      "Iteration 160, loss = 0.00872522\n",
      "Iteration 161, loss = 0.00849434\n",
      "Iteration 162, loss = 0.00853675\n",
      "Iteration 163, loss = 0.00834371\n",
      "Iteration 164, loss = 0.00824139\n",
      "Iteration 165, loss = 0.00814658\n",
      "Iteration 166, loss = 0.00791929\n",
      "Iteration 167, loss = 0.00804625\n",
      "Iteration 168, loss = 0.00788661\n",
      "Iteration 169, loss = 0.00771955\n",
      "Iteration 170, loss = 0.00760221\n",
      "Iteration 171, loss = 0.00758954\n",
      "Iteration 172, loss = 0.00755075\n",
      "Iteration 173, loss = 0.00749323\n",
      "Iteration 174, loss = 0.00749668\n",
      "Iteration 175, loss = 0.00727100\n",
      "Iteration 176, loss = 0.00727111\n",
      "Iteration 177, loss = 0.00714362\n",
      "Iteration 178, loss = 0.00714447\n",
      "Iteration 179, loss = 0.00709329\n",
      "Iteration 180, loss = 0.00746585\n",
      "Iteration 181, loss = 0.00695563\n",
      "Iteration 182, loss = 0.00678327\n",
      "Iteration 183, loss = 0.00670461\n",
      "Iteration 184, loss = 0.00663473\n",
      "Iteration 185, loss = 0.00657662\n",
      "Iteration 186, loss = 0.00661915\n",
      "Iteration 187, loss = 0.00646382\n",
      "Iteration 188, loss = 0.00652898\n",
      "Iteration 189, loss = 0.00643627\n",
      "Iteration 190, loss = 0.00628676\n",
      "Iteration 191, loss = 0.00627103\n",
      "Iteration 192, loss = 0.00637001\n",
      "Iteration 193, loss = 0.00617836\n",
      "Iteration 194, loss = 0.00604718\n",
      "Iteration 195, loss = 0.00599331\n",
      "Iteration 196, loss = 0.00596297\n",
      "Iteration 197, loss = 0.00595838\n",
      "Iteration 198, loss = 0.00591513\n",
      "Iteration 199, loss = 0.00576722\n",
      "Iteration 200, loss = 0.00579593\n",
      "Iteration 201, loss = 0.00576219\n",
      "Iteration 202, loss = 0.00570512\n",
      "Iteration 203, loss = 0.00570527\n",
      "Iteration 204, loss = 0.00563527\n",
      "Iteration 205, loss = 0.00559551\n",
      "Iteration 206, loss = 0.00553326\n",
      "Iteration 207, loss = 0.00548123\n",
      "Iteration 208, loss = 0.00540147\n",
      "Iteration 209, loss = 0.00534484\n",
      "Iteration 210, loss = 0.00541210\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "RESULTS FOR NN\n",
      "\n",
      "Best parameters set found:\n",
      "{'batch_size': 480}\n",
      "Score with best parameters:\n",
      "0.765\n",
      "\n",
      "All scores on the grid:\n",
      "[0.07333333 0.73       0.765     ]\n"
     ]
    }
   ],
   "source": [
    "# these are sample values corresponding to baseline SGD, a reasonable mini-batch size and standard GD\n",
    "# again feel free to change them as you like, try to experiment with different batch sizes!!\n",
    "parameters = {'batch_size': [1,32, 480]}\n",
    "\n",
    "# need to specify that you would like to use the standard k-fold split otherwise sklearn create splits of different sizes\n",
    "kf = sklearn.model_selection.KFold(n_splits=5)\n",
    "\n",
    "#ADD YOUR CODE\n",
    "#parameters.update(mlp_kfold.best_params_)\n",
    "\n",
    "# recall to use cv=kf to use the k-fold subdivision seen in the lectures\n",
    "\n",
    "#ADD YOUR CODE\n",
    "mlp_kfold_batch = GridSearchCV(mlp_kfold.best_estimator_, parameters, cv=kf, return_train_score=True, verbose=True)\n",
    "mlp_kfold_batch.fit(X_train, y_train)\n",
    "#mlp_kfold_batch.score(X_test, y_test)\n",
    "\n",
    "\n",
    "print ('RESULTS FOR NN\\n')\n",
    "\n",
    "print(\"Best parameters set found:\")\n",
    "print(mlp_kfold_batch.best_params_)\n",
    "\n",
    "print(\"Score with best parameters:\")\n",
    "print(mlp_kfold_batch.best_score_)\n",
    "\n",
    "print(\"\\nAll scores on the grid:\")\n",
    "print(mlp_kfold_batch.cv_results_['mean_test_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION 1\n",
    "\n",
    "What do you observe for different architectures and batch sizes? How do the number of layers and their sizes affect the performances? What do you observe for different batch sizes, in particular what happens to the training convergence for different batch sizes (notice that the algorithm could not converge for some batch sizes)?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [ANSWER TO QUESTION 1]\n",
    "\n",
    "As far as the seed I considered is concerned the algorithm does not converge for a one hidden-layer NN of size 10, this could be caused by underfitting. For more complex NN there are no convergence issue but the algorithm stops after few iterations since there is no improvement  bigger than tolerance.\n",
    "I get convergence for each batch size (tried also with batch size of 64 and still get convergence).\n",
    "What I notice is that for small batch size the algorithm stops after few iterations due to no improvement bigger than tolerance, since for small batch size the algorithm is less robust.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 3:\n",
    "\n",
    "Plot the train and test accuracies as a function of the number of learnable parameters in your neural network. Print also the computation time for the various configurations you try (the code for getting the computation time is already provided). You can use 300 iterations (if you get a warning on convergence not reached it is not an issue for this lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MLP of size (10,) ...\n",
      "Done, training time: 2.96 sec\n",
      "\n",
      "Training MLP of size (20,) ...\n",
      "Done, training time: 2.42 sec\n",
      "\n",
      "Training MLP of size (30,) ...\n",
      "Done, training time: 2.66 sec\n",
      "\n",
      "Training MLP of size (30, 20) ...\n",
      "Done, training time: 1.88 sec\n",
      "\n",
      "Training MLP of size (30, 30, 20) ...\n",
      "Done, training time: 1.17 sec\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "from functools import reduce\n",
    "\n",
    "# Function to compute the number of learnable parameters of a mlp given the size of its hidden layers\n",
    "def param_count(hl_size):\n",
    "    tot = 0\n",
    "    input_size, output_size = X_train.shape[1], len(labels)\n",
    "    tot += (input_size+1)*hl_size[0]\n",
    "    for i in range(1,len(hl_size)):\n",
    "        tot += (hl_size[i-1]+1)*hl_size[i]\n",
    "    tot += (hl_size[-1]+1)*output_size\n",
    "    return tot\n",
    "\n",
    "hl_sizes = [(10,), (20,), (30,), (30,20,), (30,30,20)]\n",
    "hl_labels = [param_count(t) for t in hl_sizes]\n",
    "\n",
    "ti = time.time()\n",
    "train_acc_list, test_acc_list = [], []\n",
    "for hl_size in hl_sizes:\n",
    "    print('Training MLP of size {} ...'.format(hl_size))\n",
    "    mlp = MLPClassifier(max_iter=300, alpha=1e-4, solver='sgd',\n",
    "                    tol=1e-4, random_state=ID,\n",
    "                    learning_rate_init=.1, hidden_layer_sizes=hl_size)\n",
    "    \n",
    "    mlp.fit(X_train, y_train)\n",
    "   \n",
    "    \n",
    "    train_acc_list.append(mlp.score(X_train, y_train))\n",
    "    test_acc_list.append(mlp.score(X_test, y_test))\n",
    "    print('Done, training time: {:.2f} sec\\n'.format(time.time()-ti))\n",
    "    ti = time.time()\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(15,5))\n",
    "\n",
    "\n",
    "ax[0].plot(train_acc_list)\n",
    "ax[0].set_xlabel('Number of learnable params')\n",
    "ax[0].set_title('Train accuracy')\n",
    "ax[0].set_xticks(np.arange(0,len(hl_labels)))\n",
    "ax[0].set_xticklabels(hl_labels)\n",
    "ax[0].grid(True)\n",
    "\n",
    "ax[1].plot(test_acc_list)\n",
    "ax[1].set_xlabel('Number of learnable params')\n",
    "ax[1].set_title('Test accuracy')\n",
    "ax[1].set_xticks(np.arange(0,len(hl_labels)))\n",
    "ax[1].set_xticklabels(hl_labels)\n",
    "ax[1].grid(True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2:\n",
    "\n",
    "Comment about the training and test accuracies referring to the discussion on underfitting and overfitting we did in the course"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [ANSWER TO QUESTION 2\n",
    "\n",
    "Increasing the number of learnable parameters returns a better and better training error due to the capability of the network to perform a more accurate fit until a certain point. After that the accuracy drops: I noticed a dependence between the accuracy trend and the training set size, then the accuracy drop could be due to the fact that the training set size is too small for this number of learnable parameters. \n",
    "Increasing too much the size of the NN leads to overfitting as we can infer from the test accuracy. This reaches a maximum for an hidden layer size of 30 and then it becomes a descent function of the number of learnable parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO DO 4\n",
    "\n",
    "Now try also to use different learning rates, while keeping the best NN architecture and batch size you have found above. Plot the learning curves (i.e., the variation of the loss over the steps, you can get it from the loss_curve_ object of sklearn) for the different values of the learning rate. Try to run each training for 600 iterations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/giulia/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/giulia/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS FOR NN\n",
      "\n",
      "Best parameters set found:\n",
      "{'batch_size': 480}\n",
      "[0.01, 0.1]\n",
      "Score with best parameters:\n",
      "1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import operator\n",
    "\n",
    "\n",
    "#lr_list = [0.001, 0.01, 0.1]\n",
    "lr_list = [10**exp for exp in range(-3,0)]\n",
    "scores = {}\n",
    "parameters = mlp_kfold_batch.best_params_\n",
    "batch_size = parameters['batch_size']\n",
    "\n",
    "hidden_layer_sizes = mlp_kfold.best_params_['hidden_layer_sizes']\n",
    "#print(hidden_layer_sizes)\n",
    "#print(batch_size)\n",
    "loss = []\n",
    "fig, ax = plt.subplots(1,3, figsize=(12,4))\n",
    "\n",
    "for i in range(len(lr_list)):\n",
    "    learning_rate = lr_list[i]\n",
    "    mlp = MLPClassifier(max_iter=600, alpha=1e-4, solver='sgd',\n",
    "                    tol=1e-4, random_state=ID, batch_size= batch_size, hidden_layer_sizes=hidden_layer_sizes,\n",
    "                    learning_rate_init=learning_rate, verbose=False )\n",
    "    \n",
    "    \n",
    "    mlp.fit(X_train, y_train)\n",
    "    scores[lr_list[i]]=mlp.score(X_train, y_train)\n",
    "    loss.append(mlp.loss_)\n",
    "    ax[i].plot(mlp.loss_curve_)\n",
    "    ax[i].set_xlabel('iterations')\n",
    "   # ax[i].set_xlim(0,600)\n",
    "    ax[i].set_ylabel('loss_function for learning rate:'+ str(learning_rate))\n",
    "    #ax[i].legend()\n",
    "\n",
    "\n",
    "print ('RESULTS FOR NN\\n')\n",
    "\n",
    "print(\"Best parameters set found:\")\n",
    "best_score = max(scores.values())\n",
    "best_lr =  [key for key, val in scores.items() if val==best_score]\n",
    "print(parameters)\n",
    "print(best_lr)   \n",
    "\n",
    "print(\"Score with best parameters:\")\n",
    "print(best_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.506653143193714, 0.03643882536484858, 0.005412096759975506]\n"
     ]
    }
   ],
   "source": [
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0.001: 0.8483333333333334, 0.01: 1.0, 0.1: 1.0}\n"
     ]
    }
   ],
   "source": [
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION 3\n",
    "\n",
    "Comment about the learning curves (i.e. the variation of the loss over the steps). How does the curve changes for different learning rates in terms of stability and speed of convergence ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [ANSWER TO QUESTION 3]\n",
    "For the smallest learning rate:0.001 we get the slowest convergence but also the strongest stability. Increasing the learning rate results in a faster convergence but leads to instability (learning rate: 0.1) at the point that after 200 iterations the algorithm stops since it does not get better accuracy any more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO DO 5\n",
    "\n",
    "Now get training and test error for a NN with best parameters (architecture, batch size and learning rate) from above. Plot the learning curve also for this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RESULTS FOR BEST NN\n",
      "\n",
      "Best NN training error: 0.030000\n",
      "Best NN test error: 0.205500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/giulia/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (250) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learning_rate = best_lr[0]\n",
    "\n",
    "mlp = MLPClassifier(max_iter=250, alpha=1e-4, solver='sgd',\n",
    "                    tol=1e-4, random_state=ID, batch_size= batch_size, hidden_layer_sizes=hidden_layer_sizes,\n",
    "                    learning_rate_init=learning_rate )\n",
    "\n",
    "mlp.fit(X_train, y_train)\n",
    "training_error = 1-mlp.score(X_train, y_train)\n",
    "test_error = 1-mlp.score(X_test, y_test)\n",
    "print ('\\nRESULTS FOR BEST NN\\n')\n",
    "\n",
    "print (\"Best NN training error: %f\" % training_error)\n",
    "print (\"Best NN test error: %f\" % test_error)\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(16,4))\n",
    "ax.plot(mlp.loss_curve_)\n",
    "ax.set_xlabel('iterations')\n",
    "ax.set_ylabel('loss function')\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More data \n",
    "Now let's do the same but using 4000 (or less if it takes too long on your machine) data points for training. Use the same NN architecture as before, but you can try more if you like and have a powerful computer!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels in training dataset:  [0 1 2 3 4 5 6 7 8 9]\n",
      "Frequencies in training dataset:  [408 414 385 412 389 378 411 402 432 369]\n"
     ]
    }
   ],
   "source": [
    "#X = X[permutation]\n",
    "#y = y[permutation]\n",
    "# I removed permutation in order to avoid that the small training set and the large test set \n",
    "#had non-null intersection since after i will check the wrong classified items in the large test set\n",
    "\n",
    "m_training = 4000\n",
    "\n",
    "X_train, X_test = X[:m_training], X[m_training:]\n",
    "y_train, y_test = y[:m_training], y[m_training:]\n",
    "\n",
    "labels, freqs = np.unique(y_train, return_counts=True)\n",
    "print(\"Labels in training dataset: \", labels)\n",
    "print(\"Frequencies in training dataset: \", freqs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO DO 6\n",
    "\n",
    "Now train the NNs with the added data points using the optimum parameters found above. Eventually, feel free to try different architectures if you like. We suggest that you use 'verbose=True' so have an idea of how long it takes to run 1 iteration (eventually reduce also the number of iterations to 50)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/giulia/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (250) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RESULTS FOR NN\n",
      "\n",
      "NN training error: 0.054500\n",
      "NN test error: 0.163768\n"
     ]
    }
   ],
   "source": [
    "# use best architecture and params from before\n",
    "\n",
    "mlp_large = MLPClassifier(max_iter=250, alpha=1e-4, solver='sgd',\n",
    "                    tol=1e-4, random_state=ID, batch_size= batch_size, hidden_layer_sizes=hidden_layer_sizes,\n",
    "                    learning_rate_init=learning_rate )\n",
    "\n",
    "mlp_large.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "print ('\\nRESULTS FOR NN\\n')\n",
    "\n",
    "#get training and test error for the NN\n",
    "\n",
    "#ADD YOUR CODE\n",
    "training_error_large = 1-mlp_large.score(X_train, y_train)\n",
    "test_error_large = 1-mlp_large.score(X_test, y_test)\n",
    "\n",
    "\n",
    "print (\"NN training error: %f\" % training_error_large)\n",
    "print (\"NN test error: %f\" % test_error_large)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QUESTION 4\n",
    "Compare the train and test error you got with a large number of samples with the best one you obtained with only 600 data points. Comment about the results you obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best NN training error, m=600: 0.030000\n",
      "Best NN test error, m=600: 0.205500\n",
      "NN training error, m=4000: 0.054500\n",
      "NN test error, m=4000: 0.163768\n"
     ]
    }
   ],
   "source": [
    "print (\"Best NN training error, m=600: %f\" % training_error)\n",
    "print (\"Best NN test error, m=600: %f\" % test_error)\n",
    "\n",
    "\n",
    "print (\"NN training error, m=4000: %f\" % training_error_large)\n",
    "print (\"NN test error, m=4000: %f\" % test_error_large)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [ANSWER TO QUESTION 4]\n",
    "Considering a bigger dataset leads to a bigger training error but reduces the test error leading so to better NN performances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO DO 7\n",
    "\n",
    "Plot an example that was missclassified by NN with m=600 training data points and it is now instead correctly classified by NN with m=4000 training data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL: 3\n",
      "0 3 3\n"
     ]
    }
   ],
   "source": [
    "NN_prediction = mlp.predict(X_test)\n",
    "large_NN_prediction = mlp_large.predict(X_test)\n",
    "\n",
    "missclassified = -1\n",
    "i=0\n",
    "\n",
    "while missclassified==-1:\n",
    "    if (NN_prediction[i] != y_test[i] and large_NN_prediction[i]== y_test[i]):\n",
    "        missclassified= i\n",
    "        plot_input(X_test,y_test,i)\n",
    "        print(NN_prediction[i], large_NN_prediction[i], y_test[i])\n",
    "    i += 1\n",
    "    \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO DO 8\n",
    "\n",
    "Let's plot the weigths of the multi-layer perceptron classifier, for the best NN we get with 600 data points and with 4000 data points. The code is already provided, just fix variable names (e.g., replace mlp , mlp_large with your estimators) in order to have it working with your implementation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights with 600 data points:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights with 4000 data points:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Weights with 600 data points:\")\n",
    "\n",
    "fig, axes = plt.subplots(4, 4)\n",
    "vmin, vmax = mlp.coefs_[0].min(), mlp.coefs_[0].max()\n",
    "for coef, ax in zip(mlp.coefs_[0].T, axes.ravel()):\n",
    "    ax.matshow(coef.reshape(28, 28), cmap=plt.cm.gray, vmin=.5 * vmin,\n",
    "               vmax=.5 * vmax)\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"Weights with 4000 data points:\")\n",
    "\n",
    "fig, axes = plt.subplots(4, 4)\n",
    "vmin, vmax = mlp_large.coefs_[0].min(), mlp_large.coefs_[0].max()\n",
    "for coef, ax in zip(mlp.coefs_[0].T, axes.ravel()):\n",
    "    ax.matshow(coef.reshape(28, 28), cmap=plt.cm.gray, vmin=.5 * vmin,\n",
    "               vmax=.5 * vmax)\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QUESTION 5\n",
    "\n",
    "Describe what do you observe by looking at the weights.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### [ANSWER TO QUESTION 5]\n",
    "From the weights we could infer the image pixel structure. In particular, increasing the training set size we get a \"smoother\" weights trend."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO DO 9\n",
    "\n",
    "Take the best SVM model and its parameters, you found in the last notebook. Fit it on a few data points and compute its training and test scores. Then fit also a logistic regression model with C=1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS FOR SVM\n",
      "Training score SVM:\n",
      "0.10040000000000004\n",
      "Test score SVM:\n",
      "0.15839999999999999\n"
     ]
    }
   ],
   "source": [
    "m_training = 5000\n",
    "\n",
    "X_train, X_test = X[:m_training], X[m_training:2*m_training]\n",
    "y_train, y_test = y[:m_training], y[m_training:2*m_training]\n",
    "\n",
    "# use best parameters found in the SVM notebook, create SVM and perform fitting\n",
    "parameters ={'C': [50], 'gamma':[0.05]}\n",
    "rbf_svm = SVC(kernel='rbf')\n",
    "#rbf_svm_kfold = GridSearchCV(rbf_svm, parameters, cv=4, return_train_score=True)\n",
    "rbf_svm.fit(X_train, y_train)\n",
    "#ADD YOUR CODE\n",
    "\n",
    "print ('RESULTS FOR SVM')\n",
    "\n",
    "SVM_training_error =  1-rbf_svm.score(X_train, y_train)\n",
    "\n",
    "print(\"Training score SVM:\")\n",
    "print(SVM_training_error)\n",
    "\n",
    "SVM_test_error = 1- rbf_svm.score(X_test, y_test)\n",
    "print(\"Test score SVM:\")\n",
    "print(SVM_test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RESULTS FOR LOGISTIC REGRESSION WITH REGULARIZATION\n",
      "Training error (reg): 0.030000\n",
      "Test error (reg): 0.205500\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "regL2 = linear_model.LogisticRegression(C=1, max_iter=1000)\n",
    "regL2.fit(X_train, y_train)\n",
    "# you can re-use your code from Lab 2\n",
    "\n",
    "#ADD YOUR CODE\n",
    "\n",
    "print ('\\nRESULTS FOR LOGISTIC REGRESSION WITH REGULARIZATION')\n",
    "\n",
    "reg_training_error = 1-regL2.score(X_train, y_train)\n",
    "reg_test_error =  1- regL2.score(X_test, y_test)\n",
    "\n",
    "print (\"Training error (reg): %f\" % training_error)\n",
    "print (\"Test error (reg): %f\" % test_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## QUESTION 6\n",
    "Compare the results of Logistic Regression, SVM and NN. Which one achieve the best results? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### [ANSWER TO QUESTION 6]\n",
    "SVM achieves the best accuracy followed by NN and linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN test error: 0.163768\n",
      "SVM test error: 0.158400\n",
      "Test error (reg): 0.190400\n"
     ]
    }
   ],
   "source": [
    "print (\"NN test error: %f\" % test_error_large)\n",
    "print(\"SVM test error: %f\" %SVM_test_error)\n",
    "print (\"Test error (reg): %f\" % reg_test_error)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
