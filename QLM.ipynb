{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c128dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "from IPython.display import Latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ab28ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.5 -0.5  0.5  0.5 -0.5 -0.5 -0.5  0.5 -0.5 -0.5  0.5  0.5]\n",
      "[-0.5  0.5  0.5  0.5  0.5 -0.5  0.5  0.5  0.5 -0.5 -0.5  0.5]\n"
     ]
    }
   ],
   "source": [
    "npr.seed(10)\n",
    "\n",
    "sites = np.ones(12)*1/2*np.sign(npr.random(12)-0.5)\n",
    "links = np.ones(12)*1/2*np.sign(npr.random(12)-0.5)\n",
    "print(sites)\n",
    "print(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ef8404b",
   "metadata": {},
   "outputs": [],
   "source": [
    "leg_sites = {\n",
    "    1/2 : '$\\circ$',\n",
    "    -1/2 : '$\\\\bullet$'\n",
    "}\n",
    "\n",
    "leg_links = {\n",
    "    1/2 : '$\\leftarrow$',\n",
    "    -1/2 : '$\\\\rightarrow$'\n",
    "}\n",
    "\n",
    "def Visualize(sites, links):\n",
    "    sites_symbols = np.vectorize(leg_sites.get)(sites)\n",
    "    links_symbols = np.vectorize(leg_links.get)(links)\n",
    "    seq_list = [i + j for i, j in zip(sites_symbols, links_symbols)]\n",
    "    total_list = ''.join(seq_list)\n",
    "    return total_list\n",
    "\n",
    "def Gaggiublock(i, sites, links):\n",
    "    s1, l1 = sites[i],links[i]\n",
    "    s2, l2 = sites[i+1],links[i+1]\n",
    "    g = s2 - l2 + l1 + (-1)**(i)*1/2 == 0     \n",
    "    '''\n",
    "    Since numering start from 0 instead of 1 like in the review, \n",
    "    we absorbe a '-1' sign (exponent of last term becomes i instead of i+1)\n",
    "    '''\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "229a7b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-0.5, 0.5) (-0.5, 0.5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma1 = (-1/2,-1/2)\n",
    "sigma2 = (1/2,1/2)\n",
    "\n",
    "sites = sigma1[0], sigma2[0]\n",
    "links = sigma1[1], sigma2[1]\n",
    "    \n",
    "print(sites, links)\n",
    "    \n",
    "Gaggiublock(0,sites,links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b55a131",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import permutations, product\n",
    "\n",
    "all_sit = list(product([0.5,-0.5], repeat=12))\n",
    "all_lin = list(product([0.5,-0.5], repeat=12))\n",
    "ok = []\n",
    "\n",
    "for s in all_sit:\n",
    "    for l in all_lin:\n",
    "        check = True\n",
    "        for i in range(len(s)-1):\n",
    "            if not Gaggiublock(i, s, l): \n",
    "                check = False\n",
    "                break\n",
    "        if check == True: ok.append(np.array([s,l]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e1f59ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\circ$$\\rightarrow$$\\circ$$\\leftarrow$$\\circ$$\\leftarrow$$\\bullet$$\\leftarrow$$\\circ$$\\leftarrow$$\\bullet$$\\leftarrow$$\\bullet$$\\rightarrow$$\\circ$$\\leftarrow$$\\circ$$\\leftarrow$$\\bullet$$\\leftarrow$$\\bullet$$\\rightarrow$$\\bullet$$\\rightarrow$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 10\n",
    "x = Visualize(ok[n][0],ok[n][1]) \n",
    "Latex(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fe1f223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "754"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27306dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences_flattened=[]\n",
    "for i in range(len(ok)):\n",
    "    sequences_flattened.append(ok[i].flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958f8aeb",
   "metadata": {},
   "source": [
    "# Definizione della RBM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1341e0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def activate(v_in, wei, bias, DE, info=False):\n",
    "    act = np.dot(v_in, wei) + bias\n",
    "    prob = 1. / (1. + np.exp(-DE*act))\n",
    "    n = len(act)\n",
    "    v_out = np.full(n, vmin)\n",
    "    v_out[np.random.random_sample(n) < prob] = 1\n",
    "    if info:\n",
    "        print('input=', v_in)\n",
    "        print('act=', act)\n",
    "        print('prob=', prob)\n",
    "        print('out=', v_out)\n",
    "        \n",
    "    return(v_out)\n",
    "\n",
    "def training_RBM(alpha, w, a, b, seq):\n",
    "    \n",
    "    number_sequences = len(seq)\n",
    "    sequence_length = len(seq[0])\n",
    "    hidden_units = alpha*sequence_length #setting nubmer of hidden units\n",
    "    \n",
    "    #minibatches\n",
    "    mini, m = int(0.08*number_sequences), 0 \n",
    "    #epochs\n",
    "    nepoch = 50\n",
    "    #l_rate\n",
    "    l_rate = 1.\n",
    "\n",
    "    for epoch in range(1, 1+nepoch):\n",
    "        for n in range(number_sequences):\n",
    "            if m==0:\n",
    "                #initialize\n",
    "                v_data, v_model = np.zeros(sequence_length), np.zeros(sequence_length) \n",
    "                h_data, h_model = np.zeros(hidden_units), np.zeros(hidden_units) \n",
    "                vh_data, vh_model = np.zeros((sequence_length,hidden_units)), np.zeros((sequence_length, hidden_units)) \n",
    "\n",
    "            #CAPIRE BENE IL GAP\n",
    "            #positive CD phase\n",
    "            h = activate(v[n],w,b,GAP)\n",
    "            #negative CD phase\n",
    "            vf = activate(h, w.T,a,GAP)\n",
    "            #positive CD nr 2\n",
    "            hf = activate(vf,w,b, GAP)\n",
    "\n",
    "            v_data += v[n]\n",
    "            v_model += vf\n",
    "            h_data += h\n",
    "            h_model += hf\n",
    "            \n",
    "            theta = np.dot(w.T,seq.T)+b\n",
    "            \n",
    "            O_a += seq.T\n",
    "            O_b += np.tanh(theta)\n",
    "            O_w += \n",
    "            vh_model += np.outer(vf.T, hf)\n",
    "\n",
    "            m += 1\n",
    "            if m==mini:\n",
    "                C = l_rate / mini\n",
    "                \n",
    "                dw = C*(vh_data - vh_model)\n",
    "                da = C*(v_data - v_model)\n",
    "                db = C*(h_data - h_model)\n",
    "\n",
    "                w += dw\n",
    "                a += da\n",
    "                b += db\n",
    "                m = 0\n",
    "\n",
    "        #randomize order\n",
    "        np.random.shuffle(v)\n",
    "        l_rate = l_rate / (0.05 * l_rate + 1)\n",
    "        \n",
    "    return w,a,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6398917-8967-4d8e-9502-e7d8d3635df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#funzioen elementi matrice per Ising e periodic boundaries conditions -> personalizzata\n",
    "\n",
    "def flip(spin):\n",
    "    return -spin\n",
    "\n",
    "def mel_Ising1D_pb(state_S, a, theta):\n",
    "        flip_seq = [[]] + [[i] for i in range(len(state))]\n",
    "        output = np.zeros(len(state_s))\n",
    "        for i in range(len(state_s)-1):\n",
    "            v = np.zero((len(state_S),1))\n",
    "            output[i]-=state_s[i]*state_s[i+1]\n",
    "        \n",
    "    \n",
    "    return \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7ff5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_RBM(alpha, w, a, b, seq):\n",
    "    \n",
    "    N_s = len(seq) #N -> per avere lo storico, sequenze fatte sin'ora s\n",
    "    n_spins = len(seq[0]) #L \n",
    "    n_h = alpha * n_spins #M\n",
    "    \n",
    "    theta = np.dot(w.T, seq.T) + b\n",
    "    \n",
    "    Oa = seq.T\n",
    "    Ob = np.tanh(theta)\n",
    "    Ow = seq.T.reshape((n_spins, 1, N_s))*np.tanh(theta.reshape(1, n_h, N_s))\n",
    "    \n",
    "    #stochastic reconfiguration\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b61fa4-4de3-45d6-abab-dd3a591282ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "        derivs = np.concatenate([dA, dB, dW.reshape(n_spins * n_h, N_s)])\n",
    "\n",
    "        avg_derivs = np.sum(derivs, axis=1, keepdims=True) / N_s\n",
    "        avg_derivs_mat = np.conjugate(avg_derivs.reshape(derivs.shape[0], 1))\n",
    "        avg_derivs_mat = avg_derivs_mat * avg_derivs.reshape(1, derivs.shape[0])\n",
    "        moment2 = np.einsum('ik,jk->ij', np.conjugate(derivs), derivs) / N_s\n",
    "        S_kk = np.subtract(moment2, avg_derivs_mat)\n",
    "\n",
    "        F_p = np.sum(Eloc.transpose() * np.conjugate(derivs), axis=1) / N_s\n",
    "        F_p -= np.sum(Eloc.transpose(), axis=1) * \\\n",
    "               np.sum(np.conjugate(derivs), axis=1) / (N_s ** 2)\n",
    "        S_kk2 = np.zeros(S_kk.shape, dtype=complex)\n",
    "        row, col = np.diag_indices(S_kk.shape[0])\n",
    "        S_kk2[row, col] = self.lambd(p) * np.diagonal(S_kk)\n",
    "        S_reg = S_kk + S_kk2\n",
    "        update = np.dot(np.linalg.inv(S_reg), F_p).reshape(derivs.shape[0], 1)\n",
    "\n",
    "        return update, derivs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0488b9da",
   "metadata": {},
   "source": [
    "$\\theta$ M*N ottenuta da una M*L e una L*N quindi quando si somma B vettore di lunghezza M questo subirà un broadcasting lungo le righe\n",
    "B: vettore M*1\n",
    "W: L*M\n",
    "seq: storico delle sequenze generate: N*L, N cambia a ogni iterazione\n",
    "corrispondenza con codice kafischer:\n",
    "n_h -> M\n",
    "N_s -> N\n",
    "n_spins -> L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81a2828",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "12d44e31",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'npr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-138-69fb523ea97e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#seq dovrà essere un'array di elementi di questo tipo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mseq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mN_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mn_spins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'npr' is not defined"
     ]
    }
   ],
   "source": [
    "#seq dovrà essere un'array di elementi di questo tipo\n",
    "seq = np.ones(12)*1/2*np.sign(npr.random(12)-0.5)\n",
    "alpha = 4\n",
    "N_s = len(seq)\n",
    "n_spins = len(seq[0])\n",
    "n_h = alpha * n_spins\n",
    "\n",
    "#stdev of initialized weights\n",
    "sigma = np.sqrt(4. / float(N_s+n_h))\n",
    "\n",
    "#initialized weights\n",
    "w = sigma * (2*np.random.rand(n_spins, n_h) - 1) #from -sigma to sigma \n",
    "a = sigma * (2*np.random.rand(n_spins) - 1)\n",
    "b = np.zeros(n_h)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d086c69-f222-4cb0-8107-b19324db2409",
   "metadata": {},
   "source": [
    "Tommaso ricomincia da qui:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1483d79-89ee-4a99-8310-cd6218cfa476",
   "metadata": {},
   "source": [
    "Librerie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fd87c54-6e06-4a74-90f5-0cdb27ecf726",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39a602e-50f0-41d4-978d-00ac324de4bd",
   "metadata": {},
   "source": [
    "Funzioni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "71f2e8a4-6f43-47e5-9297-5705207cffe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inizializzo la RBM\n",
    "\n",
    "def InitializeRBM(n_visible, n_hidden, init_weight):\n",
    "    '''\n",
    "    inizializzo completamente la RBM\n",
    "    '''\n",
    "    N=n_visible\n",
    "    M=n_hidden\n",
    "    #gli a sono i visible bias e sono N\n",
    "    a = (init_weight * (np.random.rand(N, 1)-0.5)).astype(dtype=complex)\n",
    "    #i b sono gli hidden bias e sono M\n",
    "    b = (init_weight * (np.random.rand(M, 1)-0.5)).astype(dtype=complex)\n",
    "    #i w sono una matrice NxM\n",
    "    w = (init_weight * (np.random.rand(N, M)-0.5)).astype(dtype=complex)\n",
    "    return a,b,w\n",
    "\n",
    "\n",
    "def Demagnetize(current_state, verbose=False):\n",
    "    '''\n",
    "    dati una sequenza con magnetizzazione non nulla la porto a magnetizzazione nulla flippando spin in modo intelligente\n",
    "    '''\n",
    "    total_mag_init = sum(current_state)\n",
    "    total_mag=total_mag_init\n",
    "    \n",
    "    if total_mag > 0:\n",
    "        while total_mag != 0:\n",
    "            current_state[int(np.random.choice(np.where(current_state == 1)[0], 1))] *= -1\n",
    "            total_mag = sum(current_state)\n",
    "    elif total_mag < 0:\n",
    "        while total_mag != 0:\n",
    "            current_state[int(np.random.choice(np.where(current_state == -1)[0], 1))] *= -1\n",
    "            total_mag = sum(current_state)\n",
    "            \n",
    "    if verbose:\n",
    "        print('Initial magnetization of the state:', total_mag_init)\n",
    "        print('Final magnetization of the state:', total_mag)\n",
    "        \n",
    "    return(current_state)\n",
    "\n",
    "def GenerateSpinSequence(n_visible, encoding):\n",
    "    return np.random.choice(encoding, n_visible, p=[0.5, 0.5]).reshape(n_visible, 1)\n",
    "    \n",
    "def SpinSequenceFlips(current_state, n_flips):\n",
    "    \"\"\"\n",
    "    ritorna lo stato iniziale con n_flips spin flippati\n",
    "    \"\"\"\n",
    "    output=np.copy(current_state)\n",
    "    print(n_flips)\n",
    "    for i in range(n_flips):\n",
    "        index = np.random.randint(1,len(current_state))\n",
    "        output[index]*=-1\n",
    "    return output\n",
    "        \n",
    "def AmplitudeRatio(a, b, w, current_state, proposed_state):\n",
    "    \"\"\" \n",
    "    calcola il rapporto tra Psi(state') e Psi(state) dove state' è state con spin flippati\n",
    "    prende in input i parametri della rbm, lo stato corrente e lo stato proposto dal sampling\n",
    "    \n",
    "    Tira fuori la formula C6 \n",
    "    \n",
    "    Occhio all'update dei theta in log_proposed_wf perché si updatano con formula C7. Potrebbe esserci qualcosa che non va \n",
    "    perché non ho perfettamente capito cosa sia quel 2 W_kj sigma^z_s. Controllate.\n",
    "    \"\"\"\n",
    "    #guardando la documentazione mi ritrovo con la notazione\n",
    "    thetas=Theta(b,w, current_state)\n",
    "    log_actual_wf= -np.dot(a.T,current_state)+np.sum(np.log(2*np.cosh(thetas)))\n",
    "    log_proposed_wf= -np.dot(a.T,current_state)+np.sum(np.log(2*np.cosh(thetas-2*np.dot(w.T,proposed_state))))\n",
    "    return np.exp(log_proposed_wf/log_actual_wf)\n",
    "\n",
    "def Theta(b, w, current_state):\n",
    "    \"\"\"\n",
    "    funzione che calcola i theta\n",
    "    \n",
    "    \"\"\"\n",
    "    return b+np.dot(w.T, current_state)\n",
    "    \n",
    "def Metropolis(n_sweeps): #e altro):\n",
    "    '''\n",
    "    Generates samples of configurations from an neural quantum state (NQS)\n",
    "    using a Metropolis-Hastings algorithm.\n",
    "    '''\n",
    "    print('Starting Monte Carlo Sampling')\n",
    "\n",
    "    for i in range(int(n_sweeps)):\n",
    "        for _ in range(int(sweep_factor * self.n_visible)):\n",
    "            self.move(n_flips)\n",
    "        self.current_Hloc = self.local_energy()\n",
    "        self.state_history.append(np.array(self.current_state))\n",
    "        self.local_energies.append(self.current_Hloc)\n",
    "        if self.samples_file:\n",
    "            self.write_current_state(f)\n",
    "\n",
    "        print('Completed Monte Carlo Sampling')\n",
    "    \n",
    "def optimizer(a, b, w):\n",
    "    '''\n",
    "    dati i pesi di una vecchia RBM sputo fuori quelli nuovi\n",
    "    '''\n",
    "    pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "a78e2926-a9ff-4a4d-b24f-34eba43091c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial magnetization of the state: [2]\n",
      "Final magnetization of the state: [0]\n"
     ]
    }
   ],
   "source": [
    "#per forza intero e pari\n",
    "n_visible=40 \n",
    "n_hidden=40\n",
    "#anche Baiesi lo faceva\n",
    "init_weight=0.001\n",
    "#da capire bene perché\n",
    "zero_magnetization = True \n",
    "#encoding come spin e non come bit\n",
    "particle_encoding = [-1,1] \n",
    "               \n",
    "#inizializzo uno stato\n",
    "current_state = GenerateSpinSequence(n_visible, encoding)\n",
    "\n",
    "#inizializzo la RBM\n",
    "a, b, w = InitializeRBM(n_visible, n_hidden, init_weight)\n",
    "\n",
    "if zero_magnetization == True:\n",
    "    current_state=Demagnetize(current_state, verbose=True)\n",
    "               \n",
    "sampler_params = {'n_sweeps': 10000, 'therm_factor': 0.,'sweep_factor': 1, 'n_flips': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "c2bd47b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(100):\n",
    "#               #ciclo di ottimizzazione\n",
    "#    #mi aspetto che current state, dato lo stato della RBM e la hamiltoniana propria del modello, venga samplato con metropolis\n",
    "#    current_state = Metropolis(hamiltonianaIsing1D, RBM_init, zero_magnetization=True, current_state)\n",
    "#    #a,b,w = optimizer(a,b,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "d0f155a6-4ab1-4006-bd3f-a8602611b306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 -2 -2  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  2  0  0  0  0  0  0  0]\n",
      "[[2.7182853+0.j]]\n"
     ]
    }
   ],
   "source": [
    "current_state = GenerateSpinSequence(n_visible, particle_encoding)\n",
    "proposed_state= SpinSequenceFlips(current_state, 3)\n",
    "print((current_state-proposed_state).reshape(n_visible,))\n",
    "print(AmplitudeRatio(a,b,w,current_state,proposed_state))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
